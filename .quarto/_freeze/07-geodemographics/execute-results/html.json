{
  "hash": "5c89d16c3db8669f8865e62f7da4d565",
  "result": {
    "markdown": "# Geodemographic Classification\nThis week we will turn to geodemographic classification. Geodemographic classification is a method used to categorise geographic areas and the people living in them based on demographic, socioeconomic, and sometimes lifestyle characteristics. This approach combines geographic information with demographic data to create profiles of different neighborhoods.\n\n## Lecture slides\nYou can download the slides of this week's lecture here: [[Link]]({{< var slides.week07 >}}).\n\n## Reading list \n#### Essential readings {.unnumbered}\n- Dalton, C. M. and Thatcher. J. 2015. Inflated granularity: Spatial \"Big Data\" and geodemographics. *Big Data & Society* 2(2): 1-15. [[Link]](https://doi.org/10.1177/2053951715601144)\n- Longley, P. A. 2012. Geodemographics and the practices of geographic information science. *International Journal of Geographical Information Science* 26(12): 2227-2237. [[Link]](https://doi.org/10.1080/13658816.2012.719623)\n- Wyszomierski, J., Longley, P. A., and Singleton, A. *et al.* 2024. A neighbourhood Output Area Classification from the 2021 and 2022 UK censuses. *The Geographical Journal*. 190(2): e12550. [[Link]](https://doi.org/10.1111/geoj.12550)\n\n#### Suggested readings {.unnumbered}\n- Fränti, P. and Sieronoja, S. 2019. How much can k-means be improved by using better initialization and repeats? *Pattern Recognition* 93: 95-112. [[Link]](https://doi.org/10.1016/j.patcog.2019.04.014)\n- Singleton, A. and Longley, P. A. 2024. Classifying and mapping residential structure through the London Output Area Classification. *Environment and Planning B: Urban Analytics and City Science* 51(5): 1153-1164. [[Link]](https://doi.org/10.1177/23998083241242913)\n- Singleton, A. and Spielman, S. 2014. The past, present, and future of geodemographic research in the United States and United Kingdom. *The Professional Geographer* 66(4): 558-567. [[Link]](https://doi.org/10.1080/00330124.2013.848764)\n\n## Classifying London\nToday, we will create our own geodemographic classification to examine demographic clusters across London, drawing inspiration from [London Output Area Classification](https://doi.org/10.1177/23998083241242913). Specifically, we will try to identify clusters based on age group, self-identified ethnicity, country of birth, and first or preferred language. \n\nThe data covers all usual residents, as recorded in the 2021 Census for England and Wales, aggregated at the [Lower Super Output Area (LSOA)](https://www.ons.gov.uk/methodology/geography/ukgeographies/censusgeographies/census2021geographies) level. These datasets have been extracted using the [Custom Dataset Tool](https://www.ons.gov.uk/datasets/create), and you can download each file via the links provided below. A copy of the 2021 London LSOAs spatial boundaries is also available. Save these files in your project folder under `data`.\n\n| File                                        | Type   | Link |\n| :------                                     | :------| :------ |\n| London LSOA Census 2021 Age Groups          | `csv` | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/attributes/London-LSOA-AgeGroup.csv) |\n| London LSOA Census 2021 Country of Birth    | `csv` | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/attributes/London-LSOA-Country-of-Birth.csv) |\n| London LSOA Census 2021 Ethnicity           | `csv` | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/attributes/London-LSOA-Ethnicity.csv) |\n| London LSOA Census 2021 Main Language       | `csv` | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/attributes/London-LSOA-MainLanguage.csv) |\n| London LSOA 2021 Spatial Boundaries         | `GeoPackage` | [Download](https://github.com/jtvandijk/GEOG0030/raw/refs/heads/main/data/spatial/London-LSOA-2021.gpkg) |\n\n::: {.callout-tip}\nYou may have already downloaded some of these datasets in previous weeks, but for completeness, they are all provided here. Only download the datasets you do not already have or did not save.\n:::\n\nOpen a new script within your `GEOG0030` project and save this as `w07-geodemographic-classification.r`. \n\nBegin by loading the necessary libraries:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# load libraries\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggcorrplot)\nlibrary(cluster)\nlibrary(factoextra)\nlibrary(sf)\nlibrary(tmap)\n```\n:::\n\n\n::: {.callout-warning}\nYou may have to install some of these libraries if you have not used these before.\n:::\n\nNext, we can load the individual `csv` files that we downloaded into R.\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# load age data\nlsoa_age <- read_csv(\"data/attributes/London-LSOA-AgeGroup.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 24970 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Age (5 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# load country of birth data\nlsoa_cob <- read_csv(\"data/attributes/London-LSOA-Country-of-Birth.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 39952 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Country of birth (8 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# load ethnicity data\nlsoa_eth <- read_csv(\"data/attributes/London-LSOA-Ethnicity.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 99880 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Ethnic group (20 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# load language data\nlsoa_lan <- read_csv(\"data/attributes/London-LSOA-MainLanguage.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 54934 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Main language (11 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n::: {.callout-warning}\nIf using a Windows machine, you may need to substitute your forward-slashes (`/`) with two backslashes (`\\\\`) whenever you are dealing with file paths.\n:::\n\nNow, carefully examine each individual dataframe to understand how the data is structured and what information it contains.\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# inspect age data\nhead(lsoa_age)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Age (5 categories) C…³\n  <chr>                            <chr>                                   <dbl>\n1 E01000001                        City of London 001A                         1\n2 E01000001                        City of London 001A                         2\n3 E01000001                        City of London 001A                         3\n4 E01000001                        City of London 001A                         4\n5 E01000001                        City of London 001A                         5\n6 E01000002                        City of London 001B                         1\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Age (5 categories) Code`\n# ℹ 2 more variables: `Age (5 categories)` <chr>, Observation <dbl>\n```\n:::\n\n```{.r .cell-code}\n# inspect country of birth data\nhead(lsoa_cob)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Country of birth (8 …³\n  <chr>                            <chr>                                   <dbl>\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Country of birth (8 categories) Code`\n# ℹ 2 more variables: `Country of birth (8 categories)` <chr>,\n#   Observation <dbl>\n```\n:::\n\n```{.r .cell-code}\n# inspect ethnicity data\nhead(lsoa_eth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Ethnic group (20 cat…³\n  <chr>                            <chr>                                   <dbl>\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Ethnic group (20 categories) Code`\n# ℹ 2 more variables: `Ethnic group (20 categories)` <chr>, Observation <dbl>\n```\n:::\n\n```{.r .cell-code}\n# inspect language data\nhead(lsoa_lan)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Main language (11 ca…³\n  <chr>                            <chr>                                   <dbl>\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Main language (11 categories) Code`\n# ℹ 2 more variables: `Main language (11 categories)` <chr>, Observation <dbl>\n```\n:::\n:::\n\n\n::: {.callout-tip}\nYou can further inspect the results using the `View()` function. \n:::\n\n### Variable preparation\nTo identify geodemographic clusters in our dataset, we will use a technique called $k$-means. $k$-means aims to partition a set of standardised observations into a specified number of clusters ($k$). To do this we first need to prepare the individual datasets, as well as transform and standardise the input variables.\n\n::: {.callout-note}\n$k$-means clustering is an unsupervised machine learning algorithm used to group data into a predefined number of clusters, based on similarities between data points. It works by initially assigning $k$ random centroids, then iteratively updating them by assigning each data point to the nearest centroid and recalculating the centroid's position based on the mean of the points in each cluster. The process continues until the centroids stabilise, meaning they no longer change significantly. $k$-means is often used for tasks such as data segmentation, image compression, or anomaly detection. It is simple but may not work well with non-spherical or overlapping clusters.\n:::\n\nBecause all the data are stored in [long format](https://towardsdatascience.com/long-and-wide-formats-in-data-explained-e48d7c9a06cb), with each London LSOA appearing on multiple rows for each category — such as separate rows for different age groups, ethnicities, countries of birth, and first or preferred languages - we need to transform it into a [wide format](https://towardsdatascience.com/long-and-wide-formats-in-data-explained-e48d7c9a06cb). For example, instead of having multiple rows for an LSOA showing counts for different age groups all the information for each LSOA will be consolidated into a single row. Additionally, we will clean up the column names to follow standard R naming conventions and make the data easier to work with. Like we have done previously, we can automate this process using the `janitor` package.\n\nWe will begin with the `age` dataframe:\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# clean names\nlsoa_age <- lsoa_age |>\n    clean_names()\n\n# pivot\nlsoa_age <- lsoa_age |>\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"age_5_categories\",\n        values_from = \"observation\")\n\n# clean names\nlsoa_age <- lsoa_age |>\n    clean_names()\n```\n:::\n\n\n::: {.callout-note}\nIf your `clean_names()` function returns an error, it is likely due to a conflict with another library that also includes a `clean_names()` function. In such cases, R cannot determine which one to use. To resolve this, you can specify the library explicitly by using `janitor::clean_names()`.\n:::\n\nTo account for the non-uniformity of the areal units, we further need to convert the observations to proportions and only retain those columns that are likely to be meaningful in the context of the classification:\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# total observations\nlsoa_age <- lsoa_age |>\n    rowwise() |>\n    mutate(age_pop = sum(across(2:6)))\n\n# total proportions, select columns\nlsoa_age <- lsoa_age |>\n    mutate(across(2:6, ~./age_pop)) |>\n    select(1:6)\n\n# inspect\nhead(lsoa_age)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 6\n# Rowwise: \n  lower_layer_super_output_areas_code aged_15_years_and_un…¹ aged_16_to_24_years\n  <chr>                                                <dbl>               <dbl>\n1 E01000001                                           0.0846              0.0744\n2 E01000002                                           0.0621              0.0889\n3 E01000003                                           0.0682              0.0706\n4 E01000005                                           0.127               0.178 \n5 E01000006                                           0.224               0.120 \n6 E01000007                                           0.257               0.103 \n# ℹ abbreviated name: ¹​aged_15_years_and_under\n# ℹ 3 more variables: aged_25_to_34_years <dbl>, aged_35_to_49_years <dbl>,\n#   aged_50_years_and_over <dbl>\n```\n:::\n:::\n\n\nThis looks much better. We can do the same for the country of `birth` data:\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# prepare country of birth data\nlsoa_cob <- lsoa_cob |>\n    clean_names() |>\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"country_of_birth_8_categories\",\n        values_from = \"observation\") |>\n    clean_names()\n\n# proportions, select columns\nlsoa_cob <- lsoa_cob |>\n    rowwise() |>\n    mutate(cob_pop = sum(across(2:9))) |>\n    mutate(across(2:9, ~./cob_pop)) |>\n    select(-2, -10)\n```\n:::\n\n\nAnd we can do the same for the `ethnicity` and `language` datasets:\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# prepare ethnicity data\nlsoa_eth <- lsoa_eth |>\n    clean_names() |>\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"ethnic_group_20_categories\",\n        values_from = \"observation\") |>\n    clean_names()\n\n# proportions, select columns\nlsoa_eth <- lsoa_eth |>\n    rowwise() |>\n    mutate(eth_pop = sum(across(2:21))) |>\n    mutate(across(2:21, ~./eth_pop)) |>\n    select(-2, -22)\n\n# prepare language data\nlsoa_lan <- lsoa_lan |>\n    clean_names() |>\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"main_language_11_categories\",\n        values_from = \"observation\") |>\n    clean_names()\n\n# proportions, select columns\nlsoa_lan <- lsoa_lan |>\n    rowwise() |>\n    mutate(lan_pop = sum(across(2:12))) |>\n    mutate(across(2:12, ~./lan_pop)) |>\n    select(-2, -11, -13)\n```\n:::\n\n\nWe now have four separate datasets, each containing the proportions of usual residents classified into different groups based on age, country of birth, ethnicity, and language.\n\n### Variable selection\nWhere we initially selected variables from different demographic domains, not all variables may be suitable for inclusion. Firstly, the variables need to exhibit sufficient heterogeneity to ensure they capture meaningful differences between observations. Secondly, variables should not be highly correlated with one another, as this redundancy can skew the clustering results. Ensuring acceptable correlation between variables helps maintain the diversity of information and improves the robustness of the clustering outcome.\n\n::: {.callout-warning}\nVariable selection is often a time-consuming process that requires a combination of domain knowledge and more extensive exploratory analysis than is covered in this practical.\n:::\n\nA straightforward yet effective method to examine the distribution of our variables is to create boxplots for each variable. This can be efficiently achieved by using `facet_wrap()` from the `ggplot2` library to generate a matrix of panels, allowing us to visualise all variables in a single view. \n\n::: {.callout-note}\n`ggplot2` is a popular data visualisation package in R, designed for creating complex plots. It uses the [Grammar of Graphics](https://towardsdatascience.com/a-comprehensive-guide-to-the-grammar-of-graphics-for-effective-visualization-of-multi-dimensional-1f92b4ed4149) to build layered, customisable graphics by mapping data to visual elements like colour, size, and shape. We will explore the `ggplot2` library further in [Weeks 9 and 10](09-maps.html). In the meantime, you can refer to the [ggplot2 documentation](https://ggplot2.tidyverse.org/reference/facet_wrap.html) for more details on `facet_wrap()`.\n:::\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# wide to long\nlsoa_age_wd <- lsoa_age |>\n    pivot_longer(cols = c(2:5), names_to = \"agegroup\", values_to = \"count\")\n\n# facet age\nggplot(lsoa_age_wd, aes(y = count)) + geom_boxplot() + facet_wrap(~agegroup, ncol = 2) +\n    theme_minimal() + ylab(\"\")\n```\n\n::: {.cell-output-display}\n![Boxplots of the distribution of the `age` dataset.](07-geodemographics_files/figure-html/fig-07-boxplot-data-1.png){#fig-07-boxplot-data width=672}\n:::\n:::\n\n\nWhen repeating this process for the `birth`, `ethnicity`, and `language` variables, you will notice that some variables have a very limited distribution. Specifically, some variables may have a value of `0` for the majority of London LSOAs. As a rule of thumb, we will retain only those variables where at least 75% of the LSOAs have values different from `0`.\n\n::: {.callout-warning}\nThis threshold of 75% is arbitrary, and in practice, more thorough consideration should be given when deciding whether to include or exclude a variable.\n:::\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# join\nlsoa_df <- lsoa_age |>\n    left_join(lsoa_cob, by = \"lower_layer_super_output_areas_code\") |>\n    left_join(lsoa_eth, by = \"lower_layer_super_output_areas_code\") |>\n    left_join(lsoa_lan, by = \"lower_layer_super_output_areas_code\")\n\n# calculate proportion of zeroes\nzero_prop <- sapply(lsoa_df[2:41], function(x) {\n    mean(x == 0)\n})\n\n# extract variables with high proportion zeroes\nidx <- which(zero_prop > 0.25)\n\n# inspect\nidx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   white_gypsy_or_irish_traveller            any_other_uk_languages \n                               27                                33 \n  oceanic_or_australian_languages north_or_south_american_languages \n                               37                                38 \n```\n:::\n\n```{.r .cell-code}\n# remove variables with high proportion zeroes\nlsoa_df <- lsoa_df |>\n    select(-white_gypsy_or_irish_traveller, -any_other_uk_languages, -oceanic_or_australian_languages,\n        -north_or_south_american_languages)\n```\n:::\n\n\n::: {.callout-note}\nThe code above makes use of [Boolean logic](https://en.wikipedia.org/wiki/Boolean_algebra) to calculate the proportion of zeroes within each variable. The `x == 0` part checks each value in column `x` to see if it is equal to `0`, returning `TRUE` or `FALSE` for each element. The `mean()` function is then used to calculate the average of the `TRUE` values in the column. Since `TRUE` is treated as `1` and `FALSE` as `0`, this gives the proportion of values in the column that are equal to zero.\n:::\n\nWe can subsequently check for multicollinearity of the remaining variables. The easiest way to check the correlations between all variables is probably by visualising a correlation matrix:\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# inspect variable names\nnames(lsoa_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"lower_layer_super_output_areas_code\"                                  \n [2] \"aged_15_years_and_under\"                                              \n [3] \"aged_16_to_24_years\"                                                  \n [4] \"aged_25_to_34_years\"                                                  \n [5] \"aged_35_to_49_years\"                                                  \n [6] \"aged_50_years_and_over\"                                               \n [7] \"europe_united_kingdom\"                                                \n [8] \"europe_ireland\"                                                       \n [9] \"europe_other_europe\"                                                  \n[10] \"africa\"                                                               \n[11] \"middle_east_and_asia\"                                                 \n[12] \"the_americas_and_the_caribbean\"                                       \n[13] \"antarctica_and_oceania_including_australasia_and_other\"               \n[14] \"asian_asian_british_or_asian_welsh_bangladeshi\"                       \n[15] \"asian_asian_british_or_asian_welsh_chinese\"                           \n[16] \"asian_asian_british_or_asian_welsh_indian\"                            \n[17] \"asian_asian_british_or_asian_welsh_pakistani\"                         \n[18] \"asian_asian_british_or_asian_welsh_other_asian\"                       \n[19] \"black_black_british_black_welsh_caribbean_or_african_african\"         \n[20] \"black_black_british_black_welsh_caribbean_or_african_caribbean\"       \n[21] \"black_black_british_black_welsh_caribbean_or_african_other_black\"     \n[22] \"mixed_or_multiple_ethnic_groups_white_and_asian\"                      \n[23] \"mixed_or_multiple_ethnic_groups_white_and_black_african\"              \n[24] \"mixed_or_multiple_ethnic_groups_white_and_black_caribbean\"            \n[25] \"mixed_or_multiple_ethnic_groups_other_mixed_or_multiple_ethnic_groups\"\n[26] \"white_english_welsh_scottish_northern_irish_or_british\"               \n[27] \"white_irish\"                                                          \n[28] \"white_roma\"                                                           \n[29] \"white_other_white\"                                                    \n[30] \"other_ethnic_group_arab\"                                              \n[31] \"other_ethnic_group_any_other_ethnic_group\"                            \n[32] \"english_or_welsh\"                                                     \n[33] \"european_languages_eu\"                                                \n[34] \"other_european_languages_non_eu\"                                      \n[35] \"asian_languages\"                                                      \n[36] \"african_languages\"                                                    \n[37] \"any_other_languages\"                                                  \n```\n:::\n\n```{.r .cell-code}\n# change variable names to index to improve visualisation\nlsoa_df_vis <- lsoa_df\nnames(lsoa_df_vis)[2:37] <- paste0(\"v\", sprintf(\"%02d\", 1:36))\n\n# correlation matrix\ncor_mat <- cor(lsoa_df_vis[, -1])\n\n# correlation plot\nggcorrplot(cor_mat, outline.col = \"#ffffff\", tl.cex = 8, legend.title = \"Correlation\")\n```\n\n::: {.cell-output-display}\n![Correlation plot of classification variables.](07-geodemographics_files/figure-html/fig-07-correlation-matrix-1.png){#fig-07-correlation-matrix width=672}\n:::\n:::\n\n\nFollowing the approach from [Wyszomierski *et al.* (2024)](https://doi.org/10.1111/geoj.12550), we can define a *weak* correlation as lying between 0 and 0.40, *moderate* as between 0.41 and 0.65, *strong* as between 0.66 and 0.80, and *very strong* as between 0.81 and 1. \n\nA few *strong* and *very strong* correlations can be observed that potentially could be removed; however, to maintain representation, here we decide to retain all variables.\n\n### Variable standardisation\nIf the input data are heavily skewed or contain outliers, $k$-means may produce less meaningful clusters. While normality is not required per se, it has been common to do this nonetheless. More important is to standardise the input variables, especially when they are measured on different scales. This ensures that each variable contributes equally to the clustering process. \n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# inverse hyperbolic sine\nlsoa_df_vis[, -1] <- sapply(lsoa_df_vis[-1], asinh)\n\n# range standardise\nlsoa_df_vis[, -1] <- sapply(lsoa_df_vis[-1], function(x) {\n    (x - min(x))/(max(x) - min(x))\n})\n```\n:::\n\n\n### Selecting the number of clusters\nNow our data are prepared we will start by creating an elbow plot. The [elbow method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)#:~:text=In%20cluster%20analysis%2C%20the%20elbow,number%20of%20clusters%20to%20use%60) is a visual tool that helps determine the optimal number of clusters in a dataset. This is important because with $k$-means clustering you need to specify the numbers of clusters *a priori*. The elbow method involves running the clustering algorithm with varying numbers of clusters ($k$) and plotting the total explained variation (known as the *Within Sum of Squares*) against the number of clusters. The goal is to identify the *elbow* point on the curve, where the rate of decrease in explained variation starts to slow. This point suggests that adding more clusters yields diminishing returns in terms of explained variation.\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# elbow plot\nfviz_nbclust(lsoa_df_vis[, -1], kmeans, nstart = 100, iter.max = 100, method = \"wss\")\n```\n\n::: {.cell-output-display}\n![Elbow plot with *Within Sum of Squares* against number of clusters.](07-geodemographics_files/figure-html/fig-07-elbow-plot-1.png){#fig-07-elbow-plot width=672}\n:::\n:::\n\n\nBased on the elbow plot, we can now choose the number of clusters and it looks like **6** clusters would be a reasonable choice.\n\n::: {.callout-note}\nThe interpretation of an elbow plot can be quite subjective, and multiple options for the optimal number of clusters might be justified; for instance, 4, 5, or even 7 clusters could be reasonable choices. In addition to the elbow method, other techniques can aid in determining the optimal number of clusters, such as [silhouette scores](https://en.wikipedia.org/wiki/Silhouette_(clustering)) and the [gap statistic](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#The_gap_statistics). An alternative and helful approach is to use a [clustergram](https://clustergram.readthedocs.io/en/stable/notebooks/introduction.html), which is a two-dimensional plot that visualises the flows of observations between clusters as more clusters are added. This method illustrates how your data reshuffles with each additional cluster and provides insights into the quality of the splits. This method can be done in R, but currently easier to implement in Python.\n:::\n\n### $k$-means clustering \nNow we have decided on the number of clusters, we can run our $k$-means analysis.\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# set seed for reproducibility\nset.seed(999)\n\n# k-means\nlsoa_clus <- kmeans(lsoa_df_vis[, -1], centers = 6, nstart = 100, iter.max = 100)\n```\n:::\n\n\nWe can inspect the object to get some information about our clusters:\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# inspect\nlsoa_clus\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nK-means clustering with 6 clusters of sizes 796, 1097, 771, 1011, 851, 468\n\nCluster means:\n        v01       v02       v03       v04       v05       v06       v07\n1 0.4816225 0.1632210 0.2425566 0.4838983 0.4169123 0.5410477 0.1337158\n        v08       v09       v10        v11        v12        v13        v14\n1 0.3007540 0.2480613 0.2859754 0.08913663 0.05177222 0.14603013 0.06993627\n         v15        v16        v17        v18        v19        v20        v21\n1 0.12176548 0.10935022 0.20109979 0.18150482 0.11605092 0.12757934 0.09288236\n         v22        v23       v24       v25       v26        v27       v28\n1 0.07473711 0.14662903 0.1842217 0.3522638 0.1490577 0.02997040 0.2423784\n         v29       v30       v31       v32        v33        v34        v35\n1 0.07148504 0.2193009 0.5870244 0.2411272 0.07541661 0.23467242 0.10174187\n         v36\n1 0.10216507\n [ reached getOption(\"max.print\") -- omitted 5 rows ]\n\nClustering vector:\n [1] 4 4 4 1 1 5 5 6 6 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 2 2 1 1 2 2 2 1 1 1\n[39] 1 1 1 1 5 1 5 1 1 1 1 1\n [ reached getOption(\"max.print\") -- omitted 4944 entries ]\n\nWithin cluster sum of squares by cluster:\n[1] 259.0272 177.7951 288.8625 232.7770 298.9145 160.1702\n (between_SS / total_SS =  48.5 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n```\n:::\n:::\n\n\n### Visualising clusters\nWe now need to perform some post-processing to extract useful summary data for each cluster. To characterise the clusters, we can compare the global mean values of each variable with the mean values specific to each cluster. \n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# global means\nglob_means <- colMeans(lsoa_df_vis[, -1])\n\n# add clusters to input data\nlsoa_df_vis <- cbind(lsoa_df_vis, cluster = lsoa_clus$cluster)\n\n# cluster means\ncluster_means <- lsoa_df_vis |>\n    group_by(cluster) |>\n    summarise(across(2:37, mean))\n\n# difference\ncluster_diffs <- cluster_means |>\n    mutate(across(2:37, ~. - glob_means[cur_column()]))\n```\n:::\n\n\nThese comparisons can then be visualised using, for instance, a radial bar plot:\n\n\n::: {.cell filename='R code'}\n\n```{.r .cell-code}\n# to long format\ncluster_diffs_long <- cluster_diffs |>\n    pivot_longer(!cluster, names_to = \"vars\", values_to = \"score\")\n\n# facet clusters\nggplot(cluster_diffs_long, aes(x = factor(vars), y = score)) + geom_bar(stat = \"identity\") +\n    coord_radial(rotate.angle = TRUE, expand = FALSE) + facet_wrap(~cluster, ncol = 3) +\n    theme_minimal() + theme(axis.text.x = element_text(size = 7)) + xlab(\"\") + ylab(\"\")\n```\n\n::: {.cell-output-display}\n![Radial barplots of cluster means for each input variable.](07-geodemographics_files/figure-html/fig-07-radial-plot-1.png){#fig-07-radial-plot width=672}\n:::\n:::\n\n\nThese plots can serve as a foundation for creating pen portraits by closely examining which variables drive each cluster. \n\n::: {.callout-tip}\nFor easier interpretation, these values can be transformed into index scores, allowing us to assess which variables are under- or overrepresented within each cluster group.\n:::\n\nOf course, we can also map the results:\n\n\n::: {.cell .styled-output filename='R code'}\n\n```{.r .cell-code}\n# read spatial dataset\nlsoa21 <- st_read(\"data/spatial/London-LSOA-2021.gpkg\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `London-LSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-LSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4994 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n```\n:::\n\n```{.r .cell-code}\n# join\nlsoa21 <- cbind(lsoa21, cluster = lsoa_clus$cluster)\n\n# shape, polygon\ntm_shape(lsoa21) +\n\n  # specify column, colours\n  tm_polygons(\n    col = \"cluster\",\n    palette = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n    border.col = \"#ffffff\",\n    border.alpha = 0.1,\n    title = \"Cluster number\"\n  ) +\n\n  # set layout\n  tm_layout(\n    legend.outside = FALSE,\n    legend.position = c(\"left\", \"bottom\"),\n    frame = FALSE\n  )\n```\n\n::: {.cell-output-display}\n![Classification of London LSOAs based on several demographic variables.](07-geodemographics_files/figure-html/fig-07-cluster-map-1.png){#fig-07-cluster-map width=672}\n:::\n:::\n\n\n::: {.callout-important}\nThe reason we can use `cbind()` to join the cluster outputs to the `lsoa21` spatial file is that the LSOAs in both files are recorded in the same order. It is essential to verify that the LSOAs are indeed in the same order in both datasets, as any discrepancy will result in clusters being assigned to the wrong polygons.\n:::\n\n## Assignment\nThe creation of a geodemographic classification is an iterative process. This typically includes adding or removing variables, adjusting the number of clusters, and grouping data in different ways to achieve the most meaningful segmentation. Try to do the following:\n\n1. Download the two datasets provided below and save them to your `data` folder. The datasets include:\n    * A `csv` file containing the number of people aged 16 years and older by occupational category, as defined by the [Standard Occupational Classification 2020](https://www.ons.gov.uk/methodology/classificationsandstandards/standardoccupationalclassificationsoc), aggregated by 2021 LSOAs.\n    * A `csv` file containing the number of people aged 16 years and older by their highest level of qualification, also aggregated to the 2021 LSOA level.\n2. Prepare these two datasets and retain only those variables that are potentially meaningful. Filter out any variables with a high proportion of zero values.\n3. Merge the education and occupation dataset with the dataset used to generate the initial geodemographic classification. Check for multicollinearity and consider removing any variables that are highly correlated.\n4. Perform $k$-means clustering on your extended dataset. Make sure to select an appropriate number of clusters for your analysis.\n5. Interpret the individual clusters in terms of the variables that are under- and overrepresented. \n\n| File                                        | Type   | Link |\n| :------                                     | :------| :------ |\n| London LSOA Census 2021 Occupation          | `csv`  | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/attributes/London-LSOA-Occupation.csv) |\n| London LSOA Census 2021 Education           | `csv`  | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/attributes/London-LSOA-Education.csv) |\n\n## Before you leave\nHaving finished this tutorial, you should now understand the basics of a geodemographic classification. That is [all for this week](https://www.youtube.com/watch?v=ArFyi_iaEdw)! ",
    "supporting": [
      "07-geodemographics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}