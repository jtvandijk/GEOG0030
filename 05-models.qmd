# Spatial Models 
Last week, we explored spatial dependency and methods for measuring it. This week, we will examine how spatial autocorrelation can impact our analyses, especially in models where independence assumptions are crucial. To address these dependencies, we will use the `GWmodel` library to calculate local summary statistics for geographical areas and to fit basic spatially explicit models to our data.

## Lecture slides 
You can download the slides of this week's lecture here: [[Link]]({{< var slides.week05 >}}).

## Reading list
#### Essential readings {.unnumbered}
- Harris, R. 2019. **Chapter 8**: *Not just nuisance: Spatialising social statistics.* In: Whitworth, A. (ed). Towards a Spatial Social Policy: Bridging the Gap Between Geography and Social Policy. Bristol: Policy Press. [[Link]](https://www-jstor-org.libproxy.ucl.ac.uk/stable/j.ctvs1g92b.12?socuuid=53116c87-882d-4070-b1dc-45854bbedbfe)

#### Suggested readings {.unnumbered}
- Brundson, C., Fotheringham, M., and Charlton, M. 2002. Geographically Weighted Regression. *Journal of the Royal Statistical Society: Series D (The Statistician)* 47(3): 431-443. [[Link]](https://doi.org/10.1111/1467-9884.00145)
- Comber, A., Brundson, C., Charlton, M. *et al.*. 2022. A route map for successful applications of Geographically Weighted Regression. *Geographical Analysis* 55(1): 155-178. [[Link]](https://doi.org/10.1111/gean.12316)

## Elections results in England and Wales
This week we will investigate the political geography of England and Wales, focusing on the results of the July 2024 General Election, which was won by the Labour Party led by Keir Starmer. You will work with data extracted from two data sources: the [constituency results from the election](https://commonslibrary.parliament.uk/research-briefings/cbp-10009/) and socio-demographic information relating to age groups, economic status, and ethnic background from the 2021 Census, extracted using the [Custom Dataset Tool](https://www.ons.gov.uk/datasets/create). These datasets have been prepared and merged. Along with this dataset, we also have access to a `GeoPackage` that contains the boundaries of the parliamentary constituencies. 

You can download both files below and save them in your project folder under `data/attributes` and `data/spatial`, respectively.

| File                                                        | Type   | Link |
| :------                                                     | :------| :------ |
| England and Wales Parliamentary Constituencies GE2024       | `csv` | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/attributes/England-Wales-GE2024-Constituency-Vars.csv) |
| England and Wales Parliamentary Constituencies Boundaries   | `GeoPackage` | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/spatial/England-Wales-GE2024-Boundaries.gpkg) |

Open a new script within your `GEOG0030` project and save this as `w05-election-analysis.r`. 

Begin by loading the necessary libraries:

```{r}
#| label: 05-load-libraries
#| classes: styled-output
#| echo: True
#| eval: True
#| output: False
#| tidy: True
#| filename: 'R code'
# load libraries
library(tidyverse)
library(sf)
library(tmap)
library(GWmodel)
library(easystats)
```

::: {.callout-warning}
You may have to install some of these libraries if you have not used these before.
:::

Once downloaded, we can load both files into memory:
```{r}
#| label: 5-load-gpkg-csv
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# load election dataset
elec_24 <- read_csv('data/attributes/England-Wales-GE2024-Constituency-Vars.csv')

# load constituency boundaries
cons_24 <- st_read('data/spatial/England-Wales-GE2024-Boundaries.gpkg')

# inspect
head(elec_24)

# inspect
head(cons_24)
``` 

::: {.callout-note}
You can inspect both objects using the `View()` function. 
:::

### Geographically weighted correlation
In [GEOG0018 Research Methods in Human Geography](https://jtvandijk.github.io/GEOG0018/03-statistics2.html), we already worked with this electoral dataset and we hypothesised that predominantly older voters tend to support the Conservative Party. To explore this, we examined the relationship between the proportion of individuals over 50 years old in each parliamentary constituency (`aged_50_years_and_over`) and the proportion of votes cast for the Conservative Party (`conservative_vote_share`). A scatterplot and Pearson's correlation revealed a moderate association between the two variables, suggesting a possible link between age demographics and Conservative voting patterns:

```{r}
#| label: fig-05-plot-data-scatter
#| fig-cap: Quick scatterplot
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# correlation
cor.test(elec_24$aged_50_years_and_over, elec_24$conservative_vote_share, method = 'pearson')

# scatterplot
plot(elec_24$aged_50_years_and_over, elec_24$conservative_vote_share, xlab = 'Proportion of population over 50 years old', ylab = 'Proportion of votes for the Conservative party')
```

However, as you should know by now, the first step when working with spatial data is to map your variables:

```{r tidy='styler'} 
#| label: fig-05-map-vote-share
#| fig-cap: Proportions of votes cast for the Conservative party in the 2024 elections.
#| classes: styled-output
#| echo: True
#| eval: True
#| cache: True
#| filename: 'R code'
# join attribute data onto spatial data
cons_24 <- cons_24 |> 
  left_join(elec_24, by = c('pcon24cd' = 'constituency_code'))

# shape, polygons
tm_shape(cons_24) +
  
  # specify column, colours
  tm_fill(
    col = 'conservative_vote_share',
    style = 'jenks',
    n = '5',
    palette = c('#f1eef6', '#bdc9e1', '#74a9cf', '#2b8cbe', '#045a8d'),
    title = 'Conservative vote share'
  ) +
  
  # set layout
  tm_layout(
    legend.outside = FALSE,
    legend.position = c('left', 'top'),
    frame = FALSE
  )
``` 

```{r tidy='styler'} 
#| label: fig-05-map-over-50-share
#| fig-cap: Proportions of population over 50 years old.
#| classes: styled-output
#| echo: True
#| eval: True
#| cache: True
#| filename: 'R code'
# shape, polygons
tm_shape(cons_24) +
  
  # specify column, colours
  tm_fill(
    col = 'aged_50_years_and_over',
    style = 'jenks',
    n = '5',
    palette = c('#f0f0f0', '#d9d9d9', '#bdbdbd', '#969696', '#737373'),
    title = '50+ population share'
  ) +
  
  # set layout
  tm_layout(
    legend.outside = FALSE,
    legend.position = c('left', 'top'),
    frame = FALSE
  )
``` 

Looking at the maps, the spatial distribution of Conservative vote share and the proportion of the population over 50 appears neither random nor uniform. This raises the question to what extent the observed correlation in @fig-05-plot-data-scatter holds consistently across different constituencies? To answer this we can run a Geographically Weighted Correlation using the `GWmodel` library.

Geographically Weighted Correlation (GWC) allows us to investigate whether the strength and direction of the association between variables vary across space. By applying a localised correlation technique, GWC calculates the correlation coefficient within specified spatial windows or *kernels* across the study area. This can reveal geographic areas where the relationship is stronger or weaker, providing more insight than a single global correlation and helping us to understand spatial heterogeneity in the data.

::: {.callout-note}
The `GWmodel` library allows us to calculate local statistics, such as means, standard deviations, variances, and correlations. But [as with spatial autocorrelation](04-autocorrelation.html#defining-neighbours), we must define what *local* means. One approach is to use a kernel function to select which values contribute to each local estimate. Kernels operate on point locations (e.g. polygon centroids) and apply a window with a specified shape and bandwidth. The bandwidth, which defines the kernel's size, can be set in absolute terms (e.g. within 10 km) or in relative terms (e.g. the 10 nearest centroids), the latter known as an adaptive kernel.
:::

The `GWmodel` library uses the older `sp` data format for handling spatial data. We therefore need to convert our current `sf` object to `sp` before continuing:

```{r}
#| label: 05-to-sp
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| cache: True
#| filename: 'R code'
# to sp
cons_24_sp <- as_Spatial(cons_24)
```

::: {.callout-note}
The `sf` package is now preferred over `sp` in R for its modern, efficient handling of spatial data. By using simple features, a standardised format for spatial geometries, `sf` is more compatible with other geospatial tools and integrates smoothly with the tidyverse, simplifying data manipulation and analysis. However, some libraries still rely on `sp` and have not yet transitioned to `sf.`
:::

We can now calculate a geographically weighted correlation. We will use an adaptive bandwidth that estimates the local correlation using the 25 nearest constituencies:

```{r}
#| label: 05-gwc
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| cache: True
#| filename: 'R code'
# geographically weighted correlation
cons_24_cor <- gwss(cons_24_sp , vars = c('conservative_vote_share', 'aged_50_years_and_over'), 
                    bw = 25, adaptive = TRUE)
```

We can now extract the values and bind these back to our original `sf` object:

```{r}
#| label: 05-gwc-extract
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| cache: True
#| filename: 'R code'
# extract correlation
cons_24 <- cons_24 |>
  mutate(cons_age_cor = cons_24_cor$SDF$Corr_conservative_vote_share.aged_50_years_and_over)

# inspect
summary(cons_24$cons_age_cor)
```

::: {.callout-warning}
The results of the outcomes of `gwss` function can be accessed through the `$SDF` data frame.
:::

The summary shows that there indeed seems to be variation of this relationship across the country, with the local Pearson correlation ranging from very weak to very strong. Of course, we can map this in the usual way:

```{r tidy='styler'} 
#| label: fig-05-gwc-map
#| fig-cap: Local correlation values `conservative_vote_share` and `aged_50_years_and_over` variables.
#| echo: True
#| eval: True
#| cache: True
#| filename: 'R code'
# shape, polygons
tm_shape(cons_24) +
  
  # specify column, colours
  tm_fill(
    col = 'cons_age_cor',
    style = 'jenks',
    n = '5',
    palette = c('#fee5d9', '#fcae91', '#fb6a4a', '#de2d26', '#a50f15'),
    title = 'Local correlation'
  ) +
  
  # set layout
  tm_layout(
    legend.outside = FALSE,
    legend.position = c('left', 'top'),
    frame = FALSE
  )
``` 

While the map shows correlation patterns, it doesn not indicate statistical significance. To evaluate this, we can use a Monte Carlo simulation with the `gwss.montecarlo()` function. However, for a large dataset like ours, this process is computationally intensive and time-consuming, especially with more than the default `99` simulations.


::: {.callout-important} 
Although we will not run a Monte Carlo simulation here, the code below *demonstrates* how to run this and link the results back to the *cons_24* spatial dataframe
:::

```{r}
#| label: 05-gwc-sig-example
#| classes: styled-output
#| echo: True
#| eval: False
#| tidy: True
#| cache: True
#| filename: 'R code'
# geographically weighted correlation, monte carlo simulation
cons_24_cor_sig <- gwss.montecarlo(cons_24_sp , vars = c('conservative_vote_share', 'aged_50_years_and_over'), bw = 2, adaptive = TRUE, nsim = 99) |>
  as_tibble() |>
  select(Corr_conservative_vote_share.aged_50_years_and_over) 

# replace names
names(cons_24_cor_sig) <- 'cons_age_cor_p'

# bind results
cons_24 <- cons_24 |>
  cbind(cons_24_cor_sig) |>
  mutate(cons_24_cor = if_else(cons_age_cor_p < 0.025, cons_age_cor_p,
                       if_else(cons_age_cor_p > 0.975, cons_age_cor_p, NA)))
```

::: {.callout-note}
It took more than **2 minutes** to run the Monte Carlo simulation on an Apple MacBook Pro M1 (16GB RAM) with the default of `99` simulations. 
:::

### Geographically weighted regression
A correlation describes the strength and direction of a linear relationship, but if we want to quantify the change in a dependent variable (`y`) for a one-unit change in the independent variable(s) (`x`) we need to run a regression. Geographically weighted regression (GWR) is used when the relationship between a dependent and set of independent variables is not constant across space, meaning the model coefficients vary by location. This is useful when you suspect that the relationship between variables may change depending on the geographic context. GWR provides a localised understanding of the relationships by allowing each observation to have its own set of regression coefficients, which can provide insights into how relationships differ across the study area. 

GWR fits a separate regression equation at each location in the study area, weighting nearby observations more heavily than those farther away. Again, the weighting is typically based on a kernel function. The basic GWR equation is:

$$
y_{i} = \beta_{0}(\upsilon_{i}, v_{i}) + \sum_{k=1}^{p}\beta_{k}(\upsilon_{i}, v_{i})x_{ik} + \epsilon_{i}
$$

where $(\upsilon_{i}, v_{i})$ are the coordinates of location $i$ and $\beta_{k}(\upsilon_{i}, v_{i})$ are the location-specific coefficients. 

### Multivariate regression
To predict the Conservative voter share, we hypothesise that certain socio-demographic variables may play a significant role. These independent variables include:

| Variable                  | Description |
| :-                        | :------ |
| `eco_active_employed`     | Proportion of economically active employed individuals. |
| `eth_white`               | Proportion of the population identifying as white. |
| `eth_black`               | Proportion of the population identifying as black. |
| `aged_25_to_34_years`     | Proportion of the population between ages 25 and 34. |
| `aged_50_years_and_over`  | Proportion of the population over age 50. |

We can run the multivariate regression as follows: 

```{r}
#| label: 05-regression-multi
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# regression
lm_voteshare <- lm(conservative_vote_share ~ eco_active_employed + eth_white + eth_black + aged_25_to_34_years + aged_50_years_and_over, data = cons_24)

# summary
summary(lm_voteshare)
```

The model summary indicates that all variables are statistically significant predictors of Conservative vote share. The resuls suggest that older and employed populations are linked to higher Conservative support, while younger age groups and certain ethnic proportions show a negative relationship.

We can now run the diagnostics to see whether the regression assumptions are met. Check for normality of the residuals:

```{r}
#| label: fig-05-diagnose-normality
#| fig-cap: Check for normality of residuals.
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# run diagnostics 
performance::check_model(lm_voteshare, check = c('qq', 'normality'))
```

```{r}
#| label: fig-05-diagnose-linearity
#| fig-cap: Check for linearity and homogeneity
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# run diagnostics 
performance::check_model(lm_voteshare, check = c('linearity', 'homogeneity'))
```

```{r}
#| label: fig-05-diagnose-vif
#| fig-cap: Check for influential observations and multicollinearity.
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# run diagnostics 
performance::check_model(lm_voteshare, check = c('vif', 'outliers')) 
```

### Spatial dependence
The model diagnostics seem generally fine, perhaps except for the linearity check. This could indicate a curved relationship or, alternatively, suggest spatial dependence in the relationship. If spatial dependence is present, it may imply that the observations are not independent. We can examine this by assessing whether the model residuals display spatial dependence. Let us begin with a map:

```{r tidy='styler'} 
#| label: fig-05-map-residuals
#| fig-cap: Regression model residuals.
#| classes: styled-output
#| echo: True
#| eval: True
#| cache: True
#| filename: 'R code'
# join model residuals onto spatial data
cons_24 <- cons_24 |> 
  mutate(lm_residuals = lm_voteshare$residuals)

# shape, polygons
tm_shape(cons_24) +
  
  # specify column, colours
  tm_fill(
    col = 'lm_residuals',
    style = 'jenks',
    n = '5',
    palette = c('#ffffb2', '#fecc5c', '#fd8d3c', '#f03b20', '#f03b20'),
    title = 'Regression residuals'
  ) +
  
  # set layout
  tm_layout(
    legend.outside = FALSE,
    legend.position = c('left', 'top'),
    frame = FALSE
  )
``` 

Looking at @fig-05-map-residuals there appears to be some spatial structure in the model residuals. We can test this more formally using Moran's I test to assess spatial autocorrelation:



::: {.callout-tip}
For a more comprehensive dive into Geographically Weighted Regression, the [Spatial Modelling for Data Scientists](https://gdsl-ul.github.io/san/09-gwr.html) course by Liverpool-based Professors [Francisco Rowe](https://www.franciscorowe.com/) and [Dani Arribas-Bel](https://darribas.org/) provides an excellent introduction. 
:::

### Spatial models
In this tutorial, we have looked at geographically weighted correlation and regression. However, whilst out of the scope of this module, there are many other approaches to account for space in statistical models. Examples of such models are the spatial error model and the spatial lag model.

#### Spatial error model
The spatial error model is used when the error terms in a regression model exhibit spatial autocorrelation, meaning the error terms are not independent across space. This can happen due to omitted variables that have a spatial pattern or unmeasured factors that affect the dependent variable similarly across nearby locations.

The model adjusts for spatial autocorrelation by adding a spatially lagged error term (a weighted sum of the errors from neighbouring locations) to the regression equation:

$$
y = X\beta + \upsilon, \upsilon = \lambda W \upsilon + \epsilon
$$

where $X\beta$ represents the standard regression components, $\lambda$ is a spatial autoregressive parameter, $W$ is a spatial weights matrix, and $\upsilon$ is a vector of spatially autocorrelated errors.

::: {.callout-note}
Spatial error models can be fitted using R's [spatialreg](https://cran.r-project.org/web/packages/spatialreg/index.html) package.
:::

#### Spatial lag model
The spatial lag model is appropriate when the dependent variable itself exhibits spatial dependence. This means the value of the dependent variable in one location depends on the values in neighbouring locations. This model is used to capture the spillover effects or diffusion processes, where the outcome in one area is influenced by outcomes in nearby areas (e.g. house prices, crime rates).

The model incorporates a spatially lagged dependent variable, which is the weighted sum of the dependent variable values in neighbouring locations, into the regression equation:

$$
y = \rho Wy + X\beta + \epsilon
$$

where $\rho$ is the spatial autoregressive coefficient, $Wy$ represents the spatially lagged dependent variable, and $X\beta$ represents the standard regression components.

::: {.callout-note}
Spatial lag models can be fitted using R's [spatialreg](https://cran.r-project.org/web/packages/spatialreg/index.html) package.
:::

#### To note
The spatial error model adjusts for spatial autocorrelation in the error terms, whereas the spatial lag model adjusts for spatial dependence in the dependent variable itself. The spatial error model does not alter the interpretation of the coefficients of the independent variables, while the spatial lag model introduces a feedback loop where changes in one area can influence neighbouring areas.

Both the spatial error and spatial lag models assume that the relationships between variables are the same across the study area, with adjustments made only for spatial dependencies. GWR, on the other hand, allows the relationships themselves to vary across space. GWR is more flexible but also more complex and computationally intensive, providing local instead of global estimates of coefficients.

## Assignment

## Before you leave

