# Spatial Queries and Geometric Operations
This week, we look at geometric operations and spatial queries: the fundamental building blocks when it comes to spatial data processing and analysis. This includes operations such as aggregating point data, calculating the distances separating one or more spatial objects, running a *buffer* analysis, and *intersecting* different spatial layers.

## Lecture slides
You can download the slides of this week's lecture here: [[Link]]({{< var slides.week02 >}}).

## Reading list 
#### Essential readings {.unnumbered}
- Longley, P. *et al.* 2015. *Geographic Information Science & Systems*, **Chapter 2**: *The Nature of Geographic Data*, pp. 33-54. [[Link]](https://ucl.rl.talis.com/link?url=https%3A%2F%2Fapp.knovel.com%2Fhotlink%2Ftoc%2Fid%3AkpGISSE001%2Fgeographic-information-science%3Fkpromoter%3Dmarc&sig=e437927b963cc591dcb65491eccdd3869cc31aef80e1443cb2ba12d8f3bb031a)
- Longley, P. *et al.* 2015. *Geographic Information Science & Systems*, **Chapter 3**: *Representing Geography*, pp. 55-76. [[Link]](https://ucl.rl.talis.com/link?url=https%3A%2F%2Fapp.knovel.com%2Fhotlink%2Ftoc%2Fid%3AkpGISSE001%2Fgeographic-information-science%3Fkpromoter%3Dmarc&sig=e437927b963cc591dcb65491eccdd3869cc31aef80e1443cb2ba12d8f3bb031a)
- Longley, P. *et al.* 2015. *Geographic Information Science & Systems*, **Chapter 7**: *Geographic Data Modeling*, pp. 152-172.  [[Link]](https://ucl.rl.talis.com/link?url=https%3A%2F%2Fapp.knovel.com%2Fhotlink%2Ftoc%2Fid%3AkpGISSE001%2Fgeographic-information-science%3Fkpromoter%3Dmarc&sig=e437927b963cc591dcb65491eccdd3869cc31aef80e1443cb2ba12d8f3bb031a)
- Longley, P. *et al.* 2015. *Geographic Information Science & Systems*, **Chapter 13**: *Spatial Data Analysis*, pp. 290-318. [[Link]](https://ucl.rl.talis.com/link?url=https%3A%2F%2Fapp.knovel.com%2Fhotlink%2Ftoc%2Fid%3AkpGISSE001%2Fgeographic-information-science%3Fkpromoter%3Dmarc&sig=e437927b963cc591dcb65491eccdd3869cc31aef80e1443cb2ba12d8f3bb031a)

#### Suggested readings {.unnumbered}
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. *Geocomputation with R*, **Chapter 4**: *Spatial data operations*. [[Link]](https://geocompr.robinlovelace.net/spatial-operations.html)
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. *Geocomputation with R*, **Chapter 5**: *Geometry operations*. [[Link]](https://geocompr.robinlovelace.net/geometry-operations.html)
- Lovelace, R., Nowosad, J. and Muenchow, J. 2021. *Geocomputation with R*, **Chapter 6**: *Reprojecting geographic data*. [[Link]](https://geocompr.robinlovelace.net/reproj-geo-data.html)

## Bike theft in London I
This week, we will examine to what extent reported bicycle theft in London cluster around train and underground stations. We will be using open data from [data.police.uk](https://data.police.uk/) on reported crimes alongside [OpenStreetMap](https://www.openstreetmap.org/#map=6/54.91/-3.43) data for this analysis. We will use R to directly download the necessary data from OpenStreetMap, but the crime data will need to be manually downloaded from the data portal. We further have access to a `GeoPackage` that contains the London 2021 MSOA boundaries that we can use as reference layer. If you do not already have it on your computer, save this file in your `data/spatial` folder.

| File                                        | Type   | Link |
| :------                                     | :------| :------ |
| London MSOA 2021 Spatial Boundaries         | `GeoPackage` | [Download](https://github.com/jtvandijk/GEOG0030/raw/refs/heads/master/data/spatial/London-MSOA-2021.gpkg) |

### Crime data
The UK Police Data Portal allows you to access and generate tabular data for crime recorded in the UK across the different police forces. To download recorded crime data for London:

1. Navigate to [data.police.uk](https://data.police.uk/) and click on **Downloads**.
2. Under the data range select `January 2023` to `December 2023`.
3. Under the **Custom download** tab select `Metropolitan Police Service` and `City of London Police`. Leave the other settings unchanged and click on **Generate file**.

```{r}
#| label: fig-police-data
#| echo: False 
#| fig-cap: 'Downloading data on reported crimes through [data.police.uk](https://data.police.uk/)'
knitr::include_graphics('images/w02/police-data.png')
```

4. It may take a few minutes for the download to be generated, so be patient. Once the **Download now** button appears, you can download the dataset.
5. After downloading, unzip the file. You will find that the zip file contains 12 folders, one for each month of 2023. Each folder includes two files: one for the `Metropolitan Police Service` and one for the `City of London Police`.
6. Create a new folder named `London-Crime` within your `data/attributes` directory, and copy all 12 folders with the data into this new folder.

To get started, let us create our first script. **File** -> **New File** -> **R Script**. Save your script as `w02-bike-theft.r`. 

We will start by loading the libraries that we will need:

```{r}
#| label: 02-load-libraries
#| classes: styled-output
#| echo: True
#| eval: True
#| output: False
#| tidy: True
#| filename: 'R code'
# load libraries
library(tidyverse)
library(janitor)
library(sf)
library(tmap)
library(osmdata)
```

::: {.callout-warning}
You may have to install some of these libraries if you have not used these before.
:::

Although we could read each individual crime file into R one by one and then combine them, we can actually accomplish this in a single step:

```{r tidy='styler'}
#| label: 02-combine-csv
#| echo: True
#| eval: True
#| message: False
#| filename: 'R code'
# list all csv files
crime_df <- list.files(path='data/attributes/London-Crime/', full.names=TRUE, recursive=TRUE) |>
  # read individual csv files
  lapply(read_csv) |>
  # bind together into one
  bind_rows()

# inspect
head(crime_df)
```

::: {.callout-note}
Depending on your computer, processing this data may take some time due to the large volume involved. Once completed, you should have a dataframe containing **1,144,329** observations.
:::

::: {.callout-note}
You can further inspect the object using the `View()` function. 
:::

The column names contain spaces and are therefore not easily referenced. We can easily clean this up using the `janitor` package:

```{r}
#| label: 02-rename-fields
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# clean names
crime_df <- crime_df |>
  clean_names()

# inspect
names(crime_df)
```

::: {.callout-note}
If your `clean_names()` function returns an error, it is likely due to a conflict with another library that also includes a `clean_names()` function. In such cases, R cannot determine which one to use. To resolve this, you can specify the library explicitly by using `janitor::clean_names()`.
:::

For our analysis, we are currently only interested in reported bicycle thefts, so we need to filter our data based on the `crime_type` column. We can start by examining the unique values in this column and then subset the data accordingly:

```{r}
#| label: 02-filter-crime
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# unique types
unique(crime_df$crime_type)

# filter
theft_bike <- crime_df |>
  filter(crime_type == 'Bicycle theft')

# inspect
head(theft_bike)
```

Now that we have filtered the data to only include reported bicycle thefts, we need to convert our dataframe into a spatial dataframe that maps the locations of the crimes using the recorded latitude and longitude coordinates. We can then project this spatial dataframe into the British National Grid (`EPSG:27700`).

```{r}
#| label: 02-locate-crime
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# to spatial data
theft_bike <- theft_bike |>
  filter(!is.na(longitude) & !is.na(latitude)) |>
  st_as_sf(coords = c('longitude', 'latitude'), crs = 4326) |>
  st_transform(27700)

# inspect
head(theft_bike)
```

Let's map the dataset to get an idea of how the data looks like, using the outline of London as background:

```{r tidy='styler'} 
#| label: fig-02-theft-map
#| fig-cap: Reported bicycle thefts in London.
#| classes: styled-output
#| echo: True
#| eval: True
#| filename: 'R code'
# read spatial dataset
msoa21 <- st_read('data/spatial/London-MSOA-2021.gpkg')

# london outline
outline <- msoa21 |>
  st_union()

# shape
tm_shape(outline) +
  
# map data
tm_polygons(
  fill = '#f0f0f0',
  col = NA
) +
  
# shape
tm_shape(theft_bike) + 
  
# map data
tm_symbols(
  size = 0.10,
  fill = '#fdc086',
  col = '#fdc086',
) +
  
# layout
tm_layout(
  frame = FALSE,
)
```

We can save the prepared dataset as a `GeoPackage` so that we can use it some other time:

```{r}
#| label: 02-save-crime
#| classes: styled-output
#| echo: True
#| eval: False
#| tidy: True
#| filename: 'R code'
# write
st_write(theft_bike, 'data/spatial/London-BicycleTheft-2023.gpkg')
```

### Station data
OpenStreetMap (OSM) is a free, editable map of the world. Each map element (whether a point, line, or polygon) in OSM is tagged with various attribute data. To download the station data we need, we must use the appropriate tags, represented as `key` and `value` pairs, to query the OSM database. In our case, we are looking for train stations, which fall under the *Public Transport* `key`, with a `value` of *station*. To limit our search to London, we can use the spatial extent of the 2021 MSOA boundaries as the bounding box for data extraction.

```{r tidy='styler'} 
#| label: 02-station-data
#| classes: styled-output
#| echo: True
#| eval: True
#| warning: False
#| cache: True
#| filename: 'R code'
# define our bbox coordinates, use WGS84
bbox_london <- msoa21 |>
  st_transform(4326) |>
  st_bbox()
  
# osm query
osm_stations <- opq(bbox = bbox_london) |>
  add_osm_feature(key = 'public_transport', value = 'station') |>
  osmdata_sf()
```

::: {.callout-warning}
In some cases, the OSM query may return an error, particularly when multiple users from the same location are executing the exact same query. If so, you can download a prepared copy of the data here: [[Download]](https://github.com/jtvandijk/GEOG0030/raw/refs/heads/master/data/spatial/London-OSM-Stations.RData). You can load this copy into R through `load('data/spatial/London-OSM-Stations.RData')`
:::

The OSM query returns all data types, including lines and polygons tagged as stations. For our analysis, we only want to retain the point locations. In addition, we want to clip the results to the outline of London to exclude points that fall within the bounding box but outside the boundaries of Greater London.

```{r}
#| label: 02-station-point-data
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# extract points
osm_stations <- osm_stations$osm_points |>
  st_set_crs(4326) |>
  st_transform(27700) |>
  st_intersection(outline) |>
  select(c('osm_id', 'name', 'network', 'operator', 'public_transport', 'railway'))

# inspect
head(osm_stations)

# inspect
nrow(osm_stations)
```

The total number of data points seems rather high. In fact, looking at the `railway` variable, several points are not tagged as station or do not have a value at all:

```{r}
#| label: 02-station-point-count
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# inspect values
count(osm_stations, railway)
```

The number of points tagged as station in the railway field are most likely the only points in our dataset that represent actual stations, so we will only retain those points.

```{r}
#| label: 02-station-point-extract
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# extract train and underground stations
osm_stations <- osm_stations |>
  filter(railway == 'station')
```

Let's map the dataset to get an idea of how the data looks like, using the outline of London as background:

```{r tidy='styler'} 
#| label: fig-02-station-map
#| fig-cap: Train and underground stations in London.
#| classes: styled-output
#| echo: True
#| eval: True
#| filename: 'R code'

# shape
tm_shape(outline) +
  
# map data
tm_polygons(
  fill = '#f0f0f0',
  col = NA
) +
  
# shape
tm_shape(osm_stations) + 
  
# map data
tm_symbols(
  size = 0.2,
  fill = '#636363',
  col = '#636363',
) +
  
# layout
tm_layout(
  frame = FALSE,
)

```
Now we have our data prepared, we can move on to analyse the extent to which bicycle theft in London cluster around stations. We can use both spatial queries and geometric operations to complete this analysis.

::: {.callout-warning}
When using `osmdata` to retrieve train stations in London, be aware that OpenStreetMap data may be incomplete or inconsistent due to different tagging practices by contributors, missing or outdated entries, and variations in how stations are classified. While verifying every detail is beyond the scope of this practical, it is essential to exercise due diligence when working with real-world data. Where possible triangulate with other authoritative sources such as official transport datasets and at the very least perform sanity checks to identify obvious anomalies. 
:::

### Spatial queries
A spatial query is used to retrieve data based on its geographic location or spatial relationships. It uses spatial information from one or more layers to find features that meet specific criteria, such as proximity, intersection, or containment. For instance, we can use a spatial query to count all the bicycle thefts that have occurred within 500 metres of a train or underground station:

```{r}
#| label: 02-spatial-query-1
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# create a single station geometry
osm_stations_comb <- osm_stations |>
    st_union()

# spatial query
theft_bike$d500 <- theft_bike |>
    st_is_within_distance(osm_stations_comb, dist = 500, sparse = FALSE)

# inspect
head(theft_bike)
```

::: {.callout-warning}
The above code converts the stations dataframe into a single geometry. This step is essential for `sf` to ensure that each point in the dataset is compared to every point in the stations dataframe. Without this conversion, the comparison would be done one station point at a time, storing only the last result rather than considering all station points simultaneously.
:::

We can use the `count()` function to find out just how many thefts fall in each of these categories:

```{r}
#| label: 02-spatial-query-2
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# number of bicycle thefts within 500m of a station
count(theft_bike, d500)
```

More than two-thirds of all reported bicycle thefts in London occur within 500 metres of a train or underground station. Of course, we can map the results for a visual inspection:

```{r tidy='styler'} 
#| label: fig-02-theft-map-500m
#| fig-cap: Reported bicycle thefts in London within 500 metres from a train or underground station.
#| classes: styled-output
#| echo: True
#| eval: True
#| filename: 'R code'

# classify distances
theft_bike <- theft_bike |>
  mutate(dist_class = if_else(d500 == TRUE, '> 500 m', '< 500 m')) |>
  mutate(dist_class = factor(dist_class, levels = c('> 500 m', '< 500 m')))

# shape
tm_shape(outline) +
  
# map data
tm_polygons(
  fill = '#f0f0f0',
  col = NA
) +
  
# shape
tm_shape(theft_bike) + 

# map data
tm_symbols(
  
  # map data
  col = 'dist_class',
  size = 0.1,
  col.scale = tm_scale_categorical(
    values = c('> 500 m' = '#fdc086',
               '< 500 m' = '#998ec3'),
  ),
  
  # legend 
  col.legend = tm_legend(
    title = '',
    frame = FALSE,
  ) 
) +
  
# shape
tm_shape(osm_stations) + 
  
# map data
tm_symbols(
  size = 0.2,
  fill = '#636363',
  col = '#636363',
) +

# legend
tm_add_legend(
  type = 'symbols',
  labels = 'Station',
  size = 0.2,
  fill = '#636363'
) +

# layout
tm_layout(
  
  # legend
  legend.outside = FALSE,
  legend.position = c(0.0, 0.2),
  legend.text.size = 0.8,
  
  # canvas
  frame = FALSE
)

```

### Geometric operations
Geometric operations are used to manipulate and analyse the shapes and spatial properties of geometric objects, such as points, lines, and polygons. These operations include tasks like calculating intersections, buffering, and determining the distance between shapes. In this case, we can create 500-metre buffers around each station and then count how many bicycle thefts fall within these buffers.

```{r}
#| label: 02-spatial-buffer
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: 'R code'
# buffer
osm_stations_buffer <- osm_stations |> 
  st_buffer(dist = 500) |> 
  st_union()

# inspect
head(osm_stations_buffer)
```

::: {.callout-tip}
When performing buffer analysis, the buffer sizes are determined by the units of the coordinate reference system (CRS) used. For instance, with the British National Grid, where the CRS is in metres, the buffer distance must be specified in metres.
:::

We can map the results for a visual inspection:

```{r tidy='styler'} 
#| label: fig-02-buffer-map
#| fig-cap: Train and underground stations in London with a 500 metres buffer.
#| classes: styled-output
#| echo: True
#| eval: True
#| filename: 'R code'
# shape
tm_shape(outline) +
  
# map data
tm_polygons(
  fill = '#f0f0f0',
  col = NA
) +
  
# shape
tm_shape(osm_stations_buffer) + 

  # specify colours
  tm_polygons(
    fill = '#beaed4',
  ) +
  
# layout
tm_layout(
 
  # canvas
  frame = FALSE
)
```

We can now use the `st_intersects` function to find out which reported bicycle thefts have occurred within 500 metres of a train or underground station.

```{r}
#| label: 02-intersect-buffer
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| message: False
#| filename: 'R code'
# intersect buffer with bicycle thefts
theft_bike$d500_buffer <- theft_bike |> st_intersects(osm_stations_buffer, sparse = FALSE)

# number of bicycle thefts within 500m of a station
count(theft_bike, d500_buffer)
```

::: {.callout-important}
The results are almost identical, with a small difference due to how the two methods define within and handle spatial relationships and boundaries. For instance, a point on the buffer's edge will be included in the intersect method, but may not meet the distance threshold required by `st_within_distance()`.
:::

## Assignment 
Now that we are familiar with basic spatial queries and geometric operations, we can conduct a similar analysis on the number of *serious* and *fatal* road crashed in London in 2022 and determine how many occurred on or near a main road. Try to do the following:

1. Download the two datasets provided below and save them in the appropriate subfolder within your `data` directory. The datasets include:
    * A `csv` file containing the number of road crashes that occurred in London in 2022, extracted from the UK's official road traffic casualty database using the [stats19](https://github.com/ropensci/stats19) R library.
    * A `GeoPackage` file that contains main roads in London, extracted from the [Ordnance Survey Open Roads](https://www.ordnancesurvey.co.uk/products/os-open-roads) dataset.
2. Calculate the number of *serious* and *fatal* road crashes that occurred within 100 metres and 500 metres of a main road.

| File                                        | Type   | Link |
| :------                                     | :------| :------ |
| London STATS19 Road Collisions 2022         | `csv` | [Download](https://github.com/jtvandijk/GEOG0030/tree/master/data/attributes/London-Collisions-2022.csv) |
| London OS Open Roads - Main Roads           | `GeoPackage` | [Download](https://github.com/jtvandijk/GEOG0030/raw/refs/heads/master/data/spatial/London-Open-Roads-Main.gpkg) |

## Before you leave
Boom. That is how you can conduct basic spatial queries and geometric operations and using R and `sf`. Yet more RGIS coming over the next couple of weeks, but [this concludes the tutorial for this week](https://www.youtube.com/watch?v=Xyt810Ahbxk). Time to check out that reading list?