[
  {
    "objectID": "11-data.html",
    "href": "11-data.html",
    "title": "1 Data Sources",
    "section": "",
    "text": "Below is a list of resources that you may find helpful when sourcing data for your coursework or dissertation. This list is not exhaustive but includes some recommended websites to get you started.\n\n\nThe following websites contain Open Data or link to Open Data from several respectable data providers:\n\nAfricanUrbanNetwork\nAirBnB Data\nBike Docking Data (ready for R)\nBing Maps worldwide road detections\nCamden Air Action\nConsumer Data Research Centre\nDepartment for Environment, Food & Rural Affairs\nEdina (e.g. OS mastermap)\nEU Tourism Data\nEurostat\nGeofabrik (OSM data)\nGeolytix Supermarket Retail Points\nGlobal Urban Areas dataset\nGlobal Weather Data\nGoogle Dataset Search\nGoogle Open Buildings\nKaggle Public Datasets\nKing’s College Data on Air Pollution\nLondon Data Store\nLondon Local Authority Maintained Trees\nLondon Tube PM2.5 Levels\nMicrosoft Global Building Footprints\nMicrosoft Research Open Data\nNational Public Transport Access Nodes (NaPTAN)\nNASA EARTHDATA\nNASA SocioEconomic Data and Applications Center (SEDAC)\nNHS Data (ready for R)\nnomis Official Census and Labour Market Statistics\nOffice for National Statistics Geoportal\nOffice for National Statistics\nOpen Topography\nOverture Point of Interest data for the United Kingdom\nPlanetary Computer Data Catalog\npseudo Census Output Areas 2001-2011-2021\nPublic transport accessibility indicators Great Britain\nTesco Store Data (London)\nTfL Cycling Data\nTfL Open Data\nTidy Tuesday Data (not exclusively spatial data)\nUK Data Service\nUS Census Data\nUS City Open Data Census\nUSGS Earth Explorer\nUTD19 Multi-City Traffic Dataset\nWorldPop GitHub\nWorldPop\n\n\n\n\nUndergraduate students can also apply for Safeguarded datasets held by the Geographic Data Service. Accessing these datasets requires following a specific process, which is outlined on the GeoDS website. When applying, you will need to explain why you require the specific dataset and describe how you intend to use it. Additionally, consider the ethical implications of using the data, as this will be an important part of your application. Please be aware that it normally takes 4-5 weeks for your application to be processed.\nSome of the datasets held by the GeoDS that you can apply for are:\n\nBicycle Sharing System Docking Station Observations\nModelled Ethnicity Proportions - LSOA Geography\nFCA Financial Lives Survey\nSalad Money Daily Transaction Volumes and Values\n\n\n\n\n\n\n\nSince the application process for Safeguarded GeoDS datasets can take several weeks, these datasets may be more suitable for your undergraduate dissertation rather than the GEOG0030 coursework assignment. However, CDRC datasets labeled as Open Data do not require an application process. You can download these datasets directly after registering on the website."
  },
  {
    "objectID": "11-data.html#open-data",
    "href": "11-data.html#open-data",
    "title": "1 Data Sources",
    "section": "",
    "text": "The following websites contain Open Data or link to Open Data from several respectable data providers:\n\nAfricanUrbanNetwork\nAirBnB Data\nBike Docking Data (ready for R)\nBing Maps worldwide road detections\nCamden Air Action\nConsumer Data Research Centre\nDepartment for Environment, Food & Rural Affairs\nEdina (e.g. OS mastermap)\nEU Tourism Data\nEurostat\nGeofabrik (OSM data)\nGeolytix Supermarket Retail Points\nGlobal Urban Areas dataset\nGlobal Weather Data\nGoogle Dataset Search\nGoogle Open Buildings\nKaggle Public Datasets\nKing’s College Data on Air Pollution\nLondon Data Store\nLondon Local Authority Maintained Trees\nLondon Tube PM2.5 Levels\nMicrosoft Global Building Footprints\nMicrosoft Research Open Data\nNational Public Transport Access Nodes (NaPTAN)\nNASA EARTHDATA\nNASA SocioEconomic Data and Applications Center (SEDAC)\nNHS Data (ready for R)\nnomis Official Census and Labour Market Statistics\nOffice for National Statistics Geoportal\nOffice for National Statistics\nOpen Topography\nOverture Point of Interest data for the United Kingdom\nPlanetary Computer Data Catalog\npseudo Census Output Areas 2001-2011-2021\nPublic transport accessibility indicators Great Britain\nTesco Store Data (London)\nTfL Cycling Data\nTfL Open Data\nTidy Tuesday Data (not exclusively spatial data)\nUK Data Service\nUS Census Data\nUS City Open Data Census\nUSGS Earth Explorer\nUTD19 Multi-City Traffic Dataset\nWorldPop GitHub\nWorldPop"
  },
  {
    "objectID": "11-data.html#safeguarded-data",
    "href": "11-data.html#safeguarded-data",
    "title": "1 Data Sources",
    "section": "",
    "text": "Undergraduate students can also apply for Safeguarded datasets held by the Geographic Data Service. Accessing these datasets requires following a specific process, which is outlined on the GeoDS website. When applying, you will need to explain why you require the specific dataset and describe how you intend to use it. Additionally, consider the ethical implications of using the data, as this will be an important part of your application. Please be aware that it normally takes 4-5 weeks for your application to be processed.\nSome of the datasets held by the GeoDS that you can apply for are:\n\nBicycle Sharing System Docking Station Observations\nModelled Ethnicity Proportions - LSOA Geography\nFCA Financial Lives Survey\nSalad Money Daily Transaction Volumes and Values\n\n\n\n\n\n\n\nSince the application process for Safeguarded GeoDS datasets can take several weeks, these datasets may be more suitable for your undergraduate dissertation rather than the GEOG0030 coursework assignment. However, CDRC datasets labeled as Open Data do not require an application process. You can download these datasets directly after registering on the website."
  },
  {
    "objectID": "01-spatial.html",
    "href": "01-spatial.html",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "This week’s lecture offered a comprehensive introduction to the Geocomputation module, highlighting how and why it differs from a traditional GIScience course. In this week’s tutorial, we will introduce you to using R and RStudio for working with spatial data, focusing specifically on how R can be used to make maps.\n\n\nYou can download the slides of this week’s lecture here: [Link].\n\n\n\n\n\n\nBrunsdon, C. and Comber, A. 2021. Opening practice: Supporting reproducibility and critical spatial data science. Journal of Geographical Systems 23: 477–496. [Link]\nFranklin, R. 2023. Quantitative methods III: Strength in numbers? Progress in Human Geography. Online First. [Link].\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 1: Geographic Information: Science, Systems, and Society, pp. 1-32. [Link]\n\n\n\n\n\nGoodchild, M. 2009. Geographic information systems and science: Today and tomorrow. Annals of GIS 15(1): 3-9. [Link]\nFranklin, S., Houlden, V., Robinson, C. et al. 2021. Who counts? Gender, Gatekeeping, and Quantitative Human Geography. The Professional Geographer 73(1): 48-61. [Link]\nSchurr, C., Müller, M. and Imhof, N. 2020. Who makes geographical knowledge? The gender of Geography’s gatekeepers. The Professional Geographer 72(3): 317-331. [Link]\nYuan, M. 2001. Representing complex geographic phenomena in GIS. Cartography and Geographic Information Science 28(2): 83-96. [Link]\n\n\n\n\n\nIn RStudio, scripts allow us to build and save code that can be run repeatedly. We can organise these scripts into RStudio projects, which consolidate all files related to an analysis such as input data, R scripts, results, figures, and more. This organisation helps keep track of all data, input, and output, while enabling us to create standalone scripts for each part of our analysis.\nNavigate to File -&gt; New Project -&gt; New Directory. Choose a directory name, such as GEOG0030, and select the location on your computer where you want to save this project by clicking on Browse…. Click on Create Project.\n\n\n\n\n\n\nEnsure you select an appropriate folder to store your GEOG0030 project. For example, you might use your Geocomputation folder, if you have one, or another location within your Documents directory on your computer.\n\n\n\n\n\n\n\n\n\nPlease ensure that folder names and file names do not contain spaces or special characters such as * . \" / \\ [ ] : ; | = , &lt; ? &gt; & $ # ! ' { } ( ). Different operating systems and programming languages deal differently with spaces and special characters and as such including these in your folder names and file names can cause many problems and unexpected errors. As an alternative to using white space you can use an underscore (_) or hyphen (-) if you like.\n\n\n\nYou should now see your main RStudio window switch to this new project and when you check your files pane, you should see a new R Project called GEOG0030.\nWith our GEOG0030 project ready to go, in this first tutorial we will look at the distribution of the share of European immigrants across London. The data covers the number of people residing in London that are born in a European country, as recorded in the 2021 Census for England and Wales, aggregated at the Middle Layer Super Output Area (MSOA) level.\n\n\n\n\n\n\nAn MSOA is a geographic unit used in the UK for statistical analysis. It typically represents small areas with populations of around 5,000 to 15,000 people and is designed to ensure consistent data reporting. MSOAs are commonly used to report on census data, deprivation indices, and other socio-economic statistics.\n\n\n\nThe dataset has been extracted using the Custom Dataset Tool, and you can download the file via the link provided below. Save the file in your project folder under data/attributes. Along with this dataset, we also have access to a GeoPackage that contains the MSOA boundaries. Save this file under data/spatial, respectively.\n\n\n\n\n\n\nYou will to have create a folder named data within your RStudio Project directory, inside which you will have to have a folder named attributes and a folder named spatial.\n\n\n\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon MSOA Census 2021 European Population\ncsv\nDownload\n\n\nLondon MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\n\n\n\n\nTo download a csv file that is hosted on GitHub, click on the Download raw file button on the top right of your screen and it should download directly to your computer.\n\n\n\n\n\n\n\n\n\nYou may have used spatial data before and noticed that we did not download a collection of files known as a shapefile but a GeoPackage instead. Whilst shapefiles are still being used, GeoPackage is a more modern and portable file format. Have a look at this article on towardsdatascience.com for an excellent explanation on why one should use GeoPackage files over shapefiles where possible: [Link]\n\n\n\nTo get started, let us create our first script. File -&gt; New File -&gt; R Script. Save your script as w01-european-population-london.r.\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\n\n\n\n\n\n\nFor Linux and macOS users who are new to working with spatial data in R, the installation of the sf library may fail because additional (non-R) libraries are required which are automatically installed for Windows users. If you encounter installation issues,, please refer to the information pages of the sf library for instructions on how to install these additional libraries.\n\n\n\nOnce downloaded, we can load both files into memory:\n\n\n\nR code\n\n# read spatial dataset\nmsoa21 &lt;- st_read(\"data/spatial/London-MSOA-2021.gpkg\")\n\n\nReading layer `London-MSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-MSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1002 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# load attribute dataset\nmsoa_eur &lt;- read_csv(\"data/attributes/London-MSOA-European.csv\")\n\nRows: 1002 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): msoa21cd\ndbl (2): eur21, pop21\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# inspect\nhead(msoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid                           geom\n1 {71249043-B176-4306-BA6C-D1A993B1B741} MULTIPOLYGON (((532135.1 18...\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E} MULTIPOLYGON (((548881.6 19...\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B} MULTIPOLYGON (((549102.4 18...\n4 {511181CD-E71F-4C63-81EE-E8E76744A627} MULTIPOLYGON (((551550.1 18...\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87} MULTIPOLYGON (((549099.6 18...\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1} MULTIPOLYGON (((549819.9 18...\n\n# inspect\nhead(msoa_eur)\n\n# A tibble: 6 × 3\n  msoa21cd  eur21 pop21\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 E02000001  1926  8582\n2 E02000002  1102  8280\n3 E02000003  1930 11542\n4 E02000004   808  6640\n5 E02000005  1541 11082\n6 E02000007  1365 10159\n\n\n\n\n\n\n\n\nYou can further inspect both objects using the View() function.\n\n\n\n\n\nThe first thing we want to do when we load spatial data is to plot the data to check whether everything is in order. To do this, we can simply use the base R plot() function\n\n\n\nR code\n\n# plot data\nplot(msoa21, max.plot = 1, main = \"\")\n\n\n\n\n\nFigure 1: Quick plot to inspect the MSOA spatial data.\n\n\n\n\nYou should see your msoa21 plot appear in your Plots window.\n\n\n\n\n\n\nThe plot() function should not to be used to make publishable maps but can be used as a quick way of inspecting your spatial data.\n\n\n\nJust as with a tabular dataframe, we can inspect the attributes of the spatial data frame:\n\n\n\nR code\n\n# inspect columns\nncol(msoa21)\n\n\n[1] 9\n\n# inspect rows\nnrow(msoa21)\n\n[1] 1002\n\n# inspect data\nhead(msoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid                           geom\n1 {71249043-B176-4306-BA6C-D1A993B1B741} MULTIPOLYGON (((532135.1 18...\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E} MULTIPOLYGON (((548881.6 19...\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B} MULTIPOLYGON (((549102.4 18...\n4 {511181CD-E71F-4C63-81EE-E8E76744A627} MULTIPOLYGON (((551550.1 18...\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87} MULTIPOLYGON (((549099.6 18...\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1} MULTIPOLYGON (((549819.9 18...\n\n# inspect column names\nnames(msoa21)\n\n[1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n[7] \"long\"      \"globalid\"  \"geom\"     \n\n\nWe can further establish the class of our data:\n\n\n\nR code\n\n# inspect\nclass(msoa21)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nWe should see our data is an sf dataframe, which is what we want.\n\n\n\nNow we have our dataset containing London’s European born population and the MSOA spatial boundaries loaded, we can join these together using an Attribute Join. Before proceeding with the join, we need to verify that a matching unique identifier exists in both datasets. Let’s look at the column names in our datasets again:\n\n\n\nR code\n\n# inspect column names\nnames(msoa21)\n\n\n[1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n[7] \"long\"      \"globalid\"  \"geom\"     \n\n# inspect column names\nnames(msoa_eur)\n\n[1] \"msoa21cd\" \"eur21\"    \"pop21\"   \n\n\nThe msoa21cd columns looks promising as it features in both datasets. We can quickly sort both columns and have a peek at the data:\n\n\n\nR code\n\n# inspect spatial dataset\nhead(sort(msoa21$msoa21cd))\n\n\n[1] \"E02000001\" \"E02000002\" \"E02000003\" \"E02000004\" \"E02000005\" \"E02000007\"\n\n# inspect attribute dataset\nhead(sort(msoa_eur$msoa21cd))\n\n[1] \"E02000001\" \"E02000002\" \"E02000003\" \"E02000004\" \"E02000005\" \"E02000007\"\n\n\nThey seem to contain similar values, so that is promising. Let us try to join the attribute data onto the spatial data:\n\n\n\nR code\n\n# join attribute data onto spatial data\nmsoa21 &lt;- msoa21 |&gt; \n  left_join(msoa_eur, by = c('msoa21cd' = 'msoa21cd'))\n\n\n\n\n\n\n\n\nThe code above uses a pipe function: |&gt;. The pipe operator allows you to pass the output of one function directly into the next, streamlining your code. While it might be a bit confusing at first, you will find that it makes your code faster to write and easier to read. More importantly, it reduces the need to create multiple intermediate variables to store outputs.\n\n\n\nWe can explore the joined data in usual fashion:\n\n\n\nR code\n\n# inspect columns\nncol(msoa21)\n\n\n[1] 11\n\n# inspect rows\nnrow(msoa21)\n\n[1] 1002\n\n# inspect data\nhead(msoa21)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid eur21 pop21\n1 {71249043-B176-4306-BA6C-D1A993B1B741}  1926  8582\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E}  1102  8280\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B}  1930 11542\n4 {511181CD-E71F-4C63-81EE-E8E76744A627}   808  6640\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87}  1541 11082\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1}  1365 10159\n                            geom\n1 MULTIPOLYGON (((532135.1 18...\n2 MULTIPOLYGON (((548881.6 19...\n3 MULTIPOLYGON (((549102.4 18...\n4 MULTIPOLYGON (((551550.1 18...\n5 MULTIPOLYGON (((549099.6 18...\n6 MULTIPOLYGON (((549819.9 18...\n\n# inspect column names\nnames(msoa21)\n\n [1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n [7] \"long\"      \"globalid\"  \"eur21\"     \"pop21\"     \"geom\"     \n\n\nAlways inspect your join to ensure everything looks as expected. A good way to do this is by using the View() function to check for any unexpected missing values, which are marked as NA.\nWe can also compare the total number of rows in the spatial dataset with the total number of non-NA values in the joined columns:\n\n\n\nR code\n\n# inspect\nnrow(msoa21)\n\n\n[1] 1002\n\n# check for missing values\nsum(!is.na(msoa21$eur21))\n\n[1] 1002\n\n# check for missing values\nsum(!is.na(msoa21$pop21))\n\n[1] 1002\n\n\nNo missing values. In this case we did not expect any missing values, so this confirms that all our full attribute dataset has been linked to the spatial dataset.\nWe are almost ready to map the data. Only thing that is left is for us to calculate the share of European-born immigrants within each MSOA:\n\n\n\nR code\n\n# calculate proportion\nmsoa21 &lt;- msoa21 |&gt;\n    mutate(prop_eur21 = eur21/pop21)\n\n\n\n\n\nFor our map-making, we will use one of the two primary visualisation libraries for spatial data: tmap. tmap offers a flexible, layer-based approach that makes it easy to create various types of thematic maps, such as choropleths and proportional symbol maps. One of the standout features of tmap is its quick plotting function, qtm(), which allows you to generate basic maps with minimal effort.\n\n\n\nR code\n\n# quick thematic map\nqtm(msoa21, fill = \"prop_eur21\")\n\n\n\n\n\nFigure 2: Quick thematic map.\n\n\n\n\nIn this case, the fill() argument in tmap is how we instruct the library to create a choropleth map based on the values in the specified column. If we set fill() to NULL, only the borders of our polygons will be drawn, without any colour fill. The qtm() function in tmap is versatile, allowing us to pass various parameters to customise the aesthetics of our map. By checking the function’s documentation, you can explore the full list of available parameters. For instance, to set the MSOA borders to white, we can use the borders parameter:\n\n\n\nR code\n\n# quick thematic map\nqtm(msoa21, fill = \"prop_eur21\", col = \"white\")\n\n\n\n\n\nFigure 3: Quick thematic map with white borders.\n\n\n\n\nThe map does not look quite right yet. While we can continue tweaking parameters in the qtm() function to improve it, qtm() is somewhat limited in its functionality and is primarily intended for quickly inspecting your data and creating basic maps. For more complex and refined map-making with the tmap library, it is better to use the main plotting method that starts with the tm_shape() function.\n\n\n\n\n\n\nThe primary approach to creating maps in tmap involves using a layered grammar of graphics to build up your map, starting with the tm_shape() function. This function, when provided with a spatial dataframe, captures the spatial information of your data, including its projection and geometry, and creates a spatial object. While you can override certain aspects of the spatial data (such as its projection) using the function’s parameters, the essential role of tm_shape() is to instruct R to “use this object as the basis for drawing the shapes.”\nTo actually render the shapes, you need to add a layer that specifies the type of shape you want R to draw from this spatial information — such as polygons for our data. This layer function tells R to “draw my spatial object as X”, where X represents the type of shape. Within this layer, you can also provide additional details to control how R draws your shapes. Further, you can add more layers to include other spatial objects and their corresponding shapes on your map. Finally, layout options can be specified through a layout layer, allowing you to customise the overall appearance and arrangement of your map.\n\n\n\nLet us build a map using tmap:\n\n\n\nR code\n\n# shape, polygons\ntm_shape(msoa21) +\n  tm_polygons()\n\n\n\n\n\nFigure 4: Building up a map layer by layer.\n\n\n\n\nAs you can now see, we have mapped the spatial polygons of our msoa21 spatial dataframe. However, this is not quite the map we want; we need a choropleth map where the polygons are coloured based on the proportion of European immigrants. To achieve this, we use the col parameter within the tm_polygons() function.\n\n\n\n\n\n\nThe fill parameter within tm_polygons() allows you to fill polygons with colours based on:\n\nA single colour value (e.g. red or #fc9272).\nThe name of a data variable within the spatial data file. This variable can either contain specific colour values or numeric/categorical values that will be mapped to a colour palette.\n\n\n\n\nLet us go ahead and pass our prop_eur21 variable within the fill() parameter and see what we get:\n\n\n\nR code\n\n# shape, polygons\ntm_shape(msoa21) +\n  # specify column\n  tm_polygons(\n    fill = \"prop_eur21\"\n  )\n\n\n\n\n\nFigure 5: Building up a map layer by layer.\n\n\n\n\nWe are making progress, but there are two immediate issues with our map. First, the classification breaks do not adequately reflect the variation in our dataset. By default, tmap uses pretty breaks, which may not be the most effective for our data. An alternative, such as natural breaks (or jenks), might better reveal the data’s variation.\nTo customise the classification breaks, refer to the tm_polygons() documentation. The following parameters are relevant:\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\nfill.scale\nDefines the color scale for polygon fills. Accepts a scale object created by functions such as tm_scale_continuous() and tm_intervals()\n\n\ntm_scale_continuous()\nCreates a continuous scale object for mapping numeric values to colours. You can specify options such as palette (color scheme) and limits (data range).\n\n\ntm_scale_intervals()\nCreates a scale object for mapping data into discrete classes (intervals). Parameters include: n (number of classes) and style (classification method: e.g. quantile, equal, jenks)\n\n\n\nFor example, if we want to adjust our choropleth map to use five classes determined by the natural breaks method, we need to specify the n and style parameters as follows:\n\n\n\nR code\n\n# shape, polygons\ntm_shape(msoa21) +\n  # specify column, classes\n  tm_polygons(\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(n = 5, style = \"jenks\"),\n  )\n\n\n\n\n\nFigure 6: Building up a map layer by layer.\n\n\n\n\n\n\n\n\nStyling a map in tmap requires a deeper understanding and familiarity with the library, which is something you will develop best through hands-on practice. Here are the key functions to be aware of:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\ntm_layout()\nCustomises overall map layout, including titles, fonts, legend position, margins, and frame settings.\n\n\ntm_compass()\nAdds a compass or North arrow to the map, with options for size, position, and style.\n\n\ntm_scale_bar()\nAdds a scale bar to indicate distance, with options for units, position, and styling.\n\n\n\nTo begin styling your map, explore each of these functions and their parameters. Through trial and error, you can tweak and refine the map until you achieve the desired look:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # specify column, classes, labels\n  tm_polygons(\n    # map data\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(\n      n = 5, style = \"jenks\",\n      values = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n      labels = c(\"Smallest share\", \"2nd smallest\", \"3rd smallest\", \"4th smallest\", \"Largest share\"),\n    ),\n\n    # legend\n    fill.legend = tm_legend(\n      title = \"Share of population\",\n      na.text = \"No population\",\n      frame = FALSE,\n    ),\n\n    # borders\n    col = \"#ffffff\",\n    col_alpha = 0.3\n  ) +\n\n  # title\n  tm_title(\n    text = \"Share of population born in Europe\"\n  ) +\n\n  # layout configuration\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.90, 1.00),\n    legend.title.size = 0.7,\n    legend.title.fontface = \"bold\",\n    legend.text.size = 0.55,\n\n    # canvas\n    inner.margins = c(0.05, 0.05, 0.05, 0.05),\n    frame = FALSE,\n  ) +\n\n  # North arrow\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"left\", \"top\"),\n    size = 1,\n    text.size = 0.7\n  ) +\n\n  # scale bar\n  tm_scalebar(\n    breaks = c(0, 5, 10, 15, 20),\n    position = c(0.85, 0.20),\n    text.size = 0.4\n  )\n\n\n\n\n\nFigure 7: Building up a map layer by layer.\n\n\n\n\nWe can also have some map labels, if we want, by extracting centroids from selected polygons and adding these as separate map layer:\n\n\n\nR code\n\n# map labels\nlab &lt;- msoa21 |&gt;\n  filter(msoa21cd == \"E02000642\" | msoa21cd == \"E02000180\") |&gt;\n  st_centroid()\n\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n# map object\nlon_eurpop &lt;-\n  # shape\n  tm_shape(msoa21) +\n\n  # specify column, classes, labels\n  tm_polygons(\n    # map data\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(\n      n = 5, style = \"jenks\",\n      values = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n      labels = c(\"Smallest share\", \"2nd smallest\", \"3rd smallest\", \"4th smallest\", \"Largest share\"),\n    ),\n\n    # legend\n    fill.legend = tm_legend(\n      title = \"Share of population\",\n      na.text = \"No population\",\n      frame = FALSE,\n    ),\n\n    # borders\n    col = \"#ffffff\",\n    col_alpha = 0.3\n  ) +\n\n  # shape\n  tm_shape(lab) +\n\n  # centroids\n  tm_symbols(\n    size = 0.4,\n    fill = \"#000000\"\n  ) +\n\n  # labels\n  tm_text(\n    text = \"msoa21nm\",\n    col = \"#000000\",\n    size = 0.8,\n    xmod = 0,\n    ymod = -0.6\n  ) +\n\n  # title\n  tm_title(\n    text = \"Share of population born in Europe\"\n  ) +\n\n  # layout configuration\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.90, 1.00),\n    legend.title.size = 0.7,\n    legend.title.fontface = \"bold\",\n    legend.text.size = 0.55,\n\n    # canvas\n    inner.margins = c(0.05, 0.05, 0.05, 0.05),\n    frame = FALSE,\n  ) +\n\n  # North arrow\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"left\", \"top\"),\n    size = 1,\n    text.size = 0.7\n  ) +\n\n  # scale bar\n  tm_scalebar(\n    breaks = c(0, 5, 10, 15, 20),\n    position = c(0.85, 0.20),\n    text.size = 0.4\n  )\n\n# plot\nlon_eurpop\n\n\n\n\nFigure 8: Building up a map layer by layer.\n\n\n\n\nIn the code above, we stored the full map definition as an object. This makes it easy to export the map and save it as a .jpg, .png or .pdf file:\n\n\n\nR code\n\n# write map\ntmap_save(tm = lon_eurpop, filename = \"london-european-population.jpg\", width = 15,\n    height = 15, units = c(\"cm\"))\n\n\n\n\n\nNow that we have prepared our dataset and created our initial maps in R, we can also try and map the distribution of the proportion of European immigrants across Wales and experiment with different mapping parameters. Follow these steps:\n\nDownload the two datasets provided below and save them in the appropriate subfolder within your data directory. The datasets include:\n\nA csv file containing the number of people residing in Wales that are born in a European country, as recorded in the 2021 Census for England and Wales, aggregated at the MSOA level.\nA GeoPackage file containing the 2021 MSOA spatial boundaries for England and Wales.\n\nLoad both datasets and merge them together. Make sure to only retain those MSOAs that belong to Wales.\nCreate a map that shows the proportion of the population residing in Wales that is born in Europe.\nExperiment by adjusting various map parameters, such as the colour scheme, map labels, and data classification method.\n\n\n\n\nFile\nType\nLink\n\n\n\n\nWales MSOA Census 2021 European Population\ncsv\nDownload\n\n\nEngland and Wales MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\n\nAnd that is how you use R as a GIS in its most basic form. More RGIS in the coming weeks, but this concludes the tutorial for this week."
  },
  {
    "objectID": "01-spatial.html#lecture-slides",
    "href": "01-spatial.html#lecture-slides",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "You can download the slides of this week’s lecture here: [Link]."
  },
  {
    "objectID": "01-spatial.html#reading-list",
    "href": "01-spatial.html#reading-list",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "Brunsdon, C. and Comber, A. 2021. Opening practice: Supporting reproducibility and critical spatial data science. Journal of Geographical Systems 23: 477–496. [Link]\nFranklin, R. 2023. Quantitative methods III: Strength in numbers? Progress in Human Geography. Online First. [Link].\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 1: Geographic Information: Science, Systems, and Society, pp. 1-32. [Link]\n\n\n\n\n\nGoodchild, M. 2009. Geographic information systems and science: Today and tomorrow. Annals of GIS 15(1): 3-9. [Link]\nFranklin, S., Houlden, V., Robinson, C. et al. 2021. Who counts? Gender, Gatekeeping, and Quantitative Human Geography. The Professional Geographer 73(1): 48-61. [Link]\nSchurr, C., Müller, M. and Imhof, N. 2020. Who makes geographical knowledge? The gender of Geography’s gatekeepers. The Professional Geographer 72(3): 317-331. [Link]\nYuan, M. 2001. Representing complex geographic phenomena in GIS. Cartography and Geographic Information Science 28(2): 83-96. [Link]"
  },
  {
    "objectID": "01-spatial.html#europeans-in-london",
    "href": "01-spatial.html#europeans-in-london",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "In RStudio, scripts allow us to build and save code that can be run repeatedly. We can organise these scripts into RStudio projects, which consolidate all files related to an analysis such as input data, R scripts, results, figures, and more. This organisation helps keep track of all data, input, and output, while enabling us to create standalone scripts for each part of our analysis.\nNavigate to File -&gt; New Project -&gt; New Directory. Choose a directory name, such as GEOG0030, and select the location on your computer where you want to save this project by clicking on Browse…. Click on Create Project.\n\n\n\n\n\n\nEnsure you select an appropriate folder to store your GEOG0030 project. For example, you might use your Geocomputation folder, if you have one, or another location within your Documents directory on your computer.\n\n\n\n\n\n\n\n\n\nPlease ensure that folder names and file names do not contain spaces or special characters such as * . \" / \\ [ ] : ; | = , &lt; ? &gt; & $ # ! ' { } ( ). Different operating systems and programming languages deal differently with spaces and special characters and as such including these in your folder names and file names can cause many problems and unexpected errors. As an alternative to using white space you can use an underscore (_) or hyphen (-) if you like.\n\n\n\nYou should now see your main RStudio window switch to this new project and when you check your files pane, you should see a new R Project called GEOG0030.\nWith our GEOG0030 project ready to go, in this first tutorial we will look at the distribution of the share of European immigrants across London. The data covers the number of people residing in London that are born in a European country, as recorded in the 2021 Census for England and Wales, aggregated at the Middle Layer Super Output Area (MSOA) level.\n\n\n\n\n\n\nAn MSOA is a geographic unit used in the UK for statistical analysis. It typically represents small areas with populations of around 5,000 to 15,000 people and is designed to ensure consistent data reporting. MSOAs are commonly used to report on census data, deprivation indices, and other socio-economic statistics.\n\n\n\nThe dataset has been extracted using the Custom Dataset Tool, and you can download the file via the link provided below. Save the file in your project folder under data/attributes. Along with this dataset, we also have access to a GeoPackage that contains the MSOA boundaries. Save this file under data/spatial, respectively.\n\n\n\n\n\n\nYou will to have create a folder named data within your RStudio Project directory, inside which you will have to have a folder named attributes and a folder named spatial.\n\n\n\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon MSOA Census 2021 European Population\ncsv\nDownload\n\n\nLondon MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\n\n\n\n\nTo download a csv file that is hosted on GitHub, click on the Download raw file button on the top right of your screen and it should download directly to your computer.\n\n\n\n\n\n\n\n\n\nYou may have used spatial data before and noticed that we did not download a collection of files known as a shapefile but a GeoPackage instead. Whilst shapefiles are still being used, GeoPackage is a more modern and portable file format. Have a look at this article on towardsdatascience.com for an excellent explanation on why one should use GeoPackage files over shapefiles where possible: [Link]\n\n\n\nTo get started, let us create our first script. File -&gt; New File -&gt; R Script. Save your script as w01-european-population-london.r.\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\n\n\n\n\n\n\nFor Linux and macOS users who are new to working with spatial data in R, the installation of the sf library may fail because additional (non-R) libraries are required which are automatically installed for Windows users. If you encounter installation issues,, please refer to the information pages of the sf library for instructions on how to install these additional libraries.\n\n\n\nOnce downloaded, we can load both files into memory:\n\n\n\nR code\n\n# read spatial dataset\nmsoa21 &lt;- st_read(\"data/spatial/London-MSOA-2021.gpkg\")\n\n\nReading layer `London-MSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-MSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1002 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# load attribute dataset\nmsoa_eur &lt;- read_csv(\"data/attributes/London-MSOA-European.csv\")\n\nRows: 1002 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): msoa21cd\ndbl (2): eur21, pop21\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# inspect\nhead(msoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid                           geom\n1 {71249043-B176-4306-BA6C-D1A993B1B741} MULTIPOLYGON (((532135.1 18...\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E} MULTIPOLYGON (((548881.6 19...\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B} MULTIPOLYGON (((549102.4 18...\n4 {511181CD-E71F-4C63-81EE-E8E76744A627} MULTIPOLYGON (((551550.1 18...\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87} MULTIPOLYGON (((549099.6 18...\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1} MULTIPOLYGON (((549819.9 18...\n\n# inspect\nhead(msoa_eur)\n\n# A tibble: 6 × 3\n  msoa21cd  eur21 pop21\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 E02000001  1926  8582\n2 E02000002  1102  8280\n3 E02000003  1930 11542\n4 E02000004   808  6640\n5 E02000005  1541 11082\n6 E02000007  1365 10159\n\n\n\n\n\n\n\n\nYou can further inspect both objects using the View() function.\n\n\n\n\n\nThe first thing we want to do when we load spatial data is to plot the data to check whether everything is in order. To do this, we can simply use the base R plot() function\n\n\n\nR code\n\n# plot data\nplot(msoa21, max.plot = 1, main = \"\")\n\n\n\n\n\nFigure 1: Quick plot to inspect the MSOA spatial data.\n\n\n\n\nYou should see your msoa21 plot appear in your Plots window.\n\n\n\n\n\n\nThe plot() function should not to be used to make publishable maps but can be used as a quick way of inspecting your spatial data.\n\n\n\nJust as with a tabular dataframe, we can inspect the attributes of the spatial data frame:\n\n\n\nR code\n\n# inspect columns\nncol(msoa21)\n\n\n[1] 9\n\n# inspect rows\nnrow(msoa21)\n\n[1] 1002\n\n# inspect data\nhead(msoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid                           geom\n1 {71249043-B176-4306-BA6C-D1A993B1B741} MULTIPOLYGON (((532135.1 18...\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E} MULTIPOLYGON (((548881.6 19...\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B} MULTIPOLYGON (((549102.4 18...\n4 {511181CD-E71F-4C63-81EE-E8E76744A627} MULTIPOLYGON (((551550.1 18...\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87} MULTIPOLYGON (((549099.6 18...\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1} MULTIPOLYGON (((549819.9 18...\n\n# inspect column names\nnames(msoa21)\n\n[1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n[7] \"long\"      \"globalid\"  \"geom\"     \n\n\nWe can further establish the class of our data:\n\n\n\nR code\n\n# inspect\nclass(msoa21)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nWe should see our data is an sf dataframe, which is what we want.\n\n\n\nNow we have our dataset containing London’s European born population and the MSOA spatial boundaries loaded, we can join these together using an Attribute Join. Before proceeding with the join, we need to verify that a matching unique identifier exists in both datasets. Let’s look at the column names in our datasets again:\n\n\n\nR code\n\n# inspect column names\nnames(msoa21)\n\n\n[1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n[7] \"long\"      \"globalid\"  \"geom\"     \n\n# inspect column names\nnames(msoa_eur)\n\n[1] \"msoa21cd\" \"eur21\"    \"pop21\"   \n\n\nThe msoa21cd columns looks promising as it features in both datasets. We can quickly sort both columns and have a peek at the data:\n\n\n\nR code\n\n# inspect spatial dataset\nhead(sort(msoa21$msoa21cd))\n\n\n[1] \"E02000001\" \"E02000002\" \"E02000003\" \"E02000004\" \"E02000005\" \"E02000007\"\n\n# inspect attribute dataset\nhead(sort(msoa_eur$msoa21cd))\n\n[1] \"E02000001\" \"E02000002\" \"E02000003\" \"E02000004\" \"E02000005\" \"E02000007\"\n\n\nThey seem to contain similar values, so that is promising. Let us try to join the attribute data onto the spatial data:\n\n\n\nR code\n\n# join attribute data onto spatial data\nmsoa21 &lt;- msoa21 |&gt; \n  left_join(msoa_eur, by = c('msoa21cd' = 'msoa21cd'))\n\n\n\n\n\n\n\n\nThe code above uses a pipe function: |&gt;. The pipe operator allows you to pass the output of one function directly into the next, streamlining your code. While it might be a bit confusing at first, you will find that it makes your code faster to write and easier to read. More importantly, it reduces the need to create multiple intermediate variables to store outputs.\n\n\n\nWe can explore the joined data in usual fashion:\n\n\n\nR code\n\n# inspect columns\nncol(msoa21)\n\n\n[1] 11\n\n# inspect rows\nnrow(msoa21)\n\n[1] 1002\n\n# inspect data\nhead(msoa21)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid eur21 pop21\n1 {71249043-B176-4306-BA6C-D1A993B1B741}  1926  8582\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E}  1102  8280\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B}  1930 11542\n4 {511181CD-E71F-4C63-81EE-E8E76744A627}   808  6640\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87}  1541 11082\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1}  1365 10159\n                            geom\n1 MULTIPOLYGON (((532135.1 18...\n2 MULTIPOLYGON (((548881.6 19...\n3 MULTIPOLYGON (((549102.4 18...\n4 MULTIPOLYGON (((551550.1 18...\n5 MULTIPOLYGON (((549099.6 18...\n6 MULTIPOLYGON (((549819.9 18...\n\n# inspect column names\nnames(msoa21)\n\n [1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n [7] \"long\"      \"globalid\"  \"eur21\"     \"pop21\"     \"geom\"     \n\n\nAlways inspect your join to ensure everything looks as expected. A good way to do this is by using the View() function to check for any unexpected missing values, which are marked as NA.\nWe can also compare the total number of rows in the spatial dataset with the total number of non-NA values in the joined columns:\n\n\n\nR code\n\n# inspect\nnrow(msoa21)\n\n\n[1] 1002\n\n# check for missing values\nsum(!is.na(msoa21$eur21))\n\n[1] 1002\n\n# check for missing values\nsum(!is.na(msoa21$pop21))\n\n[1] 1002\n\n\nNo missing values. In this case we did not expect any missing values, so this confirms that all our full attribute dataset has been linked to the spatial dataset.\nWe are almost ready to map the data. Only thing that is left is for us to calculate the share of European-born immigrants within each MSOA:\n\n\n\nR code\n\n# calculate proportion\nmsoa21 &lt;- msoa21 |&gt;\n    mutate(prop_eur21 = eur21/pop21)\n\n\n\n\n\nFor our map-making, we will use one of the two primary visualisation libraries for spatial data: tmap. tmap offers a flexible, layer-based approach that makes it easy to create various types of thematic maps, such as choropleths and proportional symbol maps. One of the standout features of tmap is its quick plotting function, qtm(), which allows you to generate basic maps with minimal effort.\n\n\n\nR code\n\n# quick thematic map\nqtm(msoa21, fill = \"prop_eur21\")\n\n\n\n\n\nFigure 2: Quick thematic map.\n\n\n\n\nIn this case, the fill() argument in tmap is how we instruct the library to create a choropleth map based on the values in the specified column. If we set fill() to NULL, only the borders of our polygons will be drawn, without any colour fill. The qtm() function in tmap is versatile, allowing us to pass various parameters to customise the aesthetics of our map. By checking the function’s documentation, you can explore the full list of available parameters. For instance, to set the MSOA borders to white, we can use the borders parameter:\n\n\n\nR code\n\n# quick thematic map\nqtm(msoa21, fill = \"prop_eur21\", col = \"white\")\n\n\n\n\n\nFigure 3: Quick thematic map with white borders.\n\n\n\n\nThe map does not look quite right yet. While we can continue tweaking parameters in the qtm() function to improve it, qtm() is somewhat limited in its functionality and is primarily intended for quickly inspecting your data and creating basic maps. For more complex and refined map-making with the tmap library, it is better to use the main plotting method that starts with the tm_shape() function.\n\n\n\n\n\n\nThe primary approach to creating maps in tmap involves using a layered grammar of graphics to build up your map, starting with the tm_shape() function. This function, when provided with a spatial dataframe, captures the spatial information of your data, including its projection and geometry, and creates a spatial object. While you can override certain aspects of the spatial data (such as its projection) using the function’s parameters, the essential role of tm_shape() is to instruct R to “use this object as the basis for drawing the shapes.”\nTo actually render the shapes, you need to add a layer that specifies the type of shape you want R to draw from this spatial information — such as polygons for our data. This layer function tells R to “draw my spatial object as X”, where X represents the type of shape. Within this layer, you can also provide additional details to control how R draws your shapes. Further, you can add more layers to include other spatial objects and their corresponding shapes on your map. Finally, layout options can be specified through a layout layer, allowing you to customise the overall appearance and arrangement of your map.\n\n\n\nLet us build a map using tmap:\n\n\n\nR code\n\n# shape, polygons\ntm_shape(msoa21) +\n  tm_polygons()\n\n\n\n\n\nFigure 4: Building up a map layer by layer.\n\n\n\n\nAs you can now see, we have mapped the spatial polygons of our msoa21 spatial dataframe. However, this is not quite the map we want; we need a choropleth map where the polygons are coloured based on the proportion of European immigrants. To achieve this, we use the col parameter within the tm_polygons() function.\n\n\n\n\n\n\nThe fill parameter within tm_polygons() allows you to fill polygons with colours based on:\n\nA single colour value (e.g. red or #fc9272).\nThe name of a data variable within the spatial data file. This variable can either contain specific colour values or numeric/categorical values that will be mapped to a colour palette.\n\n\n\n\nLet us go ahead and pass our prop_eur21 variable within the fill() parameter and see what we get:\n\n\n\nR code\n\n# shape, polygons\ntm_shape(msoa21) +\n  # specify column\n  tm_polygons(\n    fill = \"prop_eur21\"\n  )\n\n\n\n\n\nFigure 5: Building up a map layer by layer.\n\n\n\n\nWe are making progress, but there are two immediate issues with our map. First, the classification breaks do not adequately reflect the variation in our dataset. By default, tmap uses pretty breaks, which may not be the most effective for our data. An alternative, such as natural breaks (or jenks), might better reveal the data’s variation.\nTo customise the classification breaks, refer to the tm_polygons() documentation. The following parameters are relevant:\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\nfill.scale\nDefines the color scale for polygon fills. Accepts a scale object created by functions such as tm_scale_continuous() and tm_intervals()\n\n\ntm_scale_continuous()\nCreates a continuous scale object for mapping numeric values to colours. You can specify options such as palette (color scheme) and limits (data range).\n\n\ntm_scale_intervals()\nCreates a scale object for mapping data into discrete classes (intervals). Parameters include: n (number of classes) and style (classification method: e.g. quantile, equal, jenks)\n\n\n\nFor example, if we want to adjust our choropleth map to use five classes determined by the natural breaks method, we need to specify the n and style parameters as follows:\n\n\n\nR code\n\n# shape, polygons\ntm_shape(msoa21) +\n  # specify column, classes\n  tm_polygons(\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(n = 5, style = \"jenks\"),\n  )\n\n\n\n\n\nFigure 6: Building up a map layer by layer."
  },
  {
    "objectID": "01-spatial.html#styling-spatial-data",
    "href": "01-spatial.html#styling-spatial-data",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "Styling a map in tmap requires a deeper understanding and familiarity with the library, which is something you will develop best through hands-on practice. Here are the key functions to be aware of:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\ntm_layout()\nCustomises overall map layout, including titles, fonts, legend position, margins, and frame settings.\n\n\ntm_compass()\nAdds a compass or North arrow to the map, with options for size, position, and style.\n\n\ntm_scale_bar()\nAdds a scale bar to indicate distance, with options for units, position, and styling.\n\n\n\nTo begin styling your map, explore each of these functions and their parameters. Through trial and error, you can tweak and refine the map until you achieve the desired look:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # specify column, classes, labels\n  tm_polygons(\n    # map data\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(\n      n = 5, style = \"jenks\",\n      values = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n      labels = c(\"Smallest share\", \"2nd smallest\", \"3rd smallest\", \"4th smallest\", \"Largest share\"),\n    ),\n\n    # legend\n    fill.legend = tm_legend(\n      title = \"Share of population\",\n      na.text = \"No population\",\n      frame = FALSE,\n    ),\n\n    # borders\n    col = \"#ffffff\",\n    col_alpha = 0.3\n  ) +\n\n  # title\n  tm_title(\n    text = \"Share of population born in Europe\"\n  ) +\n\n  # layout configuration\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.90, 1.00),\n    legend.title.size = 0.7,\n    legend.title.fontface = \"bold\",\n    legend.text.size = 0.55,\n\n    # canvas\n    inner.margins = c(0.05, 0.05, 0.05, 0.05),\n    frame = FALSE,\n  ) +\n\n  # North arrow\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"left\", \"top\"),\n    size = 1,\n    text.size = 0.7\n  ) +\n\n  # scale bar\n  tm_scalebar(\n    breaks = c(0, 5, 10, 15, 20),\n    position = c(0.85, 0.20),\n    text.size = 0.4\n  )\n\n\n\n\n\nFigure 7: Building up a map layer by layer.\n\n\n\n\nWe can also have some map labels, if we want, by extracting centroids from selected polygons and adding these as separate map layer:\n\n\n\nR code\n\n# map labels\nlab &lt;- msoa21 |&gt;\n  filter(msoa21cd == \"E02000642\" | msoa21cd == \"E02000180\") |&gt;\n  st_centroid()\n\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n# map object\nlon_eurpop &lt;-\n  # shape\n  tm_shape(msoa21) +\n\n  # specify column, classes, labels\n  tm_polygons(\n    # map data\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(\n      n = 5, style = \"jenks\",\n      values = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n      labels = c(\"Smallest share\", \"2nd smallest\", \"3rd smallest\", \"4th smallest\", \"Largest share\"),\n    ),\n\n    # legend\n    fill.legend = tm_legend(\n      title = \"Share of population\",\n      na.text = \"No population\",\n      frame = FALSE,\n    ),\n\n    # borders\n    col = \"#ffffff\",\n    col_alpha = 0.3\n  ) +\n\n  # shape\n  tm_shape(lab) +\n\n  # centroids\n  tm_symbols(\n    size = 0.4,\n    fill = \"#000000\"\n  ) +\n\n  # labels\n  tm_text(\n    text = \"msoa21nm\",\n    col = \"#000000\",\n    size = 0.8,\n    xmod = 0,\n    ymod = -0.6\n  ) +\n\n  # title\n  tm_title(\n    text = \"Share of population born in Europe\"\n  ) +\n\n  # layout configuration\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.90, 1.00),\n    legend.title.size = 0.7,\n    legend.title.fontface = \"bold\",\n    legend.text.size = 0.55,\n\n    # canvas\n    inner.margins = c(0.05, 0.05, 0.05, 0.05),\n    frame = FALSE,\n  ) +\n\n  # North arrow\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"left\", \"top\"),\n    size = 1,\n    text.size = 0.7\n  ) +\n\n  # scale bar\n  tm_scalebar(\n    breaks = c(0, 5, 10, 15, 20),\n    position = c(0.85, 0.20),\n    text.size = 0.4\n  )\n\n# plot\nlon_eurpop\n\n\n\n\nFigure 8: Building up a map layer by layer.\n\n\n\n\nIn the code above, we stored the full map definition as an object. This makes it easy to export the map and save it as a .jpg, .png or .pdf file:\n\n\n\nR code\n\n# write map\ntmap_save(tm = lon_eurpop, filename = \"london-european-population.jpg\", width = 15,\n    height = 15, units = c(\"cm\"))"
  },
  {
    "objectID": "01-spatial.html#assignment",
    "href": "01-spatial.html#assignment",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "Now that we have prepared our dataset and created our initial maps in R, we can also try and map the distribution of the proportion of European immigrants across Wales and experiment with different mapping parameters. Follow these steps:\n\nDownload the two datasets provided below and save them in the appropriate subfolder within your data directory. The datasets include:\n\nA csv file containing the number of people residing in Wales that are born in a European country, as recorded in the 2021 Census for England and Wales, aggregated at the MSOA level.\nA GeoPackage file containing the 2021 MSOA spatial boundaries for England and Wales.\n\nLoad both datasets and merge them together. Make sure to only retain those MSOAs that belong to Wales.\nCreate a map that shows the proportion of the population residing in Wales that is born in Europe.\nExperiment by adjusting various map parameters, such as the colour scheme, map labels, and data classification method.\n\n\n\n\nFile\nType\nLink\n\n\n\n\nWales MSOA Census 2021 European Population\ncsv\nDownload\n\n\nEngland and Wales MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload"
  },
  {
    "objectID": "01-spatial.html#before-you-leave",
    "href": "01-spatial.html#before-you-leave",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "And that is how you use R as a GIS in its most basic form. More RGIS in the coming weeks, but this concludes the tutorial for this week."
  },
  {
    "objectID": "00-index.html",
    "href": "00-index.html",
    "title": "Geocomputation",
    "section": "",
    "text": "Welcome to Geocomputation. This module offers a deep dive into the principles of spatial analysis and data visualisation while providing a thorough introduction to reproducible research. Over the next ten weeks, you will explore the theory, methods, and tools of spatial analysis through engaging case studies. You will gain hands-on experience in sourcing, managing, cleaning, analysing and presenting spatial, demographic, and socioeconomic datasets.\n\n\n\nPlease be aware that for this module you are expected to have access to a working R v4.5 installation and have a basic level of proficiency in programming with R. This includes skills such as installing libraries, loading data, calculating variables, and reshaping data. For installation instructions and a refresher, please refer to the Getting started and R for Data Analysis tutorials in the GEOG0018: Methods in Human Geography workbook.\n\n\n\nMoodle serves as the central hub for GEOG0030, where you will find all essential module information, including key details about assessments. This workbook provides links to all required reading materials and contains the content for each computer tutorial.\n\n\n\nThe topics covered over the next ten weeks are:\n\n\n\nWeek\nSection\nTopic\n\n\n\n\n1\nCore Spatial Analysis\nReproducible Spatial Analysis\n\n\n2\nCore Spatial Analysis\nSpatial Queries and Geometric Operations\n\n\n3\nCore Spatial Analysis\nPoint Pattern Analysis\n\n\n4\nCore Spatial Analysis\nSpatial Autocorrelation\n\n\n5\nCore Spatial Analysis\nSpatial Models\n\n\n\nReading week\nReading week\n\n\n6\nApplied Spatial Analysis\nRaster Data Analysis\n\n\n7\nApplied Spatial Analysis\nGeodemographic Classification\n\n\n8\nApplied Spatial Analysis\nAccessibility Analysis\n\n\n9\nData Visualisation\nBeyond the Choropleth\n\n\n10\nData Visualisation\nComplex Visualisations\n\n\n\n\n\n\n\n\n\nThis GitHub resource has been updated for the 2025-2026 academic year. The content for 2024-2025 has been archived and can be found here: [Link]\n\n\n\n\n\n\nFor specific assistance with this module, you can:\n\nRefer to the Moodle assessment tab for queries about module assessments.\nAsk a question at the end of lectures or during the computer practicals.\nAttend the scheduled Geocomputation Additional Support Hours.\nBook into the Academic Support and Feedback hours.\n\n\n\n\n\n\n\n\n\n\nThis year’s module material features the following major updates:\n\nAll code has been revised to ensure compatibility with tmap v4.\nPackage management using renv has been removed to simplify the workflow\n\n\n\n\n\n\n\nThis workbook is created using the Quarto publishing system. Elements of this workbook are partially based on and modified from:\n\n\nThe GEOG0030: Geocomputation 2023-2024 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2022-2023 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2021-2022 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2020-2021 workbook by Jo Wilkin\n\nThis year’s workbook also takes inspiration and design elements from:\n\nThe Spatial Data Science for Social Geography course by Martin Fleischmann\nThe Mapping and Modelling Geographic Data in R course by Richard Harris\n\nThe datasets used in this workbook contain:\n\nData from Office for National Statistics licensed under the Open Government Licence v.3.0\nOS data © Crown copyright and database right [2024]"
  },
  {
    "objectID": "00-index.html#welcome",
    "href": "00-index.html#welcome",
    "title": "Geocomputation",
    "section": "",
    "text": "Welcome to Geocomputation. This module offers a deep dive into the principles of spatial analysis and data visualisation while providing a thorough introduction to reproducible research. Over the next ten weeks, you will explore the theory, methods, and tools of spatial analysis through engaging case studies. You will gain hands-on experience in sourcing, managing, cleaning, analysing and presenting spatial, demographic, and socioeconomic datasets."
  },
  {
    "objectID": "00-index.html#prerequisites",
    "href": "00-index.html#prerequisites",
    "title": "Geocomputation",
    "section": "",
    "text": "Please be aware that for this module you are expected to have access to a working R v4.5 installation and have a basic level of proficiency in programming with R. This includes skills such as installing libraries, loading data, calculating variables, and reshaping data. For installation instructions and a refresher, please refer to the Getting started and R for Data Analysis tutorials in the GEOG0018: Methods in Human Geography workbook."
  },
  {
    "objectID": "00-index.html#moodle",
    "href": "00-index.html#moodle",
    "title": "Geocomputation",
    "section": "",
    "text": "Moodle serves as the central hub for GEOG0030, where you will find all essential module information, including key details about assessments. This workbook provides links to all required reading materials and contains the content for each computer tutorial."
  },
  {
    "objectID": "00-index.html#module-overview",
    "href": "00-index.html#module-overview",
    "title": "Geocomputation",
    "section": "",
    "text": "The topics covered over the next ten weeks are:\n\n\n\nWeek\nSection\nTopic\n\n\n\n\n1\nCore Spatial Analysis\nReproducible Spatial Analysis\n\n\n2\nCore Spatial Analysis\nSpatial Queries and Geometric Operations\n\n\n3\nCore Spatial Analysis\nPoint Pattern Analysis\n\n\n4\nCore Spatial Analysis\nSpatial Autocorrelation\n\n\n5\nCore Spatial Analysis\nSpatial Models\n\n\n\nReading week\nReading week\n\n\n6\nApplied Spatial Analysis\nRaster Data Analysis\n\n\n7\nApplied Spatial Analysis\nGeodemographic Classification\n\n\n8\nApplied Spatial Analysis\nAccessibility Analysis\n\n\n9\nData Visualisation\nBeyond the Choropleth\n\n\n10\nData Visualisation\nComplex Visualisations\n\n\n\n\n\n\n\n\n\nThis GitHub resource has been updated for the 2025-2026 academic year. The content for 2024-2025 has been archived and can be found here: [Link]"
  },
  {
    "objectID": "00-index.html#troubleshooting",
    "href": "00-index.html#troubleshooting",
    "title": "Geocomputation",
    "section": "",
    "text": "For specific assistance with this module, you can:\n\nRefer to the Moodle assessment tab for queries about module assessments.\nAsk a question at the end of lectures or during the computer practicals.\nAttend the scheduled Geocomputation Additional Support Hours.\nBook into the Academic Support and Feedback hours."
  },
  {
    "objectID": "00-index.html#major-updates",
    "href": "00-index.html#major-updates",
    "title": "Geocomputation",
    "section": "",
    "text": "This year’s module material features the following major updates:\n\nAll code has been revised to ensure compatibility with tmap v4.\nPackage management using renv has been removed to simplify the workflow"
  },
  {
    "objectID": "00-index.html#acknowledgements",
    "href": "00-index.html#acknowledgements",
    "title": "Geocomputation",
    "section": "",
    "text": "This workbook is created using the Quarto publishing system. Elements of this workbook are partially based on and modified from:\n\n\nThe GEOG0030: Geocomputation 2023-2024 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2022-2023 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2021-2022 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2020-2021 workbook by Jo Wilkin\n\nThis year’s workbook also takes inspiration and design elements from:\n\nThe Spatial Data Science for Social Geography course by Martin Fleischmann\nThe Mapping and Modelling Geographic Data in R course by Richard Harris\n\nThe datasets used in this workbook contain:\n\nData from Office for National Statistics licensed under the Open Government Licence v.3.0\nOS data © Crown copyright and database right [2024]"
  }
]