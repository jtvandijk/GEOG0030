[
  {
    "objectID": "11-data.html",
    "href": "11-data.html",
    "title": "1 Data Sources",
    "section": "",
    "text": "Below is a list of resources that you may find helpful when sourcing data for your coursework or dissertation. This list is not exhaustive but includes some recommended websites to get you started.\n\n\nThe following websites contain Open Data or link to Open Data from several respectable data providers:\n\nAfricanUrbanNetwork\nAirBnB Data\nBike Docking Data (ready for R)\nBing Maps worldwide road detections\nCamden Air Action\nConsumer Data Research Centre\nDepartment for Environment, Food & Rural Affairs\nEdina (e.g. OS mastermap)\nEU Tourism Data\nEurostat\nGeofabrik (OSM data)\nGeolytix Supermarket Retail Points\nGlobal Urban Areas dataset\nGlobal Weather Data\nGoogle Dataset Search\nGoogle Open Buildings\nKaggle Public Datasets\nKing’s College Data on Air Pollution\nLondon Data Store\nLondon Local Authority Maintained Trees\nLondon Tube PM2.5 Levels\nMicrosoft Global Building Footprints\nMicrosoft Research Open Data\nNational Public Transport Access Nodes (NaPTAN)\nNASA EARTHDATA\nNASA SocioEconomic Data and Applications Center (SEDAC)\nNHS Data (ready for R)\nnomis Official Census and Labour Market Statistics\nOffice for National Statistics Geoportal\nOffice for National Statistics\nOpen Topography\nOverture Point of Interest data for the United Kingdom\nPlanetary Computer Data Catalog\npseudo Census Output Areas 2001-2011-2021\nPublic transport accessibility indicators Great Britain\nTesco Store Data (London)\nTfL Cycling Data\nTfL Open Data\nTidy Tuesday Data (not exclusively spatial data)\nUK Data Service\nUS Census Data\nUS City Open Data Census\nUSGS Earth Explorer\nUTD19 Multi-City Traffic Dataset\nWorldPop GitHub\nWorldPop\n\n\n\n\nUndergraduate students can also apply for Safeguarded datasets held by the Geographic Data Service. Accessing these datasets requires following a specific process, which is outlined on the GeoDS website. When applying, you will need to explain why you require the specific dataset and describe how you intend to use it. Additionally, consider the ethical implications of using the data, as this will be an important part of your application. Please be aware that it normally takes 4-5 weeks for your application to be processed.\nSome of the datasets held by the GeoDS that you can apply for are:\n\nBicycle Sharing System Docking Station Observations\nModelled Ethnicity Proportions - LSOA Geography\nFCA Financial Lives Survey\nSalad Money Daily Transaction Volumes and Values\n\n\n\n\n\n\n\nSince the application process for Safeguarded GeoDS datasets can take several weeks, these datasets may be more suitable for your undergraduate dissertation rather than the GEOG0030 coursework assignment. However, CDRC datasets labeled as Open Data do not require an application process. You can download these datasets directly after registering on the website."
  },
  {
    "objectID": "11-data.html#open-data",
    "href": "11-data.html#open-data",
    "title": "1 Data Sources",
    "section": "",
    "text": "The following websites contain Open Data or link to Open Data from several respectable data providers:\n\nAfricanUrbanNetwork\nAirBnB Data\nBike Docking Data (ready for R)\nBing Maps worldwide road detections\nCamden Air Action\nConsumer Data Research Centre\nDepartment for Environment, Food & Rural Affairs\nEdina (e.g. OS mastermap)\nEU Tourism Data\nEurostat\nGeofabrik (OSM data)\nGeolytix Supermarket Retail Points\nGlobal Urban Areas dataset\nGlobal Weather Data\nGoogle Dataset Search\nGoogle Open Buildings\nKaggle Public Datasets\nKing’s College Data on Air Pollution\nLondon Data Store\nLondon Local Authority Maintained Trees\nLondon Tube PM2.5 Levels\nMicrosoft Global Building Footprints\nMicrosoft Research Open Data\nNational Public Transport Access Nodes (NaPTAN)\nNASA EARTHDATA\nNASA SocioEconomic Data and Applications Center (SEDAC)\nNHS Data (ready for R)\nnomis Official Census and Labour Market Statistics\nOffice for National Statistics Geoportal\nOffice for National Statistics\nOpen Topography\nOverture Point of Interest data for the United Kingdom\nPlanetary Computer Data Catalog\npseudo Census Output Areas 2001-2011-2021\nPublic transport accessibility indicators Great Britain\nTesco Store Data (London)\nTfL Cycling Data\nTfL Open Data\nTidy Tuesday Data (not exclusively spatial data)\nUK Data Service\nUS Census Data\nUS City Open Data Census\nUSGS Earth Explorer\nUTD19 Multi-City Traffic Dataset\nWorldPop GitHub\nWorldPop"
  },
  {
    "objectID": "11-data.html#safeguarded-data",
    "href": "11-data.html#safeguarded-data",
    "title": "1 Data Sources",
    "section": "",
    "text": "Undergraduate students can also apply for Safeguarded datasets held by the Geographic Data Service. Accessing these datasets requires following a specific process, which is outlined on the GeoDS website. When applying, you will need to explain why you require the specific dataset and describe how you intend to use it. Additionally, consider the ethical implications of using the data, as this will be an important part of your application. Please be aware that it normally takes 4-5 weeks for your application to be processed.\nSome of the datasets held by the GeoDS that you can apply for are:\n\nBicycle Sharing System Docking Station Observations\nModelled Ethnicity Proportions - LSOA Geography\nFCA Financial Lives Survey\nSalad Money Daily Transaction Volumes and Values\n\n\n\n\n\n\n\nSince the application process for Safeguarded GeoDS datasets can take several weeks, these datasets may be more suitable for your undergraduate dissertation rather than the GEOG0030 coursework assignment. However, CDRC datasets labeled as Open Data do not require an application process. You can download these datasets directly after registering on the website."
  },
  {
    "objectID": "02-operations.html",
    "href": "02-operations.html",
    "title": "1 Spatial Queries and Geometric Operations",
    "section": "",
    "text": "This week, we look at geometric operations and spatial queries: the fundamental building blocks when it comes to spatial data processing and analysis. This includes operations such as aggregating point data, calculating the distances separating one or more spatial objects, running a buffer analysis, and intersecting different spatial layers.\n\n\nYou can download the slides of this week’s lecture here: [Link].\n\n\n\n\n\n\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 2: The Nature of Geographic Data, pp. 33-54. [Link]\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 3: Representing Geography, pp. 55-76. [Link]\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 7: Geographic Data Modeling, pp. 152-172. [Link]\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 13: Spatial Data Analysis, pp. 290-318. [Link]\n\n\n\n\n\nLovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, Chapter 4: Spatial data operations. [Link]\nLovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, Chapter 5: Geometry operations. [Link]\nLovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, Chapter 6: Reprojecting geographic data. [Link]\n\n\n\n\n\nThis week, we will examine to what extent reported bicycle theft in London cluster around train and underground stations. We will be using open data from data.police.uk on reported crimes alongside OpenStreetMap data for this analysis. We will use R to directly download the necessary data from OpenStreetMap, but the crime data will need to be manually downloaded from the data portal. We further have access to a GeoPackage that contains the London 2021 MSOA boundaries that we can use as reference layer. If you do not already have it on your computer, save this file in your data/spatial folder.\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\nThe UK Police Data Portal allows you to access and generate tabular data for crime recorded in the UK across the different police forces. To download recorded crime data for London:\n\nNavigate to data.police.uk and click on Downloads.\nUnder the data range select January 2023 to December 2023.\nUnder the Custom download tab select Metropolitan Police Service and City of London Police. Leave the other settings unchanged and click on Generate file.\n\n\n\n\n\n\nFigure 1: Downloading data on reported crimes through data.police.uk\n\n\n\n\n\nIt may take a few minutes for the download to be generated, so be patient. Once the Download now button appears, you can download the dataset.\nAfter downloading, unzip the file. You will find that the zip file contains 12 folders, one for each month of 2023. Each folder includes two files: one for the Metropolitan Police Service and one for the City of London Police.\nCreate a new folder named London-Crime within your data/attributes directory, and copy all 12 folders with the data into this new folder.\n\nTo get started, let us create our first script. File -&gt; New File -&gt; R Script. Save your script as w02-bike-theft.r.\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(sf)\nlibrary(tmap)\nlibrary(osmdata)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nAlthough we could read each individual crime file into R one by one and then combine them, we can actually accomplish this in a single step:\n\n\n\nR code\n\n# list all csv files\ncrime_df &lt;- list.files(path = \"data/attributes/London-Crime/\", full.names = TRUE, recursive = TRUE) |&gt;\n  # read individual csv files\n  lapply(read_csv) |&gt;\n  # bind together into one\n  bind_rows()\n\n# inspect\nhead(crime_df)\n\n\n# A tibble: 6 × 12\n  `Crime ID`      Month `Reported by` `Falls within` Longitude Latitude Location\n  &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;   \n1 4a14d4745da0a2… 2023… City of Lond… City of Londo…    -0.106     51.5 On or n…\n2 e6e32581c99c5b… 2023… City of Lond… City of Londo…    -0.107     51.5 On or n…\n3 7b7cb8e7debe8b… 2023… City of Lond… City of Londo…    -0.110     51.5 On or n…\n4 f7fc44e1e76332… 2023… City of Lond… City of Londo…    -0.108     51.5 On or n…\n5 8083dafd1770af… 2023… City of Lond… City of Londo…    -0.112     51.5 On or n…\n6 4587239a45f0e8… 2023… City of Lond… City of Londo…    -0.112     51.5 On or n…\n# ℹ 5 more variables: `LSOA code` &lt;chr&gt;, `LSOA name` &lt;chr&gt;, `Crime type` &lt;chr&gt;,\n#   `Last outcome category` &lt;chr&gt;, Context &lt;lgl&gt;\n\n\n\n\n\n\n\n\nDepending on your computer, processing this data may take some time due to the large volume involved. Once completed, you should have a dataframe containing 1,144,329 observations.\n\n\n\n\n\n\n\n\n\nYou can further inspect the object using the View() function.\n\n\n\nThe column names contain spaces and are therefore not easily referenced. We can easily clean this up using the janitor package:\n\n\n\nR code\n\n# clean names\ncrime_df &lt;- crime_df |&gt;\n    clean_names()\n\n# inspect\nnames(crime_df)\n\n\n [1] \"crime_id\"              \"month\"                 \"reported_by\"          \n [4] \"falls_within\"          \"longitude\"             \"latitude\"             \n [7] \"location\"              \"lsoa_code\"             \"lsoa_name\"            \n[10] \"crime_type\"            \"last_outcome_category\" \"context\"              \n\n\n\n\n\n\n\n\nIf your clean_names() function returns an error, it is likely due to a conflict with another library that also includes a clean_names() function. In such cases, R cannot determine which one to use. To resolve this, you can specify the library explicitly by using janitor::clean_names().\n\n\n\nFor our analysis, we are currently only interested in reported bicycle thefts, so we need to filter our data based on the crime_type column. We can start by examining the unique values in this column and then subset the data accordingly:\n\n\n\nR code\n\n# unique types\nunique(crime_df$crime_type)\n\n\n [1] \"Other theft\"                  \"Other crime\"                 \n [3] \"Theft from the person\"        \"Public order\"                \n [5] \"Anti-social behaviour\"        \"Burglary\"                    \n [7] \"Criminal damage and arson\"    \"Drugs\"                       \n [9] \"Shoplifting\"                  \"Vehicle crime\"               \n[11] \"Violence and sexual offences\" \"Bicycle theft\"               \n[13] \"Robbery\"                      \"Possession of weapons\"       \n\n# filter\ntheft_bike &lt;- crime_df |&gt;\n    filter(crime_type == \"Bicycle theft\")\n\n# inspect\nhead(theft_bike)\n\n# A tibble: 6 × 12\n  crime_id  month reported_by falls_within longitude latitude location lsoa_code\n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    \n1 62b0f525… 2023… City of Lo… City of Lon…   -0.0916     51.5 On or n… E01000002\n2 9a078d63… 2023… City of Lo… City of Lon…   -0.0952     51.5 On or n… E01032739\n3 f175a32e… 2023… City of Lo… City of Lon…   -0.0872     51.5 On or n… E01032739\n4 137ec120… 2023… City of Lo… City of Lon…   -0.0783     51.5 On or n… E01032739\n5 4c3b4677… 2023… City of Lo… City of Lon…   -0.108      51.5 On or n… E01032740\n6 13b5eb5c… 2023… City of Lo… City of Lon…   -0.0980     51.5 On or n… E01032740\n# ℹ 4 more variables: lsoa_name &lt;chr&gt;, crime_type &lt;chr&gt;,\n#   last_outcome_category &lt;chr&gt;, context &lt;lgl&gt;\n\n\nNow that we have filtered the data to only include reported bicycle thefts, we need to convert our dataframe into a spatial dataframe that maps the locations of the crimes using the recorded latitude and longitude coordinates. We can then project this spatial dataframe into the British National Grid (EPSG:27700).\n\n\n\nR code\n\n# to spatial data\ntheft_bike &lt;- theft_bike |&gt;\n    filter(!is.na(longitude) & !is.na(latitude)) |&gt;\n    st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) |&gt;\n    st_transform(27700)\n\n# inspect\nhead(theft_bike)\n\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 531388 ymin: 180914 xmax: 533447 ymax: 181727.9\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 6 × 11\n  crime_id           month reported_by falls_within location lsoa_code lsoa_name\n  &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    \n1 62b0f525fc471c062… 2023… City of Lo… City of Lon… On or n… E01000002 City of …\n2 9a078d630cf67c37c… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n3 f175a32ef7f90c67a… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n4 137ec1201fd64b578… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n5 4c3b467755a98afa3… 2023… City of Lo… City of Lon… On or n… E01032740 City of …\n6 13b5eb5ca0aef09a2… 2023… City of Lo… City of Lon… On or n… E01032740 City of …\n# ℹ 4 more variables: crime_type &lt;chr&gt;, last_outcome_category &lt;chr&gt;,\n#   context &lt;lgl&gt;, geometry &lt;POINT [m]&gt;\n\n\nLet’s map the dataset to get an idea of how the data looks like, using the outline of London as background:\n\n\n\nR code\n\n# read spatial dataset\nmsoa21 &lt;- st_read(\"data/spatial/London-MSOA-2021.gpkg\")\n\n\nReading layer `London-MSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-MSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1002 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# london outline\noutline &lt;- msoa21 |&gt;\n  st_union()\n\n# shape\ntm_shape(outline) +\n\n  # map data\n  tm_polygons(\n    fill = \"#f0f0f0\",\n    col = NA\n  ) +\n\n  # shape\n  tm_shape(theft_bike) +\n\n  # map data\n  tm_symbols(\n    size = 0.10,\n    fill = \"#fdc086\",\n    col = \"#fdc086\",\n  ) +\n\n  # layout\n  tm_layout(\n    frame = FALSE,\n  )\n\n\n\n\nFigure 2: Reported bicycle thefts in London.\n\n\n\n\nWe can save the prepared dataset as a GeoPackage so that we can use it some other time:\n\n\n\nR code\n\n# write\nst_write(theft_bike, \"data/spatial/London-BicycleTheft-2023.gpkg\")\n\n\n\n\n\nOpenStreetMap (OSM) is a free, editable map of the world. Each map element (whether a point, line, or polygon) in OSM is tagged with various attribute data. To download the station data we need, we must use the appropriate tags, represented as key and value pairs, to query the OSM database. In our case, we are looking for train stations, which fall under the Public Transport key, with a value of station. To limit our search to London, we can use the spatial extent of the 2021 MSOA boundaries as the bounding box for data extraction.\n\n\n\nR code\n\n# define our bbox coordinates, use WGS84\nbbox_london &lt;- msoa21 |&gt;\n  st_transform(4326) |&gt;\n  st_bbox()\n\n# osm query\nosm_stations &lt;- opq(bbox = bbox_london) |&gt;\n  add_osm_feature(key = \"public_transport\", value = \"station\") |&gt;\n  osmdata_sf()\n\n\n\n\n\n\n\n\nIn some cases, the OSM query may return an error, particularly when multiple users from the same location are executing the exact same query. If so, you can download a prepared copy of the data here: [Download]. You can load this copy into R through load('data/spatial/London-OSM-Stations.RData')\n\n\n\nThe OSM query returns all data types, including lines and polygons tagged as stations. For our analysis, we only want to retain the point locations. In addition, we want to clip the results to the outline of London to exclude points that fall within the bounding box but outside the boundaries of Greater London.\n\n\n\nR code\n\n# extract points\nosm_stations &lt;- osm_stations$osm_points |&gt;\n    st_set_crs(4326) |&gt;\n    st_transform(27700) |&gt;\n    st_intersection(outline) |&gt;\n    select(c(\"osm_id\", \"name\", \"network\", \"operator\", \"public_transport\", \"railway\"))\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# inspect\nhead(osm_stations)\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 506148.8 ymin: 168292.6 xmax: 546593.8 ymax: 191714.7\nProjected CRS: OSGB36 / British National Grid\n           osm_id                   name                      network\n780856     780856 Shepherd's Bush Market           London Underground\n1256794   1256794           West Drayton National Rail;Elizabeth line\n2013971   2013971       Finchley Central           London Underground\n9780241   9780241           St Mary Cray                National Rail\n13330343 13330343               Woodford           London Underground\n13790683 13790683               Mile End           London Underground\n                   operator public_transport railway                  geometry\n780856   London Underground          station station POINT (523195.9 180061.9)\n1256794      Elizabeth line          station station POINT (506148.8 180085.4)\n2013971  London Underground          station station   POINT (525294.7 190658)\n9780241        Southeastern          station station POINT (546593.8 168292.6)\n13330343 London Underground    stop_position    stop POINT (540946.1 191714.7)\n13790683 London Underground    stop_position    stop   POINT (536524.6 182545)\n\n# inspect\nnrow(osm_stations)\n\n[1] 4056\n\n\nThe total number of data points seems rather high. In fact, looking at the railway variable, several points are not tagged as station or do not have a value at all:\n\n\n\nR code\n\n# inspect values\ncount(osm_stations, railway)\n\n\nSimple feature collection with 5 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 504982.3 ymin: 159027.2 xmax: 556185.7 ymax: 200138.6\nProjected CRS: OSGB36 / British National Grid\n                 railway    n                       geometry\n1                station  614 MULTIPOINT ((505078.2 17673...\n2                   stop   17 MULTIPOINT ((528197.7 18571...\n3        subway_entrance   38 MULTIPOINT ((525226.4 18745...\n4 train_station_entrance    1      POINT (538196.2 184826.5)\n5                   &lt;NA&gt; 3386 MULTIPOINT ((504982.3 17581...\n\n\nThe number of points tagged as station in the railway field are most likely the only points in our dataset that represent actual stations, so we will only retain those points.\n\n\n\nR code\n\n# extract train and underground stations\nosm_stations &lt;- osm_stations |&gt;\n    filter(railway == \"station\")\n\n\nLet’s map the dataset to get an idea of how the data looks like, using the outline of London as background:\n\n\n\nR code\n\n# shape\ntm_shape(outline) +\n\n  # map data\n  tm_polygons(\n    fill = \"#f0f0f0\",\n    col = NA\n  ) +\n\n  # shape\n  tm_shape(osm_stations) +\n\n  # map data\n  tm_symbols(\n    size = 0.2,\n    fill = \"#636363\",\n    col = \"#636363\",\n  ) +\n\n  # layout\n  tm_layout(\n    frame = FALSE,\n  )\n\n\n\n\n\nFigure 3: Train and underground stations in London.\n\n\n\n\nNow we have our data prepared, we can move on to analyse the extent to which bicycle theft in London cluster around stations. We can use both spatial queries and geometric operations to complete this analysis.\n\n\n\n\n\n\nWhen using osmdata to retrieve train stations in London, be aware that OpenStreetMap data may be incomplete or inconsistent due to different tagging practices by contributors, missing or outdated entries, and variations in how stations are classified. While verifying every detail is beyond the scope of this practical, it is essential to exercise due diligence when working with real-world data. Where possible triangulate with other authoritative sources such as official transport datasets and at the very least perform sanity checks to identify obvious anomalies.\n\n\n\n\n\n\nA spatial query is used to retrieve data based on its geographic location or spatial relationships. It uses spatial information from one or more layers to find features that meet specific criteria, such as proximity, intersection, or containment. For instance, we can use a spatial query to count all the bicycle thefts that have occurred within 500 metres of a train or underground station:\n\n\n\nR code\n\n# create a single station geometry\nosm_stations_comb &lt;- osm_stations |&gt;\n    st_union()\n\n# spatial query\ntheft_bike$d500 &lt;- theft_bike |&gt;\n    st_is_within_distance(osm_stations_comb, dist = 500, sparse = FALSE)\n\n# inspect\nhead(theft_bike)\n\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 531388 ymin: 180914 xmax: 533447 ymax: 181727.9\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 6 × 12\n  crime_id           month reported_by falls_within location lsoa_code lsoa_name\n  &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    \n1 62b0f525fc471c062… 2023… City of Lo… City of Lon… On or n… E01000002 City of …\n2 9a078d630cf67c37c… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n3 f175a32ef7f90c67a… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n4 137ec1201fd64b578… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n5 4c3b467755a98afa3… 2023… City of Lo… City of Lon… On or n… E01032740 City of …\n6 13b5eb5ca0aef09a2… 2023… City of Lo… City of Lon… On or n… E01032740 City of …\n# ℹ 5 more variables: crime_type &lt;chr&gt;, last_outcome_category &lt;chr&gt;,\n#   context &lt;lgl&gt;, geometry &lt;POINT [m]&gt;, d500 &lt;lgl[,1]&gt;\n\n\n\n\n\n\n\n\nThe above code converts the stations dataframe into a single geometry. This step is essential for sf to ensure that each point in the dataset is compared to every point in the stations dataframe. Without this conversion, the comparison would be done one station point at a time, storing only the last result rather than considering all station points simultaneously.\n\n\n\nWe can use the count() function to find out just how many thefts fall in each of these categories:\n\n\n\nR code\n\n# number of bicycle thefts within 500m of a station\ncount(theft_bike, d500)\n\n\nSimple feature collection with 2 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 384131 ymin: 101512 xmax: 612925 ymax: 398061.1\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 2 × 3\n  d500[,1]     n                                                        geometry\n* &lt;lgl&gt;    &lt;int&gt;                                                &lt;MULTIPOINT [m]&gt;\n1 FALSE     5485 ((384131 398061.1), (409823 101512), (494953 212260), (495917 …\n2 TRUE     10534 ((505376 184282.9), (505424 184212), (505433 184416), (505558 …\n\n\nMore than two-thirds of all reported bicycle thefts in London occur within 500 metres of a train or underground station. Of course, we can map the results for a visual inspection:\n\n\n\nR code\n\n# classify distances\ntheft_bike &lt;- theft_bike |&gt;\n  mutate(dist_class = if_else(d500 == TRUE, \"&gt; 500 m\", \"&lt; 500 m\")) |&gt;\n  mutate(dist_class = factor(dist_class, levels = c(\"&gt; 500 m\", \"&lt; 500 m\")))\n\n# shape\ntm_shape(outline) +\n\n  # map data\n  tm_polygons(\n    fill = \"#f0f0f0\",\n    col = NA\n  ) +\n\n  # shape\n  tm_shape(theft_bike) +\n\n  # map data\n  tm_symbols(\n    # map data\n    col = \"dist_class\",\n    size = 0.1,\n    col.scale = tm_scale_categorical(\n      values = c(\n        \"&gt; 500 m\" = \"#fdc086\",\n        \"&lt; 500 m\" = \"#998ec3\"\n      ),\n    ),\n\n    # legend\n    col.legend = tm_legend(\n      title = \"\",\n      frame = FALSE,\n    )\n  ) +\n\n  # shape\n  tm_shape(osm_stations) +\n\n  # map data\n  tm_symbols(\n    size = 0.2,\n    fill = \"#636363\",\n    col = \"#636363\",\n  ) +\n\n  # legend\n  tm_add_legend(\n    type = \"symbols\",\n    labels = \"Station\",\n    size = 0.2,\n    fill = \"#636363\"\n  ) +\n\n  # layout\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.0, 0.2),\n    legend.text.size = 0.7,\n\n    # canvas\n    frame = FALSE\n  )\n\n\n\n\n\nFigure 4: Reported bicycle thefts in London within 500 metres from a train or underground station.\n\n\n\n\n\n\n\nGeometric operations are used to manipulate and analyse the shapes and spatial properties of geometric objects, such as points, lines, and polygons. These operations include tasks like calculating intersections, buffering, and determining the distance between shapes. In this case, we can create 500-metre buffers around each station and then count how many bicycle thefts fall within these buffers.\n\n\n\nR code\n\n# buffer\nosm_stations_buffer &lt;- osm_stations |&gt;\n    st_buffer(dist = 500) |&gt;\n    st_union()\n\n# inspect\nhead(osm_stations_buffer)\n\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 504578.2 ymin: 158527.2 xmax: 556685.7 ymax: 200638.6\nProjected CRS: OSGB36 / British National Grid\n\n\nMULTIPOLYGON (((517709.6 169311.1, 517686.6 169...\n\n\n\n\n\n\n\n\nWhen performing buffer analysis, the buffer sizes are determined by the units of the coordinate reference system (CRS) used. For instance, with the British National Grid, where the CRS is in metres, the buffer distance must be specified in metres.\n\n\n\nWe can map the results for a visual inspection:\n\n\n\nR code\n\n# shape\ntm_shape(outline) +\n\n  # map data\n  tm_polygons(\n    fill = \"#f0f0f0\",\n    col = NA\n  ) +\n\n  # shape\n  tm_shape(osm_stations_buffer) +\n\n  # specify colours\n  tm_polygons(\n    fill = \"#beaed4\",\n  ) +\n\n  # layout\n  tm_layout(\n    # canvas\n    frame = FALSE\n  )\n\n\n\n\n\nFigure 5: Train and underground stations in London with a 500 metres buffer.\n\n\n\n\nWe can now use the st_intersects function to find out which reported bicycle thefts have occurred within 500 metres of a train or underground station.\n\n\n\nR code\n\n# intersect buffer with bicycle thefts\ntheft_bike$d500_buffer &lt;- theft_bike |&gt;\n    st_intersects(osm_stations_buffer, sparse = FALSE)\n\n# number of bicycle thefts within 500m of a station\ncount(theft_bike, d500_buffer)\n\n\nSimple feature collection with 2 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 384131 ymin: 101512 xmax: 612925 ymax: 398061.1\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 2 × 3\n  d500_buffer[,1]     n                                                 geometry\n* &lt;lgl&gt;           &lt;int&gt;                                         &lt;MULTIPOINT [m]&gt;\n1 FALSE            5491 ((384131 398061.1), (409823 101512), (494953 212260), (…\n2 TRUE            10528 ((505376 184282.9), (505424 184212), (505433 184416), (…\n\n\n\n\n\n\n\n\nThe results are almost identical, with a small difference due to how the two methods define within and handle spatial relationships and boundaries. For instance, a point on the buffer’s edge will be included in the intersect method, but may not meet the distance threshold required by st_within_distance().\n\n\n\n\n\n\n\nNow that we are familiar with basic spatial queries and geometric operations, we can conduct a similar analysis on the number of serious and fatal road crashed in London in 2022 and determine how many occurred on or near a main road. Try to do the following:\n\nDownload the two datasets provided below and save them in the appropriate subfolder within your data directory. The datasets include:\n\nA csv file containing the number of road crashes that occurred in London in 2022, extracted from the UK’s official road traffic casualty database using the stats19 R library.\nA GeoPackage file that contains main roads in London, extracted from the Ordnance Survey Open Roads dataset.\n\nCalculate the number of serious and fatal road crashes that occurred within 100 metres and 500 metres of a main road.\n\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon STATS19 Road Collisions 2022\ncsv\nDownload\n\n\nLondon OS Open Roads - Main Roads\nGeoPackage\nDownload\n\n\n\n\n\n\nBoom. That is how you can conduct basic spatial queries and geometric operations and using R and sf. Yet more RGIS coming over the next couple of weeks, but this concludes the tutorial for this week. Time to check out that reading list?"
  },
  {
    "objectID": "02-operations.html#lecture-slides",
    "href": "02-operations.html#lecture-slides",
    "title": "1 Spatial Queries and Geometric Operations",
    "section": "",
    "text": "You can download the slides of this week’s lecture here: [Link]."
  },
  {
    "objectID": "02-operations.html#reading-list",
    "href": "02-operations.html#reading-list",
    "title": "1 Spatial Queries and Geometric Operations",
    "section": "",
    "text": "Longley, P. et al. 2015. Geographic Information Science & Systems, Chapter 2: The Nature of Geographic Data, pp. 33-54. [Link]\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 3: Representing Geography, pp. 55-76. [Link]\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 7: Geographic Data Modeling, pp. 152-172. [Link]\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 13: Spatial Data Analysis, pp. 290-318. [Link]\n\n\n\n\n\nLovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, Chapter 4: Spatial data operations. [Link]\nLovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, Chapter 5: Geometry operations. [Link]\nLovelace, R., Nowosad, J. and Muenchow, J. 2021. Geocomputation with R, Chapter 6: Reprojecting geographic data. [Link]"
  },
  {
    "objectID": "02-operations.html#bike-theft-in-london-i",
    "href": "02-operations.html#bike-theft-in-london-i",
    "title": "1 Spatial Queries and Geometric Operations",
    "section": "",
    "text": "This week, we will examine to what extent reported bicycle theft in London cluster around train and underground stations. We will be using open data from data.police.uk on reported crimes alongside OpenStreetMap data for this analysis. We will use R to directly download the necessary data from OpenStreetMap, but the crime data will need to be manually downloaded from the data portal. We further have access to a GeoPackage that contains the London 2021 MSOA boundaries that we can use as reference layer. If you do not already have it on your computer, save this file in your data/spatial folder.\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\nThe UK Police Data Portal allows you to access and generate tabular data for crime recorded in the UK across the different police forces. To download recorded crime data for London:\n\nNavigate to data.police.uk and click on Downloads.\nUnder the data range select January 2023 to December 2023.\nUnder the Custom download tab select Metropolitan Police Service and City of London Police. Leave the other settings unchanged and click on Generate file.\n\n\n\n\n\n\nFigure 1: Downloading data on reported crimes through data.police.uk\n\n\n\n\n\nIt may take a few minutes for the download to be generated, so be patient. Once the Download now button appears, you can download the dataset.\nAfter downloading, unzip the file. You will find that the zip file contains 12 folders, one for each month of 2023. Each folder includes two files: one for the Metropolitan Police Service and one for the City of London Police.\nCreate a new folder named London-Crime within your data/attributes directory, and copy all 12 folders with the data into this new folder.\n\nTo get started, let us create our first script. File -&gt; New File -&gt; R Script. Save your script as w02-bike-theft.r.\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(sf)\nlibrary(tmap)\nlibrary(osmdata)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nAlthough we could read each individual crime file into R one by one and then combine them, we can actually accomplish this in a single step:\n\n\n\nR code\n\n# list all csv files\ncrime_df &lt;- list.files(path = \"data/attributes/London-Crime/\", full.names = TRUE, recursive = TRUE) |&gt;\n  # read individual csv files\n  lapply(read_csv) |&gt;\n  # bind together into one\n  bind_rows()\n\n# inspect\nhead(crime_df)\n\n\n# A tibble: 6 × 12\n  `Crime ID`      Month `Reported by` `Falls within` Longitude Latitude Location\n  &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;   \n1 4a14d4745da0a2… 2023… City of Lond… City of Londo…    -0.106     51.5 On or n…\n2 e6e32581c99c5b… 2023… City of Lond… City of Londo…    -0.107     51.5 On or n…\n3 7b7cb8e7debe8b… 2023… City of Lond… City of Londo…    -0.110     51.5 On or n…\n4 f7fc44e1e76332… 2023… City of Lond… City of Londo…    -0.108     51.5 On or n…\n5 8083dafd1770af… 2023… City of Lond… City of Londo…    -0.112     51.5 On or n…\n6 4587239a45f0e8… 2023… City of Lond… City of Londo…    -0.112     51.5 On or n…\n# ℹ 5 more variables: `LSOA code` &lt;chr&gt;, `LSOA name` &lt;chr&gt;, `Crime type` &lt;chr&gt;,\n#   `Last outcome category` &lt;chr&gt;, Context &lt;lgl&gt;\n\n\n\n\n\n\n\n\nDepending on your computer, processing this data may take some time due to the large volume involved. Once completed, you should have a dataframe containing 1,144,329 observations.\n\n\n\n\n\n\n\n\n\nYou can further inspect the object using the View() function.\n\n\n\nThe column names contain spaces and are therefore not easily referenced. We can easily clean this up using the janitor package:\n\n\n\nR code\n\n# clean names\ncrime_df &lt;- crime_df |&gt;\n    clean_names()\n\n# inspect\nnames(crime_df)\n\n\n [1] \"crime_id\"              \"month\"                 \"reported_by\"          \n [4] \"falls_within\"          \"longitude\"             \"latitude\"             \n [7] \"location\"              \"lsoa_code\"             \"lsoa_name\"            \n[10] \"crime_type\"            \"last_outcome_category\" \"context\"              \n\n\n\n\n\n\n\n\nIf your clean_names() function returns an error, it is likely due to a conflict with another library that also includes a clean_names() function. In such cases, R cannot determine which one to use. To resolve this, you can specify the library explicitly by using janitor::clean_names().\n\n\n\nFor our analysis, we are currently only interested in reported bicycle thefts, so we need to filter our data based on the crime_type column. We can start by examining the unique values in this column and then subset the data accordingly:\n\n\n\nR code\n\n# unique types\nunique(crime_df$crime_type)\n\n\n [1] \"Other theft\"                  \"Other crime\"                 \n [3] \"Theft from the person\"        \"Public order\"                \n [5] \"Anti-social behaviour\"        \"Burglary\"                    \n [7] \"Criminal damage and arson\"    \"Drugs\"                       \n [9] \"Shoplifting\"                  \"Vehicle crime\"               \n[11] \"Violence and sexual offences\" \"Bicycle theft\"               \n[13] \"Robbery\"                      \"Possession of weapons\"       \n\n# filter\ntheft_bike &lt;- crime_df |&gt;\n    filter(crime_type == \"Bicycle theft\")\n\n# inspect\nhead(theft_bike)\n\n# A tibble: 6 × 12\n  crime_id  month reported_by falls_within longitude latitude location lsoa_code\n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    \n1 62b0f525… 2023… City of Lo… City of Lon…   -0.0916     51.5 On or n… E01000002\n2 9a078d63… 2023… City of Lo… City of Lon…   -0.0952     51.5 On or n… E01032739\n3 f175a32e… 2023… City of Lo… City of Lon…   -0.0872     51.5 On or n… E01032739\n4 137ec120… 2023… City of Lo… City of Lon…   -0.0783     51.5 On or n… E01032739\n5 4c3b4677… 2023… City of Lo… City of Lon…   -0.108      51.5 On or n… E01032740\n6 13b5eb5c… 2023… City of Lo… City of Lon…   -0.0980     51.5 On or n… E01032740\n# ℹ 4 more variables: lsoa_name &lt;chr&gt;, crime_type &lt;chr&gt;,\n#   last_outcome_category &lt;chr&gt;, context &lt;lgl&gt;\n\n\nNow that we have filtered the data to only include reported bicycle thefts, we need to convert our dataframe into a spatial dataframe that maps the locations of the crimes using the recorded latitude and longitude coordinates. We can then project this spatial dataframe into the British National Grid (EPSG:27700).\n\n\n\nR code\n\n# to spatial data\ntheft_bike &lt;- theft_bike |&gt;\n    filter(!is.na(longitude) & !is.na(latitude)) |&gt;\n    st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) |&gt;\n    st_transform(27700)\n\n# inspect\nhead(theft_bike)\n\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 531388 ymin: 180914 xmax: 533447 ymax: 181727.9\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 6 × 11\n  crime_id           month reported_by falls_within location lsoa_code lsoa_name\n  &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    \n1 62b0f525fc471c062… 2023… City of Lo… City of Lon… On or n… E01000002 City of …\n2 9a078d630cf67c37c… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n3 f175a32ef7f90c67a… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n4 137ec1201fd64b578… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n5 4c3b467755a98afa3… 2023… City of Lo… City of Lon… On or n… E01032740 City of …\n6 13b5eb5ca0aef09a2… 2023… City of Lo… City of Lon… On or n… E01032740 City of …\n# ℹ 4 more variables: crime_type &lt;chr&gt;, last_outcome_category &lt;chr&gt;,\n#   context &lt;lgl&gt;, geometry &lt;POINT [m]&gt;\n\n\nLet’s map the dataset to get an idea of how the data looks like, using the outline of London as background:\n\n\n\nR code\n\n# read spatial dataset\nmsoa21 &lt;- st_read(\"data/spatial/London-MSOA-2021.gpkg\")\n\n\nReading layer `London-MSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-MSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1002 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# london outline\noutline &lt;- msoa21 |&gt;\n  st_union()\n\n# shape\ntm_shape(outline) +\n\n  # map data\n  tm_polygons(\n    fill = \"#f0f0f0\",\n    col = NA\n  ) +\n\n  # shape\n  tm_shape(theft_bike) +\n\n  # map data\n  tm_symbols(\n    size = 0.10,\n    fill = \"#fdc086\",\n    col = \"#fdc086\",\n  ) +\n\n  # layout\n  tm_layout(\n    frame = FALSE,\n  )\n\n\n\n\nFigure 2: Reported bicycle thefts in London.\n\n\n\n\nWe can save the prepared dataset as a GeoPackage so that we can use it some other time:\n\n\n\nR code\n\n# write\nst_write(theft_bike, \"data/spatial/London-BicycleTheft-2023.gpkg\")\n\n\n\n\n\nOpenStreetMap (OSM) is a free, editable map of the world. Each map element (whether a point, line, or polygon) in OSM is tagged with various attribute data. To download the station data we need, we must use the appropriate tags, represented as key and value pairs, to query the OSM database. In our case, we are looking for train stations, which fall under the Public Transport key, with a value of station. To limit our search to London, we can use the spatial extent of the 2021 MSOA boundaries as the bounding box for data extraction.\n\n\n\nR code\n\n# define our bbox coordinates, use WGS84\nbbox_london &lt;- msoa21 |&gt;\n  st_transform(4326) |&gt;\n  st_bbox()\n\n# osm query\nosm_stations &lt;- opq(bbox = bbox_london) |&gt;\n  add_osm_feature(key = \"public_transport\", value = \"station\") |&gt;\n  osmdata_sf()\n\n\n\n\n\n\n\n\nIn some cases, the OSM query may return an error, particularly when multiple users from the same location are executing the exact same query. If so, you can download a prepared copy of the data here: [Download]. You can load this copy into R through load('data/spatial/London-OSM-Stations.RData')\n\n\n\nThe OSM query returns all data types, including lines and polygons tagged as stations. For our analysis, we only want to retain the point locations. In addition, we want to clip the results to the outline of London to exclude points that fall within the bounding box but outside the boundaries of Greater London.\n\n\n\nR code\n\n# extract points\nosm_stations &lt;- osm_stations$osm_points |&gt;\n    st_set_crs(4326) |&gt;\n    st_transform(27700) |&gt;\n    st_intersection(outline) |&gt;\n    select(c(\"osm_id\", \"name\", \"network\", \"operator\", \"public_transport\", \"railway\"))\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# inspect\nhead(osm_stations)\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 506148.8 ymin: 168292.6 xmax: 546593.8 ymax: 191714.7\nProjected CRS: OSGB36 / British National Grid\n           osm_id                   name                      network\n780856     780856 Shepherd's Bush Market           London Underground\n1256794   1256794           West Drayton National Rail;Elizabeth line\n2013971   2013971       Finchley Central           London Underground\n9780241   9780241           St Mary Cray                National Rail\n13330343 13330343               Woodford           London Underground\n13790683 13790683               Mile End           London Underground\n                   operator public_transport railway                  geometry\n780856   London Underground          station station POINT (523195.9 180061.9)\n1256794      Elizabeth line          station station POINT (506148.8 180085.4)\n2013971  London Underground          station station   POINT (525294.7 190658)\n9780241        Southeastern          station station POINT (546593.8 168292.6)\n13330343 London Underground    stop_position    stop POINT (540946.1 191714.7)\n13790683 London Underground    stop_position    stop   POINT (536524.6 182545)\n\n# inspect\nnrow(osm_stations)\n\n[1] 4056\n\n\nThe total number of data points seems rather high. In fact, looking at the railway variable, several points are not tagged as station or do not have a value at all:\n\n\n\nR code\n\n# inspect values\ncount(osm_stations, railway)\n\n\nSimple feature collection with 5 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 504982.3 ymin: 159027.2 xmax: 556185.7 ymax: 200138.6\nProjected CRS: OSGB36 / British National Grid\n                 railway    n                       geometry\n1                station  614 MULTIPOINT ((505078.2 17673...\n2                   stop   17 MULTIPOINT ((528197.7 18571...\n3        subway_entrance   38 MULTIPOINT ((525226.4 18745...\n4 train_station_entrance    1      POINT (538196.2 184826.5)\n5                   &lt;NA&gt; 3386 MULTIPOINT ((504982.3 17581...\n\n\nThe number of points tagged as station in the railway field are most likely the only points in our dataset that represent actual stations, so we will only retain those points.\n\n\n\nR code\n\n# extract train and underground stations\nosm_stations &lt;- osm_stations |&gt;\n    filter(railway == \"station\")\n\n\nLet’s map the dataset to get an idea of how the data looks like, using the outline of London as background:\n\n\n\nR code\n\n# shape\ntm_shape(outline) +\n\n  # map data\n  tm_polygons(\n    fill = \"#f0f0f0\",\n    col = NA\n  ) +\n\n  # shape\n  tm_shape(osm_stations) +\n\n  # map data\n  tm_symbols(\n    size = 0.2,\n    fill = \"#636363\",\n    col = \"#636363\",\n  ) +\n\n  # layout\n  tm_layout(\n    frame = FALSE,\n  )\n\n\n\n\n\nFigure 3: Train and underground stations in London.\n\n\n\n\nNow we have our data prepared, we can move on to analyse the extent to which bicycle theft in London cluster around stations. We can use both spatial queries and geometric operations to complete this analysis.\n\n\n\n\n\n\nWhen using osmdata to retrieve train stations in London, be aware that OpenStreetMap data may be incomplete or inconsistent due to different tagging practices by contributors, missing or outdated entries, and variations in how stations are classified. While verifying every detail is beyond the scope of this practical, it is essential to exercise due diligence when working with real-world data. Where possible triangulate with other authoritative sources such as official transport datasets and at the very least perform sanity checks to identify obvious anomalies.\n\n\n\n\n\n\nA spatial query is used to retrieve data based on its geographic location or spatial relationships. It uses spatial information from one or more layers to find features that meet specific criteria, such as proximity, intersection, or containment. For instance, we can use a spatial query to count all the bicycle thefts that have occurred within 500 metres of a train or underground station:\n\n\n\nR code\n\n# create a single station geometry\nosm_stations_comb &lt;- osm_stations |&gt;\n    st_union()\n\n# spatial query\ntheft_bike$d500 &lt;- theft_bike |&gt;\n    st_is_within_distance(osm_stations_comb, dist = 500, sparse = FALSE)\n\n# inspect\nhead(theft_bike)\n\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 531388 ymin: 180914 xmax: 533447 ymax: 181727.9\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 6 × 12\n  crime_id           month reported_by falls_within location lsoa_code lsoa_name\n  &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    \n1 62b0f525fc471c062… 2023… City of Lo… City of Lon… On or n… E01000002 City of …\n2 9a078d630cf67c37c… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n3 f175a32ef7f90c67a… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n4 137ec1201fd64b578… 2023… City of Lo… City of Lon… On or n… E01032739 City of …\n5 4c3b467755a98afa3… 2023… City of Lo… City of Lon… On or n… E01032740 City of …\n6 13b5eb5ca0aef09a2… 2023… City of Lo… City of Lon… On or n… E01032740 City of …\n# ℹ 5 more variables: crime_type &lt;chr&gt;, last_outcome_category &lt;chr&gt;,\n#   context &lt;lgl&gt;, geometry &lt;POINT [m]&gt;, d500 &lt;lgl[,1]&gt;\n\n\n\n\n\n\n\n\nThe above code converts the stations dataframe into a single geometry. This step is essential for sf to ensure that each point in the dataset is compared to every point in the stations dataframe. Without this conversion, the comparison would be done one station point at a time, storing only the last result rather than considering all station points simultaneously.\n\n\n\nWe can use the count() function to find out just how many thefts fall in each of these categories:\n\n\n\nR code\n\n# number of bicycle thefts within 500m of a station\ncount(theft_bike, d500)\n\n\nSimple feature collection with 2 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 384131 ymin: 101512 xmax: 612925 ymax: 398061.1\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 2 × 3\n  d500[,1]     n                                                        geometry\n* &lt;lgl&gt;    &lt;int&gt;                                                &lt;MULTIPOINT [m]&gt;\n1 FALSE     5485 ((384131 398061.1), (409823 101512), (494953 212260), (495917 …\n2 TRUE     10534 ((505376 184282.9), (505424 184212), (505433 184416), (505558 …\n\n\nMore than two-thirds of all reported bicycle thefts in London occur within 500 metres of a train or underground station. Of course, we can map the results for a visual inspection:\n\n\n\nR code\n\n# classify distances\ntheft_bike &lt;- theft_bike |&gt;\n  mutate(dist_class = if_else(d500 == TRUE, \"&gt; 500 m\", \"&lt; 500 m\")) |&gt;\n  mutate(dist_class = factor(dist_class, levels = c(\"&gt; 500 m\", \"&lt; 500 m\")))\n\n# shape\ntm_shape(outline) +\n\n  # map data\n  tm_polygons(\n    fill = \"#f0f0f0\",\n    col = NA\n  ) +\n\n  # shape\n  tm_shape(theft_bike) +\n\n  # map data\n  tm_symbols(\n    # map data\n    col = \"dist_class\",\n    size = 0.1,\n    col.scale = tm_scale_categorical(\n      values = c(\n        \"&gt; 500 m\" = \"#fdc086\",\n        \"&lt; 500 m\" = \"#998ec3\"\n      ),\n    ),\n\n    # legend\n    col.legend = tm_legend(\n      title = \"\",\n      frame = FALSE,\n    )\n  ) +\n\n  # shape\n  tm_shape(osm_stations) +\n\n  # map data\n  tm_symbols(\n    size = 0.2,\n    fill = \"#636363\",\n    col = \"#636363\",\n  ) +\n\n  # legend\n  tm_add_legend(\n    type = \"symbols\",\n    labels = \"Station\",\n    size = 0.2,\n    fill = \"#636363\"\n  ) +\n\n  # layout\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.0, 0.2),\n    legend.text.size = 0.7,\n\n    # canvas\n    frame = FALSE\n  )\n\n\n\n\n\nFigure 4: Reported bicycle thefts in London within 500 metres from a train or underground station.\n\n\n\n\n\n\n\nGeometric operations are used to manipulate and analyse the shapes and spatial properties of geometric objects, such as points, lines, and polygons. These operations include tasks like calculating intersections, buffering, and determining the distance between shapes. In this case, we can create 500-metre buffers around each station and then count how many bicycle thefts fall within these buffers.\n\n\n\nR code\n\n# buffer\nosm_stations_buffer &lt;- osm_stations |&gt;\n    st_buffer(dist = 500) |&gt;\n    st_union()\n\n# inspect\nhead(osm_stations_buffer)\n\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 504578.2 ymin: 158527.2 xmax: 556685.7 ymax: 200638.6\nProjected CRS: OSGB36 / British National Grid\n\n\nMULTIPOLYGON (((517709.6 169311.1, 517686.6 169...\n\n\n\n\n\n\n\n\nWhen performing buffer analysis, the buffer sizes are determined by the units of the coordinate reference system (CRS) used. For instance, with the British National Grid, where the CRS is in metres, the buffer distance must be specified in metres.\n\n\n\nWe can map the results for a visual inspection:\n\n\n\nR code\n\n# shape\ntm_shape(outline) +\n\n  # map data\n  tm_polygons(\n    fill = \"#f0f0f0\",\n    col = NA\n  ) +\n\n  # shape\n  tm_shape(osm_stations_buffer) +\n\n  # specify colours\n  tm_polygons(\n    fill = \"#beaed4\",\n  ) +\n\n  # layout\n  tm_layout(\n    # canvas\n    frame = FALSE\n  )\n\n\n\n\n\nFigure 5: Train and underground stations in London with a 500 metres buffer.\n\n\n\n\nWe can now use the st_intersects function to find out which reported bicycle thefts have occurred within 500 metres of a train or underground station.\n\n\n\nR code\n\n# intersect buffer with bicycle thefts\ntheft_bike$d500_buffer &lt;- theft_bike |&gt;\n    st_intersects(osm_stations_buffer, sparse = FALSE)\n\n# number of bicycle thefts within 500m of a station\ncount(theft_bike, d500_buffer)\n\n\nSimple feature collection with 2 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 384131 ymin: 101512 xmax: 612925 ymax: 398061.1\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 2 × 3\n  d500_buffer[,1]     n                                                 geometry\n* &lt;lgl&gt;           &lt;int&gt;                                         &lt;MULTIPOINT [m]&gt;\n1 FALSE            5491 ((384131 398061.1), (409823 101512), (494953 212260), (…\n2 TRUE            10528 ((505376 184282.9), (505424 184212), (505433 184416), (…\n\n\n\n\n\n\n\n\nThe results are almost identical, with a small difference due to how the two methods define within and handle spatial relationships and boundaries. For instance, a point on the buffer’s edge will be included in the intersect method, but may not meet the distance threshold required by st_within_distance()."
  },
  {
    "objectID": "02-operations.html#assignment",
    "href": "02-operations.html#assignment",
    "title": "1 Spatial Queries and Geometric Operations",
    "section": "",
    "text": "Now that we are familiar with basic spatial queries and geometric operations, we can conduct a similar analysis on the number of serious and fatal road crashed in London in 2022 and determine how many occurred on or near a main road. Try to do the following:\n\nDownload the two datasets provided below and save them in the appropriate subfolder within your data directory. The datasets include:\n\nA csv file containing the number of road crashes that occurred in London in 2022, extracted from the UK’s official road traffic casualty database using the stats19 R library.\nA GeoPackage file that contains main roads in London, extracted from the Ordnance Survey Open Roads dataset.\n\nCalculate the number of serious and fatal road crashes that occurred within 100 metres and 500 metres of a main road.\n\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon STATS19 Road Collisions 2022\ncsv\nDownload\n\n\nLondon OS Open Roads - Main Roads\nGeoPackage\nDownload"
  },
  {
    "objectID": "02-operations.html#before-you-leave",
    "href": "02-operations.html#before-you-leave",
    "title": "1 Spatial Queries and Geometric Operations",
    "section": "",
    "text": "Boom. That is how you can conduct basic spatial queries and geometric operations and using R and sf. Yet more RGIS coming over the next couple of weeks, but this concludes the tutorial for this week. Time to check out that reading list?"
  },
  {
    "objectID": "01-spatial.html",
    "href": "01-spatial.html",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "This week’s lecture offered a comprehensive introduction to the Geocomputation module, highlighting how and why it differs from a traditional GIScience course. In this week’s tutorial, we will introduce you to using R and RStudio for working with spatial data, focusing specifically on how R can be used to make maps.\n\n\nYou can download the slides of this week’s lecture here: [Link].\n\n\n\n\n\n\nBrunsdon, C. and Comber, A. 2021. Opening practice: Supporting reproducibility and critical spatial data science. Journal of Geographical Systems 23: 477–496. [Link]\nFranklin, R. 2023. Quantitative methods III: Strength in numbers? Progress in Human Geography. Online First. [Link].\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 1: Geographic Information: Science, Systems, and Society, pp. 1-32. [Link]\n\n\n\n\n\nGoodchild, M. 2009. Geographic information systems and science: Today and tomorrow. Annals of GIS 15(1): 3-9. [Link]\nFranklin, S., Houlden, V., Robinson, C. et al. 2021. Who counts? Gender, Gatekeeping, and Quantitative Human Geography. The Professional Geographer 73(1): 48-61. [Link]\nSchurr, C., Müller, M. and Imhof, N. 2020. Who makes geographical knowledge? The gender of Geography’s gatekeepers. The Professional Geographer 72(3): 317-331. [Link]\nYuan, M. 2001. Representing complex geographic phenomena in GIS. Cartography and Geographic Information Science 28(2): 83-96. [Link]\n\n\n\n\n\nIn RStudio, scripts allow us to build and save code that can be run repeatedly. We can organise these scripts into RStudio projects, which consolidate all files related to an analysis such as input data, R scripts, results, figures, and more. This organisation helps keep track of all data, input, and output, while enabling us to create standalone scripts for each part of our analysis.\nNavigate to File -&gt; New Project -&gt; New Directory. Choose a directory name, such as GEOG0030, and select the location on your computer where you want to save this project by clicking on Browse…. Click on Create Project.\n\n\n\n\n\n\nEnsure you select an appropriate folder to store your GEOG0030 project. For example, you might use your Geocomputation folder, if you have one, or another location within your Documents directory on your computer.\n\n\n\n\n\n\n\n\n\nPlease ensure that folder names and file names do not contain spaces or special characters such as * . \" / \\ [ ] : ; | = , &lt; ? &gt; & $ # ! ' { } ( ). Different operating systems and programming languages deal differently with spaces and special characters and as such including these in your folder names and file names can cause many problems and unexpected errors. As an alternative to using white space you can use an underscore (_) or hyphen (-) if you like.\n\n\n\nYou should now see your main RStudio window switch to this new project and when you check your files pane, you should see a new R Project called GEOG0030.\nWith our GEOG0030 project ready to go, in this first tutorial we will look at the distribution of the share of European immigrants across London. The data covers the number of people residing in London that are born in a European country, as recorded in the 2021 Census for England and Wales, aggregated at the Middle Layer Super Output Area (MSOA) level.\n\n\n\n\n\n\nAn MSOA is a geographic unit used in the UK for statistical analysis. It typically represents small areas with populations of around 5,000 to 15,000 people and is designed to ensure consistent data reporting. MSOAs are commonly used to report on census data, deprivation indices, and other socio-economic statistics.\n\n\n\nThe dataset has been extracted using the Custom Dataset Tool, and you can download the file via the link provided below. Save the file in your project folder under data/attributes. Along with this dataset, we also have access to a GeoPackage that contains the MSOA boundaries. Save this file under data/spatial, respectively.\n\n\n\n\n\n\nYou will to have create a folder named data within your RStudio Project directory, inside which you will have to have a folder named attributes and a folder named spatial.\n\n\n\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon MSOA Census 2021 European Population\ncsv\nDownload\n\n\nLondon MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\n\n\n\n\nTo download a csv file that is hosted on GitHub, click on the Download raw file button on the top right of your screen and it should download directly to your computer.\n\n\n\n\n\n\n\n\n\nYou may have used spatial data before and noticed that we did not download a collection of files known as a shapefile but a GeoPackage instead. Whilst shapefiles are still being used, GeoPackage is a more modern and portable file format. Have a look at this article on towardsdatascience.com for an excellent explanation on why one should use GeoPackage files over shapefiles where possible: [Link]\n\n\n\nTo get started, let us create our first script. File -&gt; New File -&gt; R Script. Save your script as w01-european-population-london.r.\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\n\n\n\n\n\n\nFor Linux and macOS users who are new to working with spatial data in R, the installation of the sf library may fail because additional (non-R) libraries are required which are automatically installed for Windows users. If you encounter installation issues,, please refer to the information pages of the sf library for instructions on how to install these additional libraries.\n\n\n\nOnce downloaded, we can load both files into memory:\n\n\n\nR code\n\n# read spatial dataset\nmsoa21 &lt;- st_read(\"data/spatial/London-MSOA-2021.gpkg\")\n\n\nReading layer `London-MSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-MSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1002 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# load attribute dataset\nmsoa_eur &lt;- read_csv(\"data/attributes/London-MSOA-European.csv\")\n\nRows: 1002 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): msoa21cd\ndbl (2): eur21, pop21\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# inspect\nhead(msoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid                           geom\n1 {71249043-B176-4306-BA6C-D1A993B1B741} MULTIPOLYGON (((532135.1 18...\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E} MULTIPOLYGON (((548881.6 19...\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B} MULTIPOLYGON (((549102.4 18...\n4 {511181CD-E71F-4C63-81EE-E8E76744A627} MULTIPOLYGON (((551550.1 18...\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87} MULTIPOLYGON (((549099.6 18...\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1} MULTIPOLYGON (((549819.9 18...\n\n# inspect\nhead(msoa_eur)\n\n# A tibble: 6 × 3\n  msoa21cd  eur21 pop21\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 E02000001  1926  8582\n2 E02000002  1102  8280\n3 E02000003  1930 11542\n4 E02000004   808  6640\n5 E02000005  1541 11082\n6 E02000007  1365 10159\n\n\n\n\n\n\n\n\nYou can further inspect both objects using the View() function.\n\n\n\n\n\nThe first thing we want to do when we load spatial data is to plot the data to check whether everything is in order. To do this, we can simply use the base R plot() function\n\n\n\nR code\n\n# plot data\nplot(msoa21, max.plot = 1, main = \"\")\n\n\n\n\n\nFigure 1: Quick plot to inspect the MSOA spatial data.\n\n\n\n\nYou should see your msoa21 plot appear in your Plots window.\n\n\n\n\n\n\nThe plot() function should not to be used to make publishable maps but can be used as a quick way of inspecting your spatial data.\n\n\n\nJust as with a tabular dataframe, we can inspect the attributes of the spatial data frame:\n\n\n\nR code\n\n# inspect columns\nncol(msoa21)\n\n\n[1] 9\n\n# inspect rows\nnrow(msoa21)\n\n[1] 1002\n\n# inspect data\nhead(msoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid                           geom\n1 {71249043-B176-4306-BA6C-D1A993B1B741} MULTIPOLYGON (((532135.1 18...\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E} MULTIPOLYGON (((548881.6 19...\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B} MULTIPOLYGON (((549102.4 18...\n4 {511181CD-E71F-4C63-81EE-E8E76744A627} MULTIPOLYGON (((551550.1 18...\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87} MULTIPOLYGON (((549099.6 18...\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1} MULTIPOLYGON (((549819.9 18...\n\n# inspect column names\nnames(msoa21)\n\n[1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n[7] \"long\"      \"globalid\"  \"geom\"     \n\n\nWe can further establish the class of our data:\n\n\n\nR code\n\n# inspect\nclass(msoa21)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nWe should see our data is an sf dataframe, which is what we want.\n\n\n\nNow we have our dataset containing London’s European born population and the MSOA spatial boundaries loaded, we can join these together using an Attribute Join. Before proceeding with the join, we need to verify that a matching unique identifier exists in both datasets. Let’s look at the column names in our datasets again:\n\n\n\nR code\n\n# inspect column names\nnames(msoa21)\n\n\n[1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n[7] \"long\"      \"globalid\"  \"geom\"     \n\n# inspect column names\nnames(msoa_eur)\n\n[1] \"msoa21cd\" \"eur21\"    \"pop21\"   \n\n\nThe msoa21cd columns looks promising as it features in both datasets. We can quickly sort both columns and have a peek at the data:\n\n\n\nR code\n\n# inspect spatial dataset\nhead(sort(msoa21$msoa21cd))\n\n\n[1] \"E02000001\" \"E02000002\" \"E02000003\" \"E02000004\" \"E02000005\" \"E02000007\"\n\n# inspect attribute dataset\nhead(sort(msoa_eur$msoa21cd))\n\n[1] \"E02000001\" \"E02000002\" \"E02000003\" \"E02000004\" \"E02000005\" \"E02000007\"\n\n\nThey seem to contain similar values, so that is promising. Let us try to join the attribute data onto the spatial data:\n\n\n\nR code\n\n# join attribute data onto spatial data\nmsoa21 &lt;- msoa21 |&gt; \n  left_join(msoa_eur, by = c('msoa21cd' = 'msoa21cd'))\n\n\n\n\n\n\n\n\nThe code above uses a pipe function: |&gt;. The pipe operator allows you to pass the output of one function directly into the next, streamlining your code. While it might be a bit confusing at first, you will find that it makes your code faster to write and easier to read. More importantly, it reduces the need to create multiple intermediate variables to store outputs.\n\n\n\nWe can explore the joined data in usual fashion:\n\n\n\nR code\n\n# inspect columns\nncol(msoa21)\n\n\n[1] 11\n\n# inspect rows\nnrow(msoa21)\n\n[1] 1002\n\n# inspect data\nhead(msoa21)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid eur21 pop21\n1 {71249043-B176-4306-BA6C-D1A993B1B741}  1926  8582\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E}  1102  8280\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B}  1930 11542\n4 {511181CD-E71F-4C63-81EE-E8E76744A627}   808  6640\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87}  1541 11082\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1}  1365 10159\n                            geom\n1 MULTIPOLYGON (((532135.1 18...\n2 MULTIPOLYGON (((548881.6 19...\n3 MULTIPOLYGON (((549102.4 18...\n4 MULTIPOLYGON (((551550.1 18...\n5 MULTIPOLYGON (((549099.6 18...\n6 MULTIPOLYGON (((549819.9 18...\n\n# inspect column names\nnames(msoa21)\n\n [1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n [7] \"long\"      \"globalid\"  \"eur21\"     \"pop21\"     \"geom\"     \n\n\nAlways inspect your join to ensure everything looks as expected. A good way to do this is by using the View() function to check for any unexpected missing values, which are marked as NA.\nWe can also compare the total number of rows in the spatial dataset with the total number of non-NA values in the joined columns:\n\n\n\nR code\n\n# inspect\nnrow(msoa21)\n\n\n[1] 1002\n\n# check for missing values\nsum(!is.na(msoa21$eur21))\n\n[1] 1002\n\n# check for missing values\nsum(!is.na(msoa21$pop21))\n\n[1] 1002\n\n\nNo missing values. In this case we did not expect any missing values, so this confirms that all our full attribute dataset has been linked to the spatial dataset.\nWe are almost ready to map the data. Only thing that is left is for us to calculate the share of European-born immigrants within each MSOA:\n\n\n\nR code\n\n# calculate proportion\nmsoa21 &lt;- msoa21 |&gt;\n    mutate(prop_eur21 = eur21/pop21)\n\n\n\n\n\nFor our map-making, we will use one of the two primary visualisation libraries for spatial data: tmap. tmap offers a flexible, layer-based approach that makes it easy to create various types of thematic maps, such as choropleths and proportional symbol maps. One of the standout features of tmap is its quick plotting function, qtm(), which allows you to generate basic maps with minimal effort.\n\n\n\nR code\n\n# quick thematic map\nqtm(msoa21, fill = \"prop_eur21\")\n\n\n\n\n\nFigure 2: Quick thematic map.\n\n\n\n\nIn this case, the fill() argument in tmap is how we instruct the library to create a choropleth map based on the values in the specified column. If we set fill() to NULL, only the borders of our polygons will be drawn, without any colour fill. The qtm() function in tmap is versatile, allowing us to pass various parameters to customise the aesthetics of our map. By checking the function’s documentation, you can explore the full list of available parameters. For instance, to set the MSOA borders to white, we can use the borders parameter:\n\n\n\nR code\n\n# quick thematic map\nqtm(msoa21, fill = \"prop_eur21\", col = \"white\")\n\n\n\n\n\nFigure 3: Quick thematic map with white borders.\n\n\n\n\nThe map does not look quite right yet. While we can continue tweaking parameters in the qtm() function to improve it, qtm() is somewhat limited in its functionality and is primarily intended for quickly inspecting your data and creating basic maps. For more complex and refined map-making with the tmap library, it is better to use the main plotting method that starts with the tm_shape() function.\n\n\n\n\n\n\nThe primary approach to creating maps in tmap involves using a layered grammar of graphics to build up your map, starting with the tm_shape() function. This function, when provided with a spatial dataframe, captures the spatial information of your data, including its projection and geometry, and creates a spatial object. While you can override certain aspects of the spatial data (such as its projection) using the function’s parameters, the essential role of tm_shape() is to instruct R to “use this object as the basis for drawing the shapes.”\nTo actually render the shapes, you need to add a layer that specifies the type of shape you want R to draw from this spatial information — such as polygons for our data. This layer function tells R to “draw my spatial object as X”, where X represents the type of shape. Within this layer, you can also provide additional details to control how R draws your shapes. Further, you can add more layers to include other spatial objects and their corresponding shapes on your map. Finally, layout options can be specified through a layout layer, allowing you to customise the overall appearance and arrangement of your map.\n\n\n\nLet us build a map using tmap:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # map data\n  tm_polygons()\n\n\n\n\n\nFigure 4: Building up a map layer by layer.\n\n\n\n\nAs you can now see, we have mapped the spatial polygons of our msoa21 spatial dataframe. However, this is not quite the map we want; we need a choropleth map where the polygons are coloured based on the proportion of European immigrants. To achieve this, we use the col parameter within the tm_polygons() function.\n\n\n\n\n\n\nThe fill parameter within tm_polygons() allows you to fill polygons with colours based on:\n\nA single colour value (e.g. red or #fc9272).\nThe name of a data variable within the spatial data file. This variable can either contain specific colour values or numeric/categorical values that will be mapped to a colour palette.\n\n\n\n\nLet us go ahead and pass our prop_eur21 variable within the fill() parameter and see what we get:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # map data\n  tm_polygons(\n    fill = \"prop_eur21\"\n  )\n\n\n\n\n\nFigure 5: Building up a map layer by layer.\n\n\n\n\nWe are making progress, but there are two immediate issues with our map. First, the classification breaks do not adequately reflect the variation in our dataset. By default, tmap uses pretty breaks, which may not be the most effective for our data. An alternative, such as natural breaks (or jenks), might better reveal the data’s variation.\nTo customise the classification breaks, refer to the tm_polygons() documentation. The following parameters are relevant:\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\nfill.scale\nDefines the color scale for polygon fills. Accepts a scale object created by functions such as tm_scale_continuous() and tm_intervals()\n\n\ntm_scale_continuous()\nCreates a continuous scale object for mapping numeric values to colours. You can specify options such as palette (color scheme) and limits (data range).\n\n\ntm_scale_intervals()\nCreates a scale object for mapping data into discrete classes (intervals). Parameters include: n (number of classes) and style (classification method: e.g. quantile, equal, jenks)\n\n\n\nFor example, if we want to adjust our choropleth map to use five classes determined by the natural breaks method, we need to specify the n and style parameters as follows:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # map data\n  tm_polygons(\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(n = 5, style = \"jenks\"),\n  )\n\n\n\n\n\nFigure 6: Building up a map layer by layer.\n\n\n\n\n\n\n\n\nStyling a map in tmap requires a deeper understanding and familiarity with the library, which is something you will develop best through hands-on practice. Here are the key functions to be aware of:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\ntm_layout()\nCustomises overall map layout, including titles, fonts, legend position, margins, and frame settings.\n\n\ntm_compass()\nAdds a compass or North arrow to the map, with options for size, position, and style.\n\n\ntm_scale_bar()\nAdds a scale bar to indicate distance, with options for units, position, and styling.\n\n\n\nTo begin styling your map, explore each of these functions and their parameters. Through trial and error, you can tweak and refine the map until you achieve the desired look:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # map data\n  tm_polygons(\n    # map data\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(\n      n = 5, style = \"jenks\",\n      values = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n      labels = c(\"Smallest share\", \"2nd smallest\", \"3rd smallest\", \"4th smallest\", \"Largest share\"),\n    ),\n\n    # legend\n    fill.legend = tm_legend(\n      title = \"Share of population\",\n      na.text = \"No population\",\n      frame = FALSE,\n    ),\n\n    # borders\n    col = \"#ffffff\",\n    col_alpha = 0.3\n  ) +\n\n  # title\n  tm_title(\n    text = \"Share of population born in Europe\"\n  ) +\n\n  # layout\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.90, 1.00),\n    legend.title.size = 0.7,\n    legend.title.fontface = \"bold\",\n    legend.text.size = 0.55,\n\n    # canvas\n    inner.margins = c(0.05, 0.05, 0.05, 0.05),\n    frame = FALSE,\n  ) +\n\n  # North arrow\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"left\", \"top\"),\n    size = 1,\n    text.size = 0.7\n  ) +\n\n  # scale bar\n  tm_scalebar(\n    breaks = c(0, 5, 10, 15, 20),\n    position = c(0.85, 0.20),\n    text.size = 0.4\n  )\n\n\n\n\n\nFigure 7: Building up a map layer by layer.\n\n\n\n\nWe can also have some map labels, if we want, by extracting centroids from selected polygons and adding these as separate map layer:\n\n\n\nR code\n\n# map labels\nlab &lt;- msoa21 |&gt;\n  filter(msoa21cd == \"E02000642\" | msoa21cd == \"E02000180\") |&gt;\n  st_centroid()\n\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n# map object\nlon_eurpop &lt;-\n  # shape\n  tm_shape(msoa21) +\n\n  # map data\n  tm_polygons(\n    # map data\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(\n      n = 5, style = \"jenks\",\n      values = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n      labels = c(\"Smallest share\", \"2nd smallest\", \"3rd smallest\", \"4th smallest\", \"Largest share\"),\n    ),\n\n    # legend\n    fill.legend = tm_legend(\n      title = \"Share of population\",\n      na.text = \"No population\",\n      frame = FALSE,\n    ),\n\n    # borders\n    col = \"#ffffff\",\n    col_alpha = 0.3\n  ) +\n\n  # shape\n  tm_shape(lab) +\n\n  # centroids\n  tm_symbols(\n    size = 0.4,\n    col = \"#000000\",\n    fill = \"#000000\"\n  ) +\n\n  # labels\n  tm_text(\n    text = \"msoa21nm\",\n    col = \"#000000\",\n    size = 0.8,\n    xmod = 0,\n    ymod = -0.8,\n    bgcol = \"#f0f0f0\",\n    bgcol_alpha = 0.5\n  ) +\n\n  # title\n  tm_title(\n    text = \"Share of population born in Europe\"\n  ) +\n\n  # layout\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.90, 1.00),\n    legend.title.size = 0.7,\n    legend.title.fontface = \"bold\",\n    legend.text.size = 0.55,\n\n    # canvas\n    inner.margins = c(0.05, 0.05, 0.05, 0.05),\n    frame = FALSE,\n  ) +\n\n  # North arrow\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"left\", \"top\"),\n    size = 1,\n    text.size = 0.7\n  ) +\n\n  # scale bar\n  tm_scalebar(\n    breaks = c(0, 5, 10, 15, 20),\n    position = c(0.85, 0.20),\n    text.size = 0.4\n  )\n\n# plot\nlon_eurpop\n\n\n\n\nFigure 8: Building up a map layer by layer.\n\n\n\n\nIn the code above, we stored the full map definition as an object. This makes it easy to export the map and save it as a .jpg, .png or .pdf file:\n\n\n\nR code\n\n# write map\ntmap_save(tm = lon_eurpop, filename = \"london-european-population.jpg\", width = 15,\n    height = 15, units = c(\"cm\"))\n\n\n\n\n\nNow that we have prepared our dataset and created our initial maps in R, we can also try and map the distribution of the proportion of European immigrants across Wales and experiment with different mapping parameters. Follow these steps:\n\nDownload the two datasets provided below and save them in the appropriate subfolder within your data directory. The datasets include:\n\nA csv file containing the number of people residing in Wales that are born in a European country, as recorded in the 2021 Census for England and Wales, aggregated at the MSOA level.\nA GeoPackage file containing the 2021 MSOA spatial boundaries for England and Wales.\n\nLoad both datasets and merge them together. Make sure to only retain those MSOAs that belong to Wales.\nCreate a map that shows the proportion of the population residing in Wales that is born in Europe.\nExperiment by adjusting various map parameters, such as the colour scheme, map labels, and data classification method.\n\n\n\n\nFile\nType\nLink\n\n\n\n\nWales MSOA Census 2021 European Population\ncsv\nDownload\n\n\nEngland and Wales MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\n\nAnd that is how you use R as a GIS in its most basic form. More RGIS in the coming weeks, but this concludes the tutorial for this week."
  },
  {
    "objectID": "01-spatial.html#lecture-slides",
    "href": "01-spatial.html#lecture-slides",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "You can download the slides of this week’s lecture here: [Link]."
  },
  {
    "objectID": "01-spatial.html#reading-list",
    "href": "01-spatial.html#reading-list",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "Brunsdon, C. and Comber, A. 2021. Opening practice: Supporting reproducibility and critical spatial data science. Journal of Geographical Systems 23: 477–496. [Link]\nFranklin, R. 2023. Quantitative methods III: Strength in numbers? Progress in Human Geography. Online First. [Link].\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 1: Geographic Information: Science, Systems, and Society, pp. 1-32. [Link]\n\n\n\n\n\nGoodchild, M. 2009. Geographic information systems and science: Today and tomorrow. Annals of GIS 15(1): 3-9. [Link]\nFranklin, S., Houlden, V., Robinson, C. et al. 2021. Who counts? Gender, Gatekeeping, and Quantitative Human Geography. The Professional Geographer 73(1): 48-61. [Link]\nSchurr, C., Müller, M. and Imhof, N. 2020. Who makes geographical knowledge? The gender of Geography’s gatekeepers. The Professional Geographer 72(3): 317-331. [Link]\nYuan, M. 2001. Representing complex geographic phenomena in GIS. Cartography and Geographic Information Science 28(2): 83-96. [Link]"
  },
  {
    "objectID": "01-spatial.html#europeans-in-london",
    "href": "01-spatial.html#europeans-in-london",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "In RStudio, scripts allow us to build and save code that can be run repeatedly. We can organise these scripts into RStudio projects, which consolidate all files related to an analysis such as input data, R scripts, results, figures, and more. This organisation helps keep track of all data, input, and output, while enabling us to create standalone scripts for each part of our analysis.\nNavigate to File -&gt; New Project -&gt; New Directory. Choose a directory name, such as GEOG0030, and select the location on your computer where you want to save this project by clicking on Browse…. Click on Create Project.\n\n\n\n\n\n\nEnsure you select an appropriate folder to store your GEOG0030 project. For example, you might use your Geocomputation folder, if you have one, or another location within your Documents directory on your computer.\n\n\n\n\n\n\n\n\n\nPlease ensure that folder names and file names do not contain spaces or special characters such as * . \" / \\ [ ] : ; | = , &lt; ? &gt; & $ # ! ' { } ( ). Different operating systems and programming languages deal differently with spaces and special characters and as such including these in your folder names and file names can cause many problems and unexpected errors. As an alternative to using white space you can use an underscore (_) or hyphen (-) if you like.\n\n\n\nYou should now see your main RStudio window switch to this new project and when you check your files pane, you should see a new R Project called GEOG0030.\nWith our GEOG0030 project ready to go, in this first tutorial we will look at the distribution of the share of European immigrants across London. The data covers the number of people residing in London that are born in a European country, as recorded in the 2021 Census for England and Wales, aggregated at the Middle Layer Super Output Area (MSOA) level.\n\n\n\n\n\n\nAn MSOA is a geographic unit used in the UK for statistical analysis. It typically represents small areas with populations of around 5,000 to 15,000 people and is designed to ensure consistent data reporting. MSOAs are commonly used to report on census data, deprivation indices, and other socio-economic statistics.\n\n\n\nThe dataset has been extracted using the Custom Dataset Tool, and you can download the file via the link provided below. Save the file in your project folder under data/attributes. Along with this dataset, we also have access to a GeoPackage that contains the MSOA boundaries. Save this file under data/spatial, respectively.\n\n\n\n\n\n\nYou will to have create a folder named data within your RStudio Project directory, inside which you will have to have a folder named attributes and a folder named spatial.\n\n\n\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon MSOA Census 2021 European Population\ncsv\nDownload\n\n\nLondon MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\n\n\n\n\nTo download a csv file that is hosted on GitHub, click on the Download raw file button on the top right of your screen and it should download directly to your computer.\n\n\n\n\n\n\n\n\n\nYou may have used spatial data before and noticed that we did not download a collection of files known as a shapefile but a GeoPackage instead. Whilst shapefiles are still being used, GeoPackage is a more modern and portable file format. Have a look at this article on towardsdatascience.com for an excellent explanation on why one should use GeoPackage files over shapefiles where possible: [Link]\n\n\n\nTo get started, let us create our first script. File -&gt; New File -&gt; R Script. Save your script as w01-european-population-london.r.\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\n\n\n\n\n\n\nFor Linux and macOS users who are new to working with spatial data in R, the installation of the sf library may fail because additional (non-R) libraries are required which are automatically installed for Windows users. If you encounter installation issues,, please refer to the information pages of the sf library for instructions on how to install these additional libraries.\n\n\n\nOnce downloaded, we can load both files into memory:\n\n\n\nR code\n\n# read spatial dataset\nmsoa21 &lt;- st_read(\"data/spatial/London-MSOA-2021.gpkg\")\n\n\nReading layer `London-MSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-MSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1002 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# load attribute dataset\nmsoa_eur &lt;- read_csv(\"data/attributes/London-MSOA-European.csv\")\n\nRows: 1002 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): msoa21cd\ndbl (2): eur21, pop21\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# inspect\nhead(msoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid                           geom\n1 {71249043-B176-4306-BA6C-D1A993B1B741} MULTIPOLYGON (((532135.1 18...\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E} MULTIPOLYGON (((548881.6 19...\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B} MULTIPOLYGON (((549102.4 18...\n4 {511181CD-E71F-4C63-81EE-E8E76744A627} MULTIPOLYGON (((551550.1 18...\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87} MULTIPOLYGON (((549099.6 18...\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1} MULTIPOLYGON (((549819.9 18...\n\n# inspect\nhead(msoa_eur)\n\n# A tibble: 6 × 3\n  msoa21cd  eur21 pop21\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 E02000001  1926  8582\n2 E02000002  1102  8280\n3 E02000003  1930 11542\n4 E02000004   808  6640\n5 E02000005  1541 11082\n6 E02000007  1365 10159\n\n\n\n\n\n\n\n\nYou can further inspect both objects using the View() function.\n\n\n\n\n\nThe first thing we want to do when we load spatial data is to plot the data to check whether everything is in order. To do this, we can simply use the base R plot() function\n\n\n\nR code\n\n# plot data\nplot(msoa21, max.plot = 1, main = \"\")\n\n\n\n\n\nFigure 1: Quick plot to inspect the MSOA spatial data.\n\n\n\n\nYou should see your msoa21 plot appear in your Plots window.\n\n\n\n\n\n\nThe plot() function should not to be used to make publishable maps but can be used as a quick way of inspecting your spatial data.\n\n\n\nJust as with a tabular dataframe, we can inspect the attributes of the spatial data frame:\n\n\n\nR code\n\n# inspect columns\nncol(msoa21)\n\n\n[1] 9\n\n# inspect rows\nnrow(msoa21)\n\n[1] 1002\n\n# inspect data\nhead(msoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid                           geom\n1 {71249043-B176-4306-BA6C-D1A993B1B741} MULTIPOLYGON (((532135.1 18...\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E} MULTIPOLYGON (((548881.6 19...\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B} MULTIPOLYGON (((549102.4 18...\n4 {511181CD-E71F-4C63-81EE-E8E76744A627} MULTIPOLYGON (((551550.1 18...\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87} MULTIPOLYGON (((549099.6 18...\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1} MULTIPOLYGON (((549819.9 18...\n\n# inspect column names\nnames(msoa21)\n\n[1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n[7] \"long\"      \"globalid\"  \"geom\"     \n\n\nWe can further establish the class of our data:\n\n\n\nR code\n\n# inspect\nclass(msoa21)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nWe should see our data is an sf dataframe, which is what we want.\n\n\n\nNow we have our dataset containing London’s European born population and the MSOA spatial boundaries loaded, we can join these together using an Attribute Join. Before proceeding with the join, we need to verify that a matching unique identifier exists in both datasets. Let’s look at the column names in our datasets again:\n\n\n\nR code\n\n# inspect column names\nnames(msoa21)\n\n\n[1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n[7] \"long\"      \"globalid\"  \"geom\"     \n\n# inspect column names\nnames(msoa_eur)\n\n[1] \"msoa21cd\" \"eur21\"    \"pop21\"   \n\n\nThe msoa21cd columns looks promising as it features in both datasets. We can quickly sort both columns and have a peek at the data:\n\n\n\nR code\n\n# inspect spatial dataset\nhead(sort(msoa21$msoa21cd))\n\n\n[1] \"E02000001\" \"E02000002\" \"E02000003\" \"E02000004\" \"E02000005\" \"E02000007\"\n\n# inspect attribute dataset\nhead(sort(msoa_eur$msoa21cd))\n\n[1] \"E02000001\" \"E02000002\" \"E02000003\" \"E02000004\" \"E02000005\" \"E02000007\"\n\n\nThey seem to contain similar values, so that is promising. Let us try to join the attribute data onto the spatial data:\n\n\n\nR code\n\n# join attribute data onto spatial data\nmsoa21 &lt;- msoa21 |&gt; \n  left_join(msoa_eur, by = c('msoa21cd' = 'msoa21cd'))\n\n\n\n\n\n\n\n\nThe code above uses a pipe function: |&gt;. The pipe operator allows you to pass the output of one function directly into the next, streamlining your code. While it might be a bit confusing at first, you will find that it makes your code faster to write and easier to read. More importantly, it reduces the need to create multiple intermediate variables to store outputs.\n\n\n\nWe can explore the joined data in usual fashion:\n\n\n\nR code\n\n# inspect columns\nncol(msoa21)\n\n\n[1] 11\n\n# inspect rows\nnrow(msoa21)\n\n[1] 1002\n\n# inspect data\nhead(msoa21)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180512.6 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   msoa21cd                 msoa21nm msoa21nmw  bng_e  bng_n      lat      long\n1 E02000001       City of London 001           532384 181355 51.51562 -0.093490\n2 E02000002 Barking and Dagenham 001           548267 189685 51.58652  0.138756\n3 E02000003 Barking and Dagenham 002           548259 188520 51.57606  0.138149\n4 E02000004 Barking and Dagenham 003           551004 186412 51.55639  0.176828\n5 E02000005 Barking and Dagenham 004           548733 186824 51.56069  0.144267\n6 E02000007 Barking and Dagenham 006           549698 186609 51.55851  0.158087\n                                globalid eur21 pop21\n1 {71249043-B176-4306-BA6C-D1A993B1B741}  1926  8582\n2 {997A80A8-0EBE-461C-91EB-3E4122571A6E}  1102  8280\n3 {62DED9D9-F53A-454D-AF35-04404D9DBE9B}  1930 11542\n4 {511181CD-E71F-4C63-81EE-E8E76744A627}   808  6640\n5 {B0C823EB-69E0-4AE7-9E1C-37715CF3FE87}  1541 11082\n6 {A33C6ADD-D70A-4737-ADE5-3460D7016CA1}  1365 10159\n                            geom\n1 MULTIPOLYGON (((532135.1 18...\n2 MULTIPOLYGON (((548881.6 19...\n3 MULTIPOLYGON (((549102.4 18...\n4 MULTIPOLYGON (((551550.1 18...\n5 MULTIPOLYGON (((549099.6 18...\n6 MULTIPOLYGON (((549819.9 18...\n\n# inspect column names\nnames(msoa21)\n\n [1] \"msoa21cd\"  \"msoa21nm\"  \"msoa21nmw\" \"bng_e\"     \"bng_n\"     \"lat\"      \n [7] \"long\"      \"globalid\"  \"eur21\"     \"pop21\"     \"geom\"     \n\n\nAlways inspect your join to ensure everything looks as expected. A good way to do this is by using the View() function to check for any unexpected missing values, which are marked as NA.\nWe can also compare the total number of rows in the spatial dataset with the total number of non-NA values in the joined columns:\n\n\n\nR code\n\n# inspect\nnrow(msoa21)\n\n\n[1] 1002\n\n# check for missing values\nsum(!is.na(msoa21$eur21))\n\n[1] 1002\n\n# check for missing values\nsum(!is.na(msoa21$pop21))\n\n[1] 1002\n\n\nNo missing values. In this case we did not expect any missing values, so this confirms that all our full attribute dataset has been linked to the spatial dataset.\nWe are almost ready to map the data. Only thing that is left is for us to calculate the share of European-born immigrants within each MSOA:\n\n\n\nR code\n\n# calculate proportion\nmsoa21 &lt;- msoa21 |&gt;\n    mutate(prop_eur21 = eur21/pop21)\n\n\n\n\n\nFor our map-making, we will use one of the two primary visualisation libraries for spatial data: tmap. tmap offers a flexible, layer-based approach that makes it easy to create various types of thematic maps, such as choropleths and proportional symbol maps. One of the standout features of tmap is its quick plotting function, qtm(), which allows you to generate basic maps with minimal effort.\n\n\n\nR code\n\n# quick thematic map\nqtm(msoa21, fill = \"prop_eur21\")\n\n\n\n\n\nFigure 2: Quick thematic map.\n\n\n\n\nIn this case, the fill() argument in tmap is how we instruct the library to create a choropleth map based on the values in the specified column. If we set fill() to NULL, only the borders of our polygons will be drawn, without any colour fill. The qtm() function in tmap is versatile, allowing us to pass various parameters to customise the aesthetics of our map. By checking the function’s documentation, you can explore the full list of available parameters. For instance, to set the MSOA borders to white, we can use the borders parameter:\n\n\n\nR code\n\n# quick thematic map\nqtm(msoa21, fill = \"prop_eur21\", col = \"white\")\n\n\n\n\n\nFigure 3: Quick thematic map with white borders.\n\n\n\n\nThe map does not look quite right yet. While we can continue tweaking parameters in the qtm() function to improve it, qtm() is somewhat limited in its functionality and is primarily intended for quickly inspecting your data and creating basic maps. For more complex and refined map-making with the tmap library, it is better to use the main plotting method that starts with the tm_shape() function.\n\n\n\n\n\n\nThe primary approach to creating maps in tmap involves using a layered grammar of graphics to build up your map, starting with the tm_shape() function. This function, when provided with a spatial dataframe, captures the spatial information of your data, including its projection and geometry, and creates a spatial object. While you can override certain aspects of the spatial data (such as its projection) using the function’s parameters, the essential role of tm_shape() is to instruct R to “use this object as the basis for drawing the shapes.”\nTo actually render the shapes, you need to add a layer that specifies the type of shape you want R to draw from this spatial information — such as polygons for our data. This layer function tells R to “draw my spatial object as X”, where X represents the type of shape. Within this layer, you can also provide additional details to control how R draws your shapes. Further, you can add more layers to include other spatial objects and their corresponding shapes on your map. Finally, layout options can be specified through a layout layer, allowing you to customise the overall appearance and arrangement of your map.\n\n\n\nLet us build a map using tmap:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # map data\n  tm_polygons()\n\n\n\n\n\nFigure 4: Building up a map layer by layer.\n\n\n\n\nAs you can now see, we have mapped the spatial polygons of our msoa21 spatial dataframe. However, this is not quite the map we want; we need a choropleth map where the polygons are coloured based on the proportion of European immigrants. To achieve this, we use the col parameter within the tm_polygons() function.\n\n\n\n\n\n\nThe fill parameter within tm_polygons() allows you to fill polygons with colours based on:\n\nA single colour value (e.g. red or #fc9272).\nThe name of a data variable within the spatial data file. This variable can either contain specific colour values or numeric/categorical values that will be mapped to a colour palette.\n\n\n\n\nLet us go ahead and pass our prop_eur21 variable within the fill() parameter and see what we get:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # map data\n  tm_polygons(\n    fill = \"prop_eur21\"\n  )\n\n\n\n\n\nFigure 5: Building up a map layer by layer.\n\n\n\n\nWe are making progress, but there are two immediate issues with our map. First, the classification breaks do not adequately reflect the variation in our dataset. By default, tmap uses pretty breaks, which may not be the most effective for our data. An alternative, such as natural breaks (or jenks), might better reveal the data’s variation.\nTo customise the classification breaks, refer to the tm_polygons() documentation. The following parameters are relevant:\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\nfill.scale\nDefines the color scale for polygon fills. Accepts a scale object created by functions such as tm_scale_continuous() and tm_intervals()\n\n\ntm_scale_continuous()\nCreates a continuous scale object for mapping numeric values to colours. You can specify options such as palette (color scheme) and limits (data range).\n\n\ntm_scale_intervals()\nCreates a scale object for mapping data into discrete classes (intervals). Parameters include: n (number of classes) and style (classification method: e.g. quantile, equal, jenks)\n\n\n\nFor example, if we want to adjust our choropleth map to use five classes determined by the natural breaks method, we need to specify the n and style parameters as follows:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # map data\n  tm_polygons(\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(n = 5, style = \"jenks\"),\n  )\n\n\n\n\n\nFigure 6: Building up a map layer by layer."
  },
  {
    "objectID": "01-spatial.html#styling-spatial-data",
    "href": "01-spatial.html#styling-spatial-data",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "Styling a map in tmap requires a deeper understanding and familiarity with the library, which is something you will develop best through hands-on practice. Here are the key functions to be aware of:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\ntm_layout()\nCustomises overall map layout, including titles, fonts, legend position, margins, and frame settings.\n\n\ntm_compass()\nAdds a compass or North arrow to the map, with options for size, position, and style.\n\n\ntm_scale_bar()\nAdds a scale bar to indicate distance, with options for units, position, and styling.\n\n\n\nTo begin styling your map, explore each of these functions and their parameters. Through trial and error, you can tweak and refine the map until you achieve the desired look:\n\n\n\nR code\n\n# shape\ntm_shape(msoa21) +\n\n  # map data\n  tm_polygons(\n    # map data\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(\n      n = 5, style = \"jenks\",\n      values = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n      labels = c(\"Smallest share\", \"2nd smallest\", \"3rd smallest\", \"4th smallest\", \"Largest share\"),\n    ),\n\n    # legend\n    fill.legend = tm_legend(\n      title = \"Share of population\",\n      na.text = \"No population\",\n      frame = FALSE,\n    ),\n\n    # borders\n    col = \"#ffffff\",\n    col_alpha = 0.3\n  ) +\n\n  # title\n  tm_title(\n    text = \"Share of population born in Europe\"\n  ) +\n\n  # layout\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.90, 1.00),\n    legend.title.size = 0.7,\n    legend.title.fontface = \"bold\",\n    legend.text.size = 0.55,\n\n    # canvas\n    inner.margins = c(0.05, 0.05, 0.05, 0.05),\n    frame = FALSE,\n  ) +\n\n  # North arrow\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"left\", \"top\"),\n    size = 1,\n    text.size = 0.7\n  ) +\n\n  # scale bar\n  tm_scalebar(\n    breaks = c(0, 5, 10, 15, 20),\n    position = c(0.85, 0.20),\n    text.size = 0.4\n  )\n\n\n\n\n\nFigure 7: Building up a map layer by layer.\n\n\n\n\nWe can also have some map labels, if we want, by extracting centroids from selected polygons and adding these as separate map layer:\n\n\n\nR code\n\n# map labels\nlab &lt;- msoa21 |&gt;\n  filter(msoa21cd == \"E02000642\" | msoa21cd == \"E02000180\") |&gt;\n  st_centroid()\n\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n# map object\nlon_eurpop &lt;-\n  # shape\n  tm_shape(msoa21) +\n\n  # map data\n  tm_polygons(\n    # map data\n    fill = \"prop_eur21\",\n    fill.scale = tm_scale_intervals(\n      n = 5, style = \"jenks\",\n      values = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n      labels = c(\"Smallest share\", \"2nd smallest\", \"3rd smallest\", \"4th smallest\", \"Largest share\"),\n    ),\n\n    # legend\n    fill.legend = tm_legend(\n      title = \"Share of population\",\n      na.text = \"No population\",\n      frame = FALSE,\n    ),\n\n    # borders\n    col = \"#ffffff\",\n    col_alpha = 0.3\n  ) +\n\n  # shape\n  tm_shape(lab) +\n\n  # centroids\n  tm_symbols(\n    size = 0.4,\n    col = \"#000000\",\n    fill = \"#000000\"\n  ) +\n\n  # labels\n  tm_text(\n    text = \"msoa21nm\",\n    col = \"#000000\",\n    size = 0.8,\n    xmod = 0,\n    ymod = -0.8,\n    bgcol = \"#f0f0f0\",\n    bgcol_alpha = 0.5\n  ) +\n\n  # title\n  tm_title(\n    text = \"Share of population born in Europe\"\n  ) +\n\n  # layout\n  tm_layout(\n    # legend\n    legend.outside = FALSE,\n    legend.position = c(0.90, 1.00),\n    legend.title.size = 0.7,\n    legend.title.fontface = \"bold\",\n    legend.text.size = 0.55,\n\n    # canvas\n    inner.margins = c(0.05, 0.05, 0.05, 0.05),\n    frame = FALSE,\n  ) +\n\n  # North arrow\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"left\", \"top\"),\n    size = 1,\n    text.size = 0.7\n  ) +\n\n  # scale bar\n  tm_scalebar(\n    breaks = c(0, 5, 10, 15, 20),\n    position = c(0.85, 0.20),\n    text.size = 0.4\n  )\n\n# plot\nlon_eurpop\n\n\n\n\nFigure 8: Building up a map layer by layer.\n\n\n\n\nIn the code above, we stored the full map definition as an object. This makes it easy to export the map and save it as a .jpg, .png or .pdf file:\n\n\n\nR code\n\n# write map\ntmap_save(tm = lon_eurpop, filename = \"london-european-population.jpg\", width = 15,\n    height = 15, units = c(\"cm\"))"
  },
  {
    "objectID": "01-spatial.html#assignment",
    "href": "01-spatial.html#assignment",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "Now that we have prepared our dataset and created our initial maps in R, we can also try and map the distribution of the proportion of European immigrants across Wales and experiment with different mapping parameters. Follow these steps:\n\nDownload the two datasets provided below and save them in the appropriate subfolder within your data directory. The datasets include:\n\nA csv file containing the number of people residing in Wales that are born in a European country, as recorded in the 2021 Census for England and Wales, aggregated at the MSOA level.\nA GeoPackage file containing the 2021 MSOA spatial boundaries for England and Wales.\n\nLoad both datasets and merge them together. Make sure to only retain those MSOAs that belong to Wales.\nCreate a map that shows the proportion of the population residing in Wales that is born in Europe.\nExperiment by adjusting various map parameters, such as the colour scheme, map labels, and data classification method.\n\n\n\n\nFile\nType\nLink\n\n\n\n\nWales MSOA Census 2021 European Population\ncsv\nDownload\n\n\nEngland and Wales MSOA 2021 Spatial Boundaries\nGeoPackage\nDownload"
  },
  {
    "objectID": "01-spatial.html#before-you-leave",
    "href": "01-spatial.html#before-you-leave",
    "title": "1 Reproducible Spatial Analysis",
    "section": "",
    "text": "And that is how you use R as a GIS in its most basic form. More RGIS in the coming weeks, but this concludes the tutorial for this week."
  },
  {
    "objectID": "00-index.html",
    "href": "00-index.html",
    "title": "Geocomputation",
    "section": "",
    "text": "Welcome to Geocomputation. This module offers a deep dive into the principles of spatial analysis and data visualisation while providing a thorough introduction to reproducible research. Over the next ten weeks, you will explore the theory, methods, and tools of spatial analysis through engaging case studies. You will gain hands-on experience in sourcing, managing, cleaning, analysing and presenting spatial, demographic, and socioeconomic datasets.\n\n\n\nPlease be aware that for this module you are expected to have access to a working R v4.5 installation and have a basic level of proficiency in programming with R. This includes skills such as installing libraries, loading data, calculating variables, and reshaping data.\n\n\n\n\n\n\nFor installation instructions and a refresher, please refer to the Getting started and R for Data Analysis tutorials in the GEOG0018: Methods in Human Geography workbook.\n\n\n\n\n\n\nMoodle serves as the central hub for GEOG0030, where you will find all essential module information, including key details about assessments. This workbook provides links to all required reading materials and contains the content for each computer tutorial.\n\n\n\nThe topics covered over the next ten weeks are:\n\n\n\nWeek\nSection\nTopic\n\n\n\n\n1\nCore Spatial Analysis\nReproducible Spatial Analysis\n\n\n2\nCore Spatial Analysis\nSpatial Queries and Geometric Operations\n\n\n3\nCore Spatial Analysis\nPoint Pattern Analysis\n\n\n4\nCore Spatial Analysis\nSpatial Autocorrelation\n\n\n5\nCore Spatial Analysis\nSpatial Models\n\n\n\nReading week\nReading week\n\n\n6\nApplied Spatial Analysis\nRaster Data Analysis\n\n\n7\nApplied Spatial Analysis\nGeodemographic Classification\n\n\n8\nApplied Spatial Analysis\nAccessibility Analysis\n\n\n9\nData Visualisation\nBeyond the Choropleth\n\n\n10\nData Visualisation\nComplex Visualisations\n\n\n\n\n\n\n\n\n\nThis GitHub resource has been updated for the 2025-2026 academic year. The content for 2024-2025 has been archived and can be found here: [Link]\n\n\n\n\n\n\nFor specific assistance with this module, you can:\n\nRefer to the Moodle assessment tab for queries about module assessments.\nAsk a question at the end of lectures or during the computer practicals.\nAttend the scheduled Geocomputation Additional Support Hours.\nBook into the Academic Support and Feedback hours.\n\n\n\n\n\n\n\n\n\n\nThis year’s module material features the following major updates:\n\nAll code has been revised to ensure compatibility with tmap v4.\nPackage management using renv has been removed due to issues where sf installed within the package manager would not bind correctly to GDAL.\n\n\n\n\n\n\n\nThis workbook is created using the Quarto publishing system. Elements of this workbook are partially based on and modified from:\n\n\nThe GEOG0030: Geocomputation 2023-2024 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2022-2023 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2021-2022 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2020-2021 workbook by Jo Wilkin\n\nThis year’s workbook also takes inspiration and design elements from:\n\nThe Spatial Data Science for Social Geography course by Martin Fleischmann\nThe Mapping and Modelling Geographic Data in R course by Richard Harris\n\nThe datasets used in this workbook contain:\n\nData from Office for National Statistics licensed under the Open Government Licence v.3.0\nOS data © Crown copyright and database right [2024]"
  },
  {
    "objectID": "00-index.html#welcome",
    "href": "00-index.html#welcome",
    "title": "Geocomputation",
    "section": "",
    "text": "Welcome to Geocomputation. This module offers a deep dive into the principles of spatial analysis and data visualisation while providing a thorough introduction to reproducible research. Over the next ten weeks, you will explore the theory, methods, and tools of spatial analysis through engaging case studies. You will gain hands-on experience in sourcing, managing, cleaning, analysing and presenting spatial, demographic, and socioeconomic datasets."
  },
  {
    "objectID": "00-index.html#prerequisites",
    "href": "00-index.html#prerequisites",
    "title": "Geocomputation",
    "section": "",
    "text": "Please be aware that for this module you are expected to have access to a working R v4.5 installation and have a basic level of proficiency in programming with R. This includes skills such as installing libraries, loading data, calculating variables, and reshaping data.\n\n\n\n\n\n\nFor installation instructions and a refresher, please refer to the Getting started and R for Data Analysis tutorials in the GEOG0018: Methods in Human Geography workbook."
  },
  {
    "objectID": "00-index.html#moodle",
    "href": "00-index.html#moodle",
    "title": "Geocomputation",
    "section": "",
    "text": "Moodle serves as the central hub for GEOG0030, where you will find all essential module information, including key details about assessments. This workbook provides links to all required reading materials and contains the content for each computer tutorial."
  },
  {
    "objectID": "00-index.html#module-overview",
    "href": "00-index.html#module-overview",
    "title": "Geocomputation",
    "section": "",
    "text": "The topics covered over the next ten weeks are:\n\n\n\nWeek\nSection\nTopic\n\n\n\n\n1\nCore Spatial Analysis\nReproducible Spatial Analysis\n\n\n2\nCore Spatial Analysis\nSpatial Queries and Geometric Operations\n\n\n3\nCore Spatial Analysis\nPoint Pattern Analysis\n\n\n4\nCore Spatial Analysis\nSpatial Autocorrelation\n\n\n5\nCore Spatial Analysis\nSpatial Models\n\n\n\nReading week\nReading week\n\n\n6\nApplied Spatial Analysis\nRaster Data Analysis\n\n\n7\nApplied Spatial Analysis\nGeodemographic Classification\n\n\n8\nApplied Spatial Analysis\nAccessibility Analysis\n\n\n9\nData Visualisation\nBeyond the Choropleth\n\n\n10\nData Visualisation\nComplex Visualisations\n\n\n\n\n\n\n\n\n\nThis GitHub resource has been updated for the 2025-2026 academic year. The content for 2024-2025 has been archived and can be found here: [Link]"
  },
  {
    "objectID": "00-index.html#troubleshooting",
    "href": "00-index.html#troubleshooting",
    "title": "Geocomputation",
    "section": "",
    "text": "For specific assistance with this module, you can:\n\nRefer to the Moodle assessment tab for queries about module assessments.\nAsk a question at the end of lectures or during the computer practicals.\nAttend the scheduled Geocomputation Additional Support Hours.\nBook into the Academic Support and Feedback hours."
  },
  {
    "objectID": "00-index.html#major-updates",
    "href": "00-index.html#major-updates",
    "title": "Geocomputation",
    "section": "",
    "text": "This year’s module material features the following major updates:\n\nAll code has been revised to ensure compatibility with tmap v4.\nPackage management using renv has been removed due to issues where sf installed within the package manager would not bind correctly to GDAL."
  },
  {
    "objectID": "00-index.html#acknowledgements",
    "href": "00-index.html#acknowledgements",
    "title": "Geocomputation",
    "section": "",
    "text": "This workbook is created using the Quarto publishing system. Elements of this workbook are partially based on and modified from:\n\n\nThe GEOG0030: Geocomputation 2023-2024 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2022-2023 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2021-2022 workbook by Justin van Dijk\nThe GEOG0030: Geocomputation 2020-2021 workbook by Jo Wilkin\n\nThis year’s workbook also takes inspiration and design elements from:\n\nThe Spatial Data Science for Social Geography course by Martin Fleischmann\nThe Mapping and Modelling Geographic Data in R course by Richard Harris\n\nThe datasets used in this workbook contain:\n\nData from Office for National Statistics licensed under the Open Government Licence v.3.0\nOS data © Crown copyright and database right [2024]"
  }
]