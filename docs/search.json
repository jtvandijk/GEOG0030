[
  {
    "objectID": "10-datavis.html",
    "href": "10-datavis.html",
    "title": "1 Complex Visualisations",
    "section": "",
    "text": "1 Complex Visualisations\n\n\n\n\n\n\nThe Geocomputation content for the 2024-2025 academic year is currently undergoing a major update. The materials from 2023-2024 have been archived and can be accessed here: [Link]"
  },
  {
    "objectID": "08-network.html",
    "href": "08-network.html",
    "title": "1 Accessibility Analysis",
    "section": "",
    "text": "Accessibility is often described as the ease with which individuals can reach places and opportunities, such as employment, public services, and cultural activities. We can utilise transport network data to quantify accessibility and characterise areas based on their accessibility levels. This week, we will use the dodgr R library to measure accessibility between different points of interest by calculating the network distances between them.\n\n\nYou can download the slides of this weekâ€™s lecture here: [Link].\n\n\n\n\n\n\nGeurs, K. and Van Wee, B. 2004. Accessibility evaluation of land-use and transport strategies: review and research directions. Journal of Transport Geography 12(2): 127-140. [Link]\nHiggins, C., Palm, M. DeJohn, A. et al. 2022. Calculating place-based transit accessibility: Methods, tools and algorithmic dependence. Journal of Transport and Land Use 15(1): 95-116. [Link]\n\n\n\n\n\nVan Dijk, J., Krygsman, S. and De Jong, T. 2015. Toward spatial justice: The spatial equity effects of a toll road in Cape Town, South Africa. Journal of Transport and Land Use 8(3): 95-114. [Link]\nVan Dijk, J. and De Jong, T. 2017. Post-processing GPS-tracks in reconstructing travelled routes in a GIS-environment: network subset selection and attribute adjustment. Annals of GIS 23(3): 203-217. [Link]\n\n\n\n\n\nThis week, we will analyse the accessibility of fast-food outlets in the London Borough of Lambeth. Specifically, we will examine how closely these outlets are located within walking distance of primary and secondary schools, and explore any potential relationships between their proximity and the relative levels of deprivation in the area.\nWe will extract the points of interest that we will use for this analysis from the Point of Interest (POI) data for the United Kingdom, obtained from the Overture Maps Foundation and pre-processed by the Consumer Data Research Centre to provide users with easy access.\nYou can download a subset of the POI dataset via the link provided below. A copy of the 2011 London LSOAs spatial boundaries, the boundaries of the London Boroughs, and the 2019 English Index of Multiple Deprivation. Save these files in your project folder under data.\n\n\n\nFile\nType\nLink\n\n\n\n\nLambeth Overture Points of Interest 2024\nGeoPackage\nDownload\n\n\nLondon LSOA 2011 Spatial Boundaries\nGeoPackage\nDownload\n\n\nLondon Borough Spatial Boundaries\nGeoPackage\nDownload\n\n\nEngland 2019 Index of Multiple Deprivation\ncsv\nDownload\n\n\n\n\n\n\n\n\n\nYou may have already downloaded some of these datasets in previous weeks, but for completeness, they are all provided here. Only download the datasets you do not already have or did not save.\n\n\n\n\n\n\n\n\n\nTo extract the Lambeth Overture Points of Interest data, a 2-kilometre buffer was applied around the boundaries of Lambeth. This approach ensures that points just outside the study area are included, as locations beyond the borough boundary may still be accessible to residents and could represent the nearest available options.\n\n\n\nOpen a new script within your GEOG0030 project and save this as w08-accessibility-analysis.r.\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\nlibrary(osmdata)\nlibrary(dodgr)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nNext, we can load the spatial data into R.\n\n\n\nR code\n\n# read poi data\npoi24 &lt;- st_read(\"data/spatial/Lambeth-POI-2024.gpkg\")\n\n\nReading layer `Lambeth-POI-2024' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/Lambeth-POI-2024.gpkg' \n  using driver `GPKG'\nSimple feature collection with 65060 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526556.6 ymin: 167827 xmax: 535640.4 ymax: 182673.8\nProjected CRS: OSGB36 / British National Grid\n\n# read lsoa dataset\nlsoa11 &lt;- st_read(\"data/spatial/London-LSOA-2011.gpkg\")\n\nReading layer `London-LSOA-2011' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-LSOA-2011.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4835 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# read borough dataset\nborough &lt;- st_read(\"data/spatial/London-Boroughs.gpkg\")\n\nReading layer `london_boroughs' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-Boroughs.gpkg' \n  using driver `GPKG'\nSimple feature collection with 33 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9\nProjected CRS: OSGB36 / British National Grid\n\n\nNow, carefully examine each individual dataframe to understand how the data is structured and what information it contains.\n\n\n\nR code\n\n# inspect poi data\nhead(poi24)\n\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526913.4 ymin: 169695.2 xmax: 526945.5 ymax: 169970.8\nProjected CRS: OSGB36 / British National Grid\n                                id    primary_name       main_category\n1 08f194ada9716b86030eab41bbd4207e \"Gorgeous Grub\" \"burger_restaurant\"\n2 08f194ada9715a1903d73f4aef170602    \"TLC Direct\"   \"wholesale_store\"\n3 08f194ada944cba203fa613de4f5e6d5     \"JD Sports\"       \"sports_wear\"\n4 08f194ada9449a8a0345a466a0a6ece9       \"Lidl GB\"       \"supermarket\"\n                    alternate_category                                 address\n1   eat_and_drink|fast_food_restaurant                 \"1 Prince Georges Road\"\n2 professional_services|lighting_store                      \"280 Western Road\"\n3            sporting_goods|shoe_store \"Unit 2 Tandem Centre Top Of Church Rd\"\n4          retail|fast_food_restaurant                         \"Colliers Wood\"\n         locality   postcode region country source   source_record_id\n1        \"London\"   \"SW19 2\"  \"ENG\"    \"GB\" \"meta\"  \"232538816864698\"\n2        \"London\" \"SW19 2QA\"  \"ENG\"    \"GB\" \"meta\" \"1959707454355017\"\n3 \"Colliers Wood\" \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\"  \"644899945690935\"\n4        \"London\" \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\"  \"111430837210163\"\n                            geom\n1 MULTIPOINT ((526913.4 16984...\n2 MULTIPOINT ((526921.1 16969...\n3 MULTIPOINT ((526915.7 16997...\n4 MULTIPOINT ((526922.2 16988...\n [ reached 'max' / getOption(\"max.print\") -- omitted 2 rows ]\n\n# inspect lsoa dataset\nhead(lsoa11)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 531948.3 ymin: 180733.9 xmax: 545296.2 ymax: 184700.6\nProjected CRS: OSGB36 / British National Grid\n   lsoa11cd            lsoa11nm           lsoa11nmw  bng_e  bng_n     long\n1 E01000001 City of London 001A City of London 001A 532129 181625 -0.09706\n2 E01000002 City of London 001B City of London 001B 532480 181699 -0.09197\n3 E01000003 City of London 001C City of London 001C 532245 182036 -0.09523\n4 E01000005 City of London 001E City of London 001E 533581 181265 -0.07628\n       lat                               globalid          lsoa11_name pop2011\n1 51.51810 {283B0EAD-F8FC-40B6-9A79-1DDD7E5C0758}  City of London 001A    1465\n2 51.51868 {DDCE266B-7825-428C-9E0A-DF66B0179A55}  City of London 001B    1436\n3 51.52176 {C45E358E-A794-485A-BF76-D96E5D458EA4}  City of London 001C    1346\n4 51.51452 {4DDAF5E4-E47F-4312-89A0-923FFEC028A6}  City of London 001E     985\n                            geom\n1 MULTIPOLYGON (((532105.1 18...\n2 MULTIPOLYGON (((532634.5 18...\n3 MULTIPOLYGON (((532135.1 18...\n4 MULTIPOLYGON (((533808 1807...\n [ reached 'max' / getOption(\"max.print\") -- omitted 2 rows ]\n\n# inspect borough dataset\nhead(borough)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 507007.4 ymin: 155850.8 xmax: 561957.5 ymax: 194889.3\nProjected CRS: OSGB36 / British National Grid\n  objectid                 name  gss_code  hectares nonld_area ons_inner\n1        1 Kingston upon Thames E09000021  3726.117      0.000         F\n2        2              Croydon E09000008  8649.441      0.000         F\n3        3              Bromley E09000006 15013.487      0.000         F\n4        4             Hounslow E09000018  5658.541     60.755         F\n5        5               Ealing E09000009  5554.428      0.000         F\n6        6             Havering E09000016 11445.735    210.763         F\n  sub_2011                           geom\n1    South POLYGON ((516401.6 160201.8...\n2    South POLYGON ((535009.2 159504.7...\n3    South POLYGON ((540373.6 157530.4...\n4     West POLYGON ((509703.4 175356.6...\n5     West POLYGON ((515647.2 178787.8...\n6     East POLYGON ((553564 179127.1, ...\n\n\n\n\nThe inspection shows that the POI dataset contains a wide variety of location types, with each point tagged under a main and alternative category, as provided by the Overture Maps Foundation via Meta and Microsoft. However, these tags may not be consistent across the dataset, so we will need to identify specific keywords to filter the main_category and alternate_category columns.\nWe will start by filtering out all POIs where the word school features in the main_category column:\n\n\n\nR code\n\n# filter school poi data\npoi_schools &lt;- poi24 |&gt;\n    filter(str_detect(main_category, \"school\"))\n\n# inspect\nhead(unique(poi_schools$main_category), n = 50)\n\n\n [1] \"\\\"day_care_preschool\\\"\"              \"\\\"driving_school\\\"\"                 \n [3] \"\\\"elementary_school\\\"\"               \"\\\"school\\\"\"                         \n [5] \"\\\"language_school\\\"\"                 \"\\\"music_school\\\"\"                   \n [7] \"\\\"specialty_school\\\"\"                \"\\\"preschool\\\"\"                      \n [9] \"\\\"dance_school\\\"\"                    \"\\\"high_school\\\"\"                    \n[11] \"\\\"drama_school\\\"\"                    \"\\\"cooking_school\\\"\"                 \n[13] \"\\\"middle_school\\\"\"                   \"\\\"vocational_and_technical_school\\\"\"\n[15] \"\\\"art_school\\\"\"                      \"\\\"private_school\\\"\"                 \n[17] \"\\\"religious_school\\\"\"                \"\\\"nursing_school\\\"\"                 \n[19] \"\\\"montessori_school\\\"\"               \"\\\"public_school\\\"\"                  \n[21] \"\\\"cosmetology_school\\\"\"              \"\\\"medical_school\\\"\"                 \n[23] \"\\\"engineering_schools\\\"\"             \"\\\"massage_school\\\"\"                 \n[25] \"\\\"business_schools\\\"\"                \"\\\"law_schools\\\"\"                    \n[27] \"\\\"medical_sciences_schools\\\"\"        \"\\\"sports_school\\\"\"                  \n[29] \"\\\"flight_school\\\"\"                  \n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\nThis is still a very large list, and looking at the categories not all POIs containing the string school should be included. However, this initial selection has given us a more manageable list from which we can choose the relevant tags. We can now further filter the dataset as well as clip the dataset to the administrative boundaries of Lambeth.\n\n\n\nR code\n\n# remove quotes for easier processing\npoi_schools &lt;- poi_schools |&gt;\n    mutate(main_category = str_replace_all(main_category, \"\\\"\", \"\"))\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(main_category == \"elementary_school\" | main_category == \"high_school\" |\n        main_category == \"middle_school\" | main_category == \"private_school\" | main_category ==\n        \"public_school\" | main_category == \"school\")\n\n# filter school poi data\nlambeth &lt;- borough |&gt;\n    filter(name == \"Lambeth\")\n\npoi_schools &lt;- poi_schools |&gt;\n    st_intersection(lambeth) |&gt;\n    select(1:11)\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 141 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 169846.4 xmax: 533065.9 ymax: 180398\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                 id\n6  08f194ad1a394235035f3ab7c2e4721d\n7  08f194ad1a8da734035945d69c357ddd\n8  08f194ad1abb648603defd9d76b4c314\n27 08f194ad130f0cd303c1c9f9b42438f8\n                                               primary_name     main_category\n6                         \"Woodmansterne Children's Centre\" elementary_school\n7   \"Immanuel & St Andrew Church of England Primary School\"            school\n8  \"Monkey Puzzle Day Nursery & Preschool Streatham Common\"            school\n27                                     \"Campsbourne School\"            school\n                        alternate_category                   address locality\n6                         school|education            \"Stockport Rd\"     &lt;NA&gt;\n7              elementary_school|education           \"Northanger Rd\"     &lt;NA&gt;\n8  education|public_service_and_government \"496 Streatham High Road\" \"London\"\n27                               education                      &lt;NA&gt; \"London\"\n     postcode region country source   source_record_id\n6  \"SW16 5XE\"   &lt;NA&gt;    \"GB\" \"meta\"  \"114577088601307\"\n7  \"SW16 5SL\"   &lt;NA&gt;    \"GB\" \"meta\"  \"128479257200832\"\n8  \"SW16 3QB\"  \"ENG\"    \"GB\" \"meta\" \"1092187950854118\"\n27       &lt;NA&gt;   &lt;NA&gt;    \"GB\" \"meta\"  \"114411542481619\"\n                        geom\n6  POINT (529701.5 169846.4)\n7  POINT (530016.4 170574.1)\n8  POINT (530208.6 170587.9)\n27 POINT (528819.8 174228.7)\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nThis is still a rather long list and likely inaccurate. According to Lambeth Council Education Statistics, there should be 80 primary and secondary schools across the borough. We can use the alternate_category column to further narrow down our results.\n\n\n\n\n\n\nYou can inspect the different tags and their frequencies easily by creating a frequency table: table(poi_schools$alternate_category).\n\n\n\n\n\n\nR code\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(str_detect(alternate_category, \"elementary_school\") | str_detect(alternate_category,\n        \"high_school\") | str_detect(alternate_category, \"middle_school\") | str_detect(alternate_category,\n        \"private_school\") | str_detect(alternate_category, \"public_school\"))\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 58 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 170025.3 xmax: 532897.2 ymax: 179678.2\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                id\n1 08f194ad1a8da734035945d69c357ddd\n2 08f194ad1a70460d037da737c256001b\n3 08f194ad1c2dc81c032e9e0aa296a8d1\n4 08f194ad1e4cec5903fafb7496a2d2f3\n                                             primary_name     main_category\n1 \"Immanuel & St Andrew Church of England Primary School\"            school\n2                                \"Granton Primary School\" elementary_school\n3                 \"Kingswood Primary School (Upper Site)\" elementary_school\n4                              \"Battersea Grammar School\"            school\n           alternate_category          address locality   postcode region\n1 elementary_school|education  \"Northanger Rd\"     &lt;NA&gt; \"SW16 5SL\"   &lt;NA&gt;\n2        school|public_school     \"Granton Rd\"     &lt;NA&gt; \"SW16 5AN\"   &lt;NA&gt;\n3          school|high_school \"193 Gipsy Road\" \"London\"   \"SE27 9\"  \"ENG\"\n4       high_school|education             &lt;NA&gt; \"London\"       &lt;NA&gt;   &lt;NA&gt;\n  country source  source_record_id                      geom\n1    \"GB\" \"meta\" \"128479257200832\" POINT (530016.4 170574.1)\n2    \"GB\" \"meta\" \"235737420093504\" POINT (529299.7 170025.3)\n3    \"GB\" \"meta\" \"110066125723254\" POINT (532897.2 171498.4)\n4    \"GB\" \"meta\" \"103107239728950\" POINT (529523.9 172310.9)\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nSince the POI dataset is compiled from various open sources, the data quality is not guaranteed. Some schools may be missing, while others could be duplicated, perhaps under slightly different names or because different buildings have been assigned separate point locations. However, it is unlikely that more than one school would share the same postcode. Therefore, we will use postcode information (where available) to finalise our school selection and remove any likely duplicates.\n\n\n\nR code\n\n# identify duplicate postcodes\npoi_schools &lt;- poi_schools |&gt;\n    group_by(postcode) |&gt;\n    mutate(rank = rank(primary_name)) |&gt;\n    ungroup()\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(is.na(postcode) | rank == 1) |&gt;\n    select(-rank)\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 54 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 170025.3 xmax: 532897.2 ymax: 179678.2\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 54 Ã— 12\n   id    primary_name main_category alternate_category address locality postcode\n   &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;              &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n 1 08f1â€¦ \"\\\"Immanuelâ€¦ school        elementary_schoolâ€¦ \"\\\"Norâ€¦  &lt;NA&gt;    \"\\\"SW16â€¦\n 2 08f1â€¦ \"\\\"Granton â€¦ elementary_sâ€¦ school|public_schâ€¦ \"\\\"Graâ€¦  &lt;NA&gt;    \"\\\"SW16â€¦\n 3 08f1â€¦ \"\\\"Kingswooâ€¦ elementary_sâ€¦ school|high_school \"\\\"193â€¦ \"\\\"Londâ€¦ \"\\\"SE27â€¦\n 4 08f1â€¦ \"\\\"Batterseâ€¦ school        high_school|educaâ€¦  &lt;NA&gt;   \"\\\"Londâ€¦  &lt;NA&gt;   \n 5 08f1â€¦ \"\\\"St Bede'â€¦ school        elementary_schoolâ€¦ \"\\\"St â€¦  &lt;NA&gt;    \"\\\"SW12â€¦\n 6 08f1â€¦ \"\\\"St Leonaâ€¦ school        elementary_schoolâ€¦ \"\\\"42 â€¦ \"\\\"Londâ€¦ \"\\\"SW16â€¦\n 7 08f1â€¦ \"\\\"Richard â€¦ elementary_sâ€¦ college_universitâ€¦ \"\\\"Newâ€¦  &lt;NA&gt;    \"\\\"SW2 â€¦\n 8 08f1â€¦ \"\\\"Henry Caâ€¦ school        high_school|elemeâ€¦ \"\\\"Hydâ€¦  &lt;NA&gt;    \"\\\"SW12â€¦\n 9 08f1â€¦ \"\\\"South Baâ€¦ school        high_school|b2b_sâ€¦ \"\\\"56 â€¦ \"\\\"Londâ€¦ \"\\\"SW2 â€¦\n10 08f1â€¦ \"\\\"Glenbrooâ€¦ elementary_sâ€¦ school|public_schâ€¦ \"\\\"Claâ€¦  &lt;NA&gt;    \"\\\"SW4 â€¦\n# â„¹ 44 more rows\n# â„¹ 5 more variables: region &lt;chr&gt;, country &lt;chr&gt;, source &lt;chr&gt;,\n#   source_record_id &lt;chr&gt;, geom &lt;POINT [m]&gt;\n\n\nAlthough we now have fewer schools than we had expected, either due to overly restrictive filtering of tags or because some school locations are not recorded in the dataset, we will proceed with the current data.\n\n\n\n\n\n\nVariable preparation can be a time-consuming process that often necessitates a more extensive exploratory analysis to ensure sufficient data quality. This may involve sourcing additional data to supplement your existing dataset.\n\n\n\nWe can use a similar approach to approximate the locations of fast food outlets in the Borough.\n\n\n\nR code\n\n# filter fast food poi data\npoi_fastfood &lt;- poi24 |&gt;\n    filter(str_detect(main_category, \"fast_food_restaurant\") | str_detect(alternate_category,\n        \"fast_food_restaurant\") | str_detect(alternate_category, \"chicken_restaurant\") |\n        str_detect(alternate_category, \"burger_restaurant\"))\n\n# inspect\npoi_fastfood\n\n\nSimple feature collection with 1444 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526666.3 ymin: 168272.9 xmax: 535546.9 ymax: 182554\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                id     primary_name          main_category\n1 08f194ada9716b86030eab41bbd4207e  \"Gorgeous Grub\"    \"burger_restaurant\"\n2 08f194ada9449a8a0345a466a0a6ece9        \"Lidl GB\"          \"supermarket\"\n3 08f194ada944daa80328c6604dab3503     \"Moss Bros.\" \"men's_clothing_store\"\n4 08f194ada932ad8603db11bbb7f953a7 \"Livi's Cuisine\"   \"african_restaurant\"\n                  alternate_category                          address  locality\n1 eat_and_drink|fast_food_restaurant          \"1 Prince Georges Road\"  \"London\"\n2        retail|fast_food_restaurant                  \"Colliers Wood\"  \"London\"\n3               fast_food_restaurant \"Unit 5, Tandem Shopping Centre\"  \"London\"\n4       caterer|fast_food_restaurant                   \"1 Locks Lane\" \"Mitcham\"\n    postcode region country source  source_record_id\n1   \"SW19 2\"  \"ENG\"    \"GB\" \"meta\" \"232538816864698\"\n2 \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\" \"111430837210163\"\n3 \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\" \"478090646011341\"\n4    \"CR4 2\"  \"ENG\"    \"GB\" \"meta\" \"231745500530140\"\n                            geom\n1 MULTIPOINT ((526913.4 16984...\n2 MULTIPOINT ((526922.2 16988...\n3 MULTIPOINT ((526945.5 16992...\n4 MULTIPOINT ((527970.3 16955...\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nLetâ€™s map both datasets to get an idea of how the data look like:\n\n\n\nR code\n\n# combine for mapping\npoi_schools &lt;- poi_schools |&gt;\n  mutate(type = \"School\")\npoi_fastfood &lt;- poi_fastfood |&gt;\n  mutate(type = \"Fast food\")\npoi_lambeth &lt;- rbind(poi_schools, poi_fastfood)\n\n# shape, polygon\ntm_shape(lambeth) +\n\n  # specify colours\n  tm_polygons(\n    col = \"#f0f0f0\",\n  ) +\n\n  # shape, points\n  tm_shape(poi_lambeth) +\n\n  # specify column, colours\n  tm_dots(\n    col = \"type\",\n    size = 0.05,\n    palette = c(\"#beaed4\", \"#fdc086\"),\n    title = \"\"\n  ) +\n\n  # set layout\n  tm_layout(\n    legend.outside = TRUE,\n    legend.position = c(\"right\", \"bottom\"),\n    legend.text.size = 1,\n    frame = FALSE\n  )\n\n\n\n\n\nFigureÂ 1: Extracted school and fast food locations for Lambeth.\n\n\n\n\n\n\n\nIn addition to the locations of interest, we need network data to assess the accessibility of schools in relation to fast food outlets. We will use OpenStreetMap to extract road segment data. Similar to the POI dataset, OSM uses key and value tags to categorise the features within its dataset.\n\n\n\n\n\n\nOpenStreetMap (OSM) is a free, editable map of the world, but its coverage is uneven globally. However, the accuracy and quality of the data can at times be questionable, with details such as road types and speed limits missing. The OpenStreetMap Wiki provides more details on the tagging system.\n\n\n\nTo download the Lambeth road network dataset, we first need to define our bounding box coordinates. We will then use these coordinates in our OSM query to extract specific types of road segments within the defined search area. Our focus will be on selecting all OSM features with the highway tag that are likely to be used by pedestrians (e.g.Â excluding motorways).\n\n\n\nR code\n\n# define our bbox coordinates, use WGS84\nbbox_lambeth &lt;- poi24 |&gt;\n    st_transform(4326) |&gt;\n    st_bbox()\n\n# osm query\nosm_network &lt;- opq(bbox = bbox_lambeth) |&gt;\n    add_osm_feature(key = \"highway\", value = c(\"primary\", \"secondary\", \"tertiary\",\n        \"residential\", \"path\", \"footway\", \"unclassified\", \"living_street\", \"pedestrian\")) |&gt;\n    osmdata_sf()\n\n\n\n\n\n\n\n\nIn some cases, the OSM query may return an error, particularly when multiple users from the same location are executing the exact same query. If so, you can download a prepared copy of the data here: [Download]. You can load this copy into R through load('data/spatial/London-OSM-Roads.RData')\n\n\n\nThe returned osm_network object contains a variety of elements with the specified tags. Our next step is to extract the spatial data from this object to create our road network dataset. Specifically, we will extract the edges of the network, which represent the lines of the roads, as well as the nodes, which represent the points where the roads start, end, or intersect.\n\n\n\nR code\n\n# extract the nodes, with their osm_id\nosm_network_nodes &lt;- osm_network$osm_points[, \"osm_id\"]\n\n# extract the edges, with their osm_id and relevant columns\nosm_network_edges &lt;- osm_network$osm_lines[, c(\"osm_id\", \"name\", \"highway\", \"maxspeed\",\n    \"oneway\")]\n\n# inspect\nhead(osm_network_nodes)\n\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -0.1541499 ymin: 51.52434 xmax: -0.1457924 ymax: 51.52698\nGeodetic CRS:  WGS 84\n      osm_id                    geometry\n78112  78112 POINT (-0.1457924 51.52698)\n99878  99878 POINT (-0.1529787 51.52434)\n99879  99879 POINT (-0.1532934 51.52482)\n99880  99880 POINT (-0.1535802 51.52508)\n99882  99882 POINT (-0.1541499 51.52567)\n99883  99883 POINT (-0.1541362 51.52598)\n\n# inspect\nhead(osm_network_edges)\n\nSimple feature collection with 6 features and 5 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -0.1398347 ymin: 51.50608 xmax: -0.0821093 ymax: 51.5246\nGeodetic CRS:  WGS 84\n         osm_id                 name     highway maxspeed oneway\n31030     31030          Grafton Way     primary   20 mph    yes\n31039     31039 Tottenham Court Road     primary   20 mph   &lt;NA&gt;\n31959     31959     Cleveland Street residential   20 mph    yes\n554369   554369  King William Street    tertiary   20 mph    yes\n554526   554526     Fenchurch Street    tertiary   20 mph   &lt;NA&gt;\n1530592 1530592  Borough High Street     primary   30 mph    yes\n                              geometry\n31030   LINESTRING (-0.1349153 51.5...\n31039   LINESTRING (-0.1303693 51.5...\n31959   LINESTRING (-0.139512 51.52...\n554369  LINESTRING (-0.08745 51.511...\n554526  LINESTRING (-0.085135 51.51...\n1530592 LINESTRING (-0.0882957 51.5...\n\n\nWe can quickly map the network edges to see how the road network looks like:\n\n\n\nR code\n\n# shape, polygon\ntm_shape(osm_network_edges) +\n\n  # specify column, classes\n  tm_lines(\n    col = \"#bdbdbd\",\n    lwd = 0.2,\n  ) +\n\n  # shape, polygon\n  tm_shape(lambeth) +\n\n  # specify column, classes\n  tm_borders(\n    col = \"#252525\",\n    lwd = 2\n  ) +\n\n  # set legend\n  tm_add_legend(\n    type = \"line\",\n    labels = \"Road segments\",\n    col = \"#bdbdbd\"\n  ) +\n\n  tm_add_legend(\n    type = \"line\",\n    labels = \"Outline Lambeth\",\n    col = \"#252525\"\n  ) +\n\n  # set layout\n  tm_layout(\n    frame = FALSE,\n    legend.outside = TRUE,\n    legend.position = c(\"right\", \"bottom\"),\n    legend.text.size = 1\n  )\n\n\n\n\n\nFigureÂ 2: Extracted OpenStreetMap road network data for Lambeth.\n\n\n\n\n\n\n\nSince our focus is on schoolchildren and walking distances, we will overwrite the oneway variable to assume that none of the road segments are restricted to one-way traffic. This adjustment will ensure our analysis is not skewed by such restrictions and will help maintain a more accurate representation of the general connectivity of the network.\n\n\n\nR code\n\n# overwrite one-way default\nosm_network_edges$oneway &lt;- \"no\"\n\n\nNow we have the network edges, we can turn this into a graph-representation that allows for the calculation of network-based accessibility statistics with our prepared point of interest data.\nIn any network analysis, the primary data structure is a graph composed of nodes and edges. The dodgr library utilises weighting profiles to assign weights based on road types, tailored to the mode of transport that each profile is designed to model. In this instance, we will use the foot weighting profile, as our focus is on modelling walking accessibility. To prevent errors related to the weighting profile, we will replace any NA values in the highway tag with the value unclassified.\n\n\n\nR code\n\n# replace missing highway tags with unclassified\nosm_network_edges &lt;- osm_network_edges |&gt;\n    mutate(highway = if_else(is.na(highway), \"unclassified\", highway))\n\n# create network graph\nosm_network_graph &lt;- weight_streetnet(osm_network_edges, wt_profile = \"foot\")\n\n\nOnce we have constructed our graph, we can use it to calculate network distances between our points of interest. One important consideration is that not all individual components in the extracted network may be connected. This can occur, for example, if the bounding box cuts off access to the road of a cul-de-sac. To ensure that our entire extracted network is connected, we will therefore extract the largest connected component of the graph.\n\n\n\n\n\n\nThe dodgr package documentation explains that components are numbered in order of decreasing size, with $component = 1 always representing the largest component. It is essential to inspect the resulting subgraph to ensure that its coverage is adequate for analysis.\n\n\n\n\n\n\nR code\n\n# extract the largest connected graph component\nnetx_connected &lt;- osm_network_graph[osm_network_graph$component == 1, ]\n\n# inspect number of remaining road segments\nnrow(netx_connected)\n\n\n[1] 436676\n\n\n\n\n\n\n\n\nOpenStreetMap is a dynamic dataset, meaning that changes are made on a continuous basis. As a result, it is quite possible that the number of remaining road segments, as shown above, may differ slightly when you run this analysis.\n\n\n\n\n\n\nNow that we have our connected subgraph, we can use the dodgr_distances() function to calculate the network distances between every possible origin (i.e.Â school) and destination (i.e.Â fast food outlet). For all combinations, the function will map the point of interest locations to the nearest point on the network and return the corresponding shortest-path distances.\n\n\n\n\n\n\nThe dodgr package requires data to be projected in WGS84, so we need to reproject our point of interest data accordingly.\n\n\n\n\n\n\nR code\n\n# reproject\npoi_schools &lt;- poi_schools |&gt;\n    st_transform(4326)\npoi_fastfood &lt;- poi_fastfood |&gt;\n    st_transform(4326)\n\n# distance matrix\ndistance_matrix &lt;- dodgr_distances(netx_connected, from = st_coordinates(poi_schools),\n    to = st_coordinates(poi_fastfood), shortest = FALSE, pairwise = FALSE, quiet = FALSE)\n\n\nThe result of this computation is a distance matrix that contains the network distances between all origins (i.e.Â schools) and all destinations (i.e.Â fast-food outlets):\n\n\n\nR code\n\n# inspect\ndistance_matrix[1:5, 1:5]\n\n\n            6807494201 7110321980 7110321980 11371586827 33148215\n8796433764    4660.831   4661.009   4661.009    3128.948 3087.031\n8820889464    3611.758   3753.383   3753.383    1957.011 1915.094\n11479633279   8497.581   8497.760   8497.760    6940.464 6898.547\n292521291     4917.554   4917.732   4917.732    4222.538 4287.953\n12331531180   6270.840   6271.018   6271.018    5575.824 5641.240\n\n\n\n\n\n\n\n\nThe above output displays the distance (in metres) between the first five schools and the first five fast-food outlets. The row and column IDs refer to the nearest nodes on the OSM network to which the schools and fast-food outlets were mapped.\n\n\n\nNow that we have the distance matrix, we can aggregate the data and perform accessibility analysis. For example, we can count the number of fast-food outlets within 500 or 1,000 metres walking distance from each school:\n\n\n\nR code\n\n# fast-food outlets within 500m\npoi_schools$fastfood_500m &lt;- rowSums(distance_matrix &lt;= 500)\n\n# fast-food outlets within 1000m\npoi_schools$fastfood_1000m &lt;- rowSums(distance_matrix &lt;= 1000)\n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\nIn the final step, we can investigate whether there is a relationship between the proximity of fast-food outlets and the relative levels of deprivation in the area. One approach is to calculate the average number of fast-food outlets within 1,000 metres of a school for each LSOA, and then compare these figures to their corresponding IMD deciles.\n\n\n\nR code\n\n# read imd dataset\nimd19 &lt;- read_csv(\"data/attributes/England-IMD-2019.csv\")\n\n\nRows: 32844 Columns: 3\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): lsoa11cd\ndbl (2): imd_rank, imd_dec\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# join imd\nlsoa11 &lt;- lsoa11 |&gt;\n  left_join(imd19, by = c(\"lsoa11cd\" = \"lsoa11cd\"))\n\n# join schools to their parent lsoa\npoi_schools &lt;- poi_schools |&gt;\n  st_transform(27700) |&gt;\n  st_join(lsoa11)\n\nWe can use this approach to derive the average number of fast-food by IMD decile:\n\n\n\nR code\n\n# average counts by imd decile\nfastfood_imd &lt;- poi_schools |&gt;\n    group_by(imd_dec) |&gt;\n    mutate(avg_cnt = mean(fastfood_1000m)) |&gt;\n    distinct(imd_dec, avg_cnt) |&gt;\n    arrange(imd_dec)\n\n# inspect\nfastfood_imd\n\n\n# A tibble: 7 Ã— 2\n# Groups:   imd_dec [7]\n  imd_dec avg_cnt\n    &lt;dbl&gt;   &lt;dbl&gt;\n1       2   20.1 \n2       3   14.3 \n3       4   17.5 \n4       5    9.83\n5       6    3   \n6       7    8.4 \n7       8   23.5 \n\n\nThere appears to be a weak relationship, with schools in more deprived areas having, on average, a higher number of fast-food outlets within a 1,000-metre walking distance. However, this trend is not consistent, as schools in the least deprived areas of Lambeth show the highest accessibility on average.\n\n\n\n\nAccessibility analysis involves evaluating how easily people can reach essential services, destinations, or opportunities, such as schools, healthcare facilities, or workplaces, from a given location. The CDRC Access to Healthy Assets & Hazards (AHAH) dataset, for instance, uses accessibility analysis to quantify how easy it is to reach â€˜unhealthyâ€™ places, such as pubs and gambling outlets, for each neighbourhood in Great Britain.\nHaving run through all the steps during the tutorial, we can recreate this analysis ourselves. Using Lambeth as a case study, try to complete the following tasks:\n\nExtract all pubs from the Point of Interest dataset.\nFor each LSOA within Lambeth, calculate the average walking distance to the nearest pub.\nCreate a map of the results.\n\n\n\n\n\n\n\nUnlike before, LSOAs are now the unit of analysis. This means you will need to input the LSOA centroids into your distance matrix.\n\n\n\n\n\n\n\n\n\nIf you want to take a deep dive into accessibility analysis, there is a great resource that got published recently: Introduction to urban accessibility: a practical guide in R.\n\n\n\n\n\n\nThis brings us to the end of the tutorial. You should now have a basic understanding of the concepts behind accessibility analysis, how it can be executed in R, and some of the challenges you may encounter when conducting your own research. With this being said, you have now reached the end of this weekâ€™s content. Onwards and upwards!"
  },
  {
    "objectID": "08-network.html#lecture-slides",
    "href": "08-network.html#lecture-slides",
    "title": "1 Accessibility Analysis",
    "section": "",
    "text": "You can download the slides of this weekâ€™s lecture here: [Link]."
  },
  {
    "objectID": "08-network.html#reading-list",
    "href": "08-network.html#reading-list",
    "title": "1 Accessibility Analysis",
    "section": "",
    "text": "Geurs, K. and Van Wee, B. 2004. Accessibility evaluation of land-use and transport strategies: review and research directions. Journal of Transport Geography 12(2): 127-140. [Link]\nHiggins, C., Palm, M. DeJohn, A. et al. 2022. Calculating place-based transit accessibility: Methods, tools and algorithmic dependence. Journal of Transport and Land Use 15(1): 95-116. [Link]\n\n\n\n\n\nVan Dijk, J., Krygsman, S. and De Jong, T. 2015. Toward spatial justice: The spatial equity effects of a toll road in Cape Town, South Africa. Journal of Transport and Land Use 8(3): 95-114. [Link]\nVan Dijk, J. and De Jong, T. 2017. Post-processing GPS-tracks in reconstructing travelled routes in a GIS-environment: network subset selection and attribute adjustment. Annals of GIS 23(3): 203-217. [Link]"
  },
  {
    "objectID": "08-network.html#accessibility-in-lambeth",
    "href": "08-network.html#accessibility-in-lambeth",
    "title": "1 Accessibility Analysis",
    "section": "",
    "text": "This week, we will analyse the accessibility of fast-food outlets in the London Borough of Lambeth. Specifically, we will examine how closely these outlets are located within walking distance of primary and secondary schools, and explore any potential relationships between their proximity and the relative levels of deprivation in the area.\nWe will extract the points of interest that we will use for this analysis from the Point of Interest (POI) data for the United Kingdom, obtained from the Overture Maps Foundation and pre-processed by the Consumer Data Research Centre to provide users with easy access.\nYou can download a subset of the POI dataset via the link provided below. A copy of the 2011 London LSOAs spatial boundaries, the boundaries of the London Boroughs, and the 2019 English Index of Multiple Deprivation. Save these files in your project folder under data.\n\n\n\nFile\nType\nLink\n\n\n\n\nLambeth Overture Points of Interest 2024\nGeoPackage\nDownload\n\n\nLondon LSOA 2011 Spatial Boundaries\nGeoPackage\nDownload\n\n\nLondon Borough Spatial Boundaries\nGeoPackage\nDownload\n\n\nEngland 2019 Index of Multiple Deprivation\ncsv\nDownload\n\n\n\n\n\n\n\n\n\nYou may have already downloaded some of these datasets in previous weeks, but for completeness, they are all provided here. Only download the datasets you do not already have or did not save.\n\n\n\n\n\n\n\n\n\nTo extract the Lambeth Overture Points of Interest data, a 2-kilometre buffer was applied around the boundaries of Lambeth. This approach ensures that points just outside the study area are included, as locations beyond the borough boundary may still be accessible to residents and could represent the nearest available options.\n\n\n\nOpen a new script within your GEOG0030 project and save this as w08-accessibility-analysis.r.\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\nlibrary(osmdata)\nlibrary(dodgr)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nNext, we can load the spatial data into R.\n\n\n\nR code\n\n# read poi data\npoi24 &lt;- st_read(\"data/spatial/Lambeth-POI-2024.gpkg\")\n\n\nReading layer `Lambeth-POI-2024' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/Lambeth-POI-2024.gpkg' \n  using driver `GPKG'\nSimple feature collection with 65060 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526556.6 ymin: 167827 xmax: 535640.4 ymax: 182673.8\nProjected CRS: OSGB36 / British National Grid\n\n# read lsoa dataset\nlsoa11 &lt;- st_read(\"data/spatial/London-LSOA-2011.gpkg\")\n\nReading layer `London-LSOA-2011' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-LSOA-2011.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4835 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# read borough dataset\nborough &lt;- st_read(\"data/spatial/London-Boroughs.gpkg\")\n\nReading layer `london_boroughs' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-Boroughs.gpkg' \n  using driver `GPKG'\nSimple feature collection with 33 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9\nProjected CRS: OSGB36 / British National Grid\n\n\nNow, carefully examine each individual dataframe to understand how the data is structured and what information it contains.\n\n\n\nR code\n\n# inspect poi data\nhead(poi24)\n\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526913.4 ymin: 169695.2 xmax: 526945.5 ymax: 169970.8\nProjected CRS: OSGB36 / British National Grid\n                                id    primary_name       main_category\n1 08f194ada9716b86030eab41bbd4207e \"Gorgeous Grub\" \"burger_restaurant\"\n2 08f194ada9715a1903d73f4aef170602    \"TLC Direct\"   \"wholesale_store\"\n3 08f194ada944cba203fa613de4f5e6d5     \"JD Sports\"       \"sports_wear\"\n4 08f194ada9449a8a0345a466a0a6ece9       \"Lidl GB\"       \"supermarket\"\n                    alternate_category                                 address\n1   eat_and_drink|fast_food_restaurant                 \"1 Prince Georges Road\"\n2 professional_services|lighting_store                      \"280 Western Road\"\n3            sporting_goods|shoe_store \"Unit 2 Tandem Centre Top Of Church Rd\"\n4          retail|fast_food_restaurant                         \"Colliers Wood\"\n         locality   postcode region country source   source_record_id\n1        \"London\"   \"SW19 2\"  \"ENG\"    \"GB\" \"meta\"  \"232538816864698\"\n2        \"London\" \"SW19 2QA\"  \"ENG\"    \"GB\" \"meta\" \"1959707454355017\"\n3 \"Colliers Wood\" \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\"  \"644899945690935\"\n4        \"London\" \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\"  \"111430837210163\"\n                            geom\n1 MULTIPOINT ((526913.4 16984...\n2 MULTIPOINT ((526921.1 16969...\n3 MULTIPOINT ((526915.7 16997...\n4 MULTIPOINT ((526922.2 16988...\n [ reached 'max' / getOption(\"max.print\") -- omitted 2 rows ]\n\n# inspect lsoa dataset\nhead(lsoa11)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 531948.3 ymin: 180733.9 xmax: 545296.2 ymax: 184700.6\nProjected CRS: OSGB36 / British National Grid\n   lsoa11cd            lsoa11nm           lsoa11nmw  bng_e  bng_n     long\n1 E01000001 City of London 001A City of London 001A 532129 181625 -0.09706\n2 E01000002 City of London 001B City of London 001B 532480 181699 -0.09197\n3 E01000003 City of London 001C City of London 001C 532245 182036 -0.09523\n4 E01000005 City of London 001E City of London 001E 533581 181265 -0.07628\n       lat                               globalid          lsoa11_name pop2011\n1 51.51810 {283B0EAD-F8FC-40B6-9A79-1DDD7E5C0758}  City of London 001A    1465\n2 51.51868 {DDCE266B-7825-428C-9E0A-DF66B0179A55}  City of London 001B    1436\n3 51.52176 {C45E358E-A794-485A-BF76-D96E5D458EA4}  City of London 001C    1346\n4 51.51452 {4DDAF5E4-E47F-4312-89A0-923FFEC028A6}  City of London 001E     985\n                            geom\n1 MULTIPOLYGON (((532105.1 18...\n2 MULTIPOLYGON (((532634.5 18...\n3 MULTIPOLYGON (((532135.1 18...\n4 MULTIPOLYGON (((533808 1807...\n [ reached 'max' / getOption(\"max.print\") -- omitted 2 rows ]\n\n# inspect borough dataset\nhead(borough)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 507007.4 ymin: 155850.8 xmax: 561957.5 ymax: 194889.3\nProjected CRS: OSGB36 / British National Grid\n  objectid                 name  gss_code  hectares nonld_area ons_inner\n1        1 Kingston upon Thames E09000021  3726.117      0.000         F\n2        2              Croydon E09000008  8649.441      0.000         F\n3        3              Bromley E09000006 15013.487      0.000         F\n4        4             Hounslow E09000018  5658.541     60.755         F\n5        5               Ealing E09000009  5554.428      0.000         F\n6        6             Havering E09000016 11445.735    210.763         F\n  sub_2011                           geom\n1    South POLYGON ((516401.6 160201.8...\n2    South POLYGON ((535009.2 159504.7...\n3    South POLYGON ((540373.6 157530.4...\n4     West POLYGON ((509703.4 175356.6...\n5     West POLYGON ((515647.2 178787.8...\n6     East POLYGON ((553564 179127.1, ...\n\n\n\n\nThe inspection shows that the POI dataset contains a wide variety of location types, with each point tagged under a main and alternative category, as provided by the Overture Maps Foundation via Meta and Microsoft. However, these tags may not be consistent across the dataset, so we will need to identify specific keywords to filter the main_category and alternate_category columns.\nWe will start by filtering out all POIs where the word school features in the main_category column:\n\n\n\nR code\n\n# filter school poi data\npoi_schools &lt;- poi24 |&gt;\n    filter(str_detect(main_category, \"school\"))\n\n# inspect\nhead(unique(poi_schools$main_category), n = 50)\n\n\n [1] \"\\\"day_care_preschool\\\"\"              \"\\\"driving_school\\\"\"                 \n [3] \"\\\"elementary_school\\\"\"               \"\\\"school\\\"\"                         \n [5] \"\\\"language_school\\\"\"                 \"\\\"music_school\\\"\"                   \n [7] \"\\\"specialty_school\\\"\"                \"\\\"preschool\\\"\"                      \n [9] \"\\\"dance_school\\\"\"                    \"\\\"high_school\\\"\"                    \n[11] \"\\\"drama_school\\\"\"                    \"\\\"cooking_school\\\"\"                 \n[13] \"\\\"middle_school\\\"\"                   \"\\\"vocational_and_technical_school\\\"\"\n[15] \"\\\"art_school\\\"\"                      \"\\\"private_school\\\"\"                 \n[17] \"\\\"religious_school\\\"\"                \"\\\"nursing_school\\\"\"                 \n[19] \"\\\"montessori_school\\\"\"               \"\\\"public_school\\\"\"                  \n[21] \"\\\"cosmetology_school\\\"\"              \"\\\"medical_school\\\"\"                 \n[23] \"\\\"engineering_schools\\\"\"             \"\\\"massage_school\\\"\"                 \n[25] \"\\\"business_schools\\\"\"                \"\\\"law_schools\\\"\"                    \n[27] \"\\\"medical_sciences_schools\\\"\"        \"\\\"sports_school\\\"\"                  \n[29] \"\\\"flight_school\\\"\"                  \n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\nThis is still a very large list, and looking at the categories not all POIs containing the string school should be included. However, this initial selection has given us a more manageable list from which we can choose the relevant tags. We can now further filter the dataset as well as clip the dataset to the administrative boundaries of Lambeth.\n\n\n\nR code\n\n# remove quotes for easier processing\npoi_schools &lt;- poi_schools |&gt;\n    mutate(main_category = str_replace_all(main_category, \"\\\"\", \"\"))\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(main_category == \"elementary_school\" | main_category == \"high_school\" |\n        main_category == \"middle_school\" | main_category == \"private_school\" | main_category ==\n        \"public_school\" | main_category == \"school\")\n\n# filter school poi data\nlambeth &lt;- borough |&gt;\n    filter(name == \"Lambeth\")\n\npoi_schools &lt;- poi_schools |&gt;\n    st_intersection(lambeth) |&gt;\n    select(1:11)\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 141 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 169846.4 xmax: 533065.9 ymax: 180398\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                 id\n6  08f194ad1a394235035f3ab7c2e4721d\n7  08f194ad1a8da734035945d69c357ddd\n8  08f194ad1abb648603defd9d76b4c314\n27 08f194ad130f0cd303c1c9f9b42438f8\n                                               primary_name     main_category\n6                         \"Woodmansterne Children's Centre\" elementary_school\n7   \"Immanuel & St Andrew Church of England Primary School\"            school\n8  \"Monkey Puzzle Day Nursery & Preschool Streatham Common\"            school\n27                                     \"Campsbourne School\"            school\n                        alternate_category                   address locality\n6                         school|education            \"Stockport Rd\"     &lt;NA&gt;\n7              elementary_school|education           \"Northanger Rd\"     &lt;NA&gt;\n8  education|public_service_and_government \"496 Streatham High Road\" \"London\"\n27                               education                      &lt;NA&gt; \"London\"\n     postcode region country source   source_record_id\n6  \"SW16 5XE\"   &lt;NA&gt;    \"GB\" \"meta\"  \"114577088601307\"\n7  \"SW16 5SL\"   &lt;NA&gt;    \"GB\" \"meta\"  \"128479257200832\"\n8  \"SW16 3QB\"  \"ENG\"    \"GB\" \"meta\" \"1092187950854118\"\n27       &lt;NA&gt;   &lt;NA&gt;    \"GB\" \"meta\"  \"114411542481619\"\n                        geom\n6  POINT (529701.5 169846.4)\n7  POINT (530016.4 170574.1)\n8  POINT (530208.6 170587.9)\n27 POINT (528819.8 174228.7)\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nThis is still a rather long list and likely inaccurate. According to Lambeth Council Education Statistics, there should be 80 primary and secondary schools across the borough. We can use the alternate_category column to further narrow down our results.\n\n\n\n\n\n\nYou can inspect the different tags and their frequencies easily by creating a frequency table: table(poi_schools$alternate_category).\n\n\n\n\n\n\nR code\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(str_detect(alternate_category, \"elementary_school\") | str_detect(alternate_category,\n        \"high_school\") | str_detect(alternate_category, \"middle_school\") | str_detect(alternate_category,\n        \"private_school\") | str_detect(alternate_category, \"public_school\"))\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 58 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 170025.3 xmax: 532897.2 ymax: 179678.2\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                id\n1 08f194ad1a8da734035945d69c357ddd\n2 08f194ad1a70460d037da737c256001b\n3 08f194ad1c2dc81c032e9e0aa296a8d1\n4 08f194ad1e4cec5903fafb7496a2d2f3\n                                             primary_name     main_category\n1 \"Immanuel & St Andrew Church of England Primary School\"            school\n2                                \"Granton Primary School\" elementary_school\n3                 \"Kingswood Primary School (Upper Site)\" elementary_school\n4                              \"Battersea Grammar School\"            school\n           alternate_category          address locality   postcode region\n1 elementary_school|education  \"Northanger Rd\"     &lt;NA&gt; \"SW16 5SL\"   &lt;NA&gt;\n2        school|public_school     \"Granton Rd\"     &lt;NA&gt; \"SW16 5AN\"   &lt;NA&gt;\n3          school|high_school \"193 Gipsy Road\" \"London\"   \"SE27 9\"  \"ENG\"\n4       high_school|education             &lt;NA&gt; \"London\"       &lt;NA&gt;   &lt;NA&gt;\n  country source  source_record_id                      geom\n1    \"GB\" \"meta\" \"128479257200832\" POINT (530016.4 170574.1)\n2    \"GB\" \"meta\" \"235737420093504\" POINT (529299.7 170025.3)\n3    \"GB\" \"meta\" \"110066125723254\" POINT (532897.2 171498.4)\n4    \"GB\" \"meta\" \"103107239728950\" POINT (529523.9 172310.9)\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nSince the POI dataset is compiled from various open sources, the data quality is not guaranteed. Some schools may be missing, while others could be duplicated, perhaps under slightly different names or because different buildings have been assigned separate point locations. However, it is unlikely that more than one school would share the same postcode. Therefore, we will use postcode information (where available) to finalise our school selection and remove any likely duplicates.\n\n\n\nR code\n\n# identify duplicate postcodes\npoi_schools &lt;- poi_schools |&gt;\n    group_by(postcode) |&gt;\n    mutate(rank = rank(primary_name)) |&gt;\n    ungroup()\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(is.na(postcode) | rank == 1) |&gt;\n    select(-rank)\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 54 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 170025.3 xmax: 532897.2 ymax: 179678.2\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 54 Ã— 12\n   id    primary_name main_category alternate_category address locality postcode\n   &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;              &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n 1 08f1â€¦ \"\\\"Immanuelâ€¦ school        elementary_schoolâ€¦ \"\\\"Norâ€¦  &lt;NA&gt;    \"\\\"SW16â€¦\n 2 08f1â€¦ \"\\\"Granton â€¦ elementary_sâ€¦ school|public_schâ€¦ \"\\\"Graâ€¦  &lt;NA&gt;    \"\\\"SW16â€¦\n 3 08f1â€¦ \"\\\"Kingswooâ€¦ elementary_sâ€¦ school|high_school \"\\\"193â€¦ \"\\\"Londâ€¦ \"\\\"SE27â€¦\n 4 08f1â€¦ \"\\\"Batterseâ€¦ school        high_school|educaâ€¦  &lt;NA&gt;   \"\\\"Londâ€¦  &lt;NA&gt;   \n 5 08f1â€¦ \"\\\"St Bede'â€¦ school        elementary_schoolâ€¦ \"\\\"St â€¦  &lt;NA&gt;    \"\\\"SW12â€¦\n 6 08f1â€¦ \"\\\"St Leonaâ€¦ school        elementary_schoolâ€¦ \"\\\"42 â€¦ \"\\\"Londâ€¦ \"\\\"SW16â€¦\n 7 08f1â€¦ \"\\\"Richard â€¦ elementary_sâ€¦ college_universitâ€¦ \"\\\"Newâ€¦  &lt;NA&gt;    \"\\\"SW2 â€¦\n 8 08f1â€¦ \"\\\"Henry Caâ€¦ school        high_school|elemeâ€¦ \"\\\"Hydâ€¦  &lt;NA&gt;    \"\\\"SW12â€¦\n 9 08f1â€¦ \"\\\"South Baâ€¦ school        high_school|b2b_sâ€¦ \"\\\"56 â€¦ \"\\\"Londâ€¦ \"\\\"SW2 â€¦\n10 08f1â€¦ \"\\\"Glenbrooâ€¦ elementary_sâ€¦ school|public_schâ€¦ \"\\\"Claâ€¦  &lt;NA&gt;    \"\\\"SW4 â€¦\n# â„¹ 44 more rows\n# â„¹ 5 more variables: region &lt;chr&gt;, country &lt;chr&gt;, source &lt;chr&gt;,\n#   source_record_id &lt;chr&gt;, geom &lt;POINT [m]&gt;\n\n\nAlthough we now have fewer schools than we had expected, either due to overly restrictive filtering of tags or because some school locations are not recorded in the dataset, we will proceed with the current data.\n\n\n\n\n\n\nVariable preparation can be a time-consuming process that often necessitates a more extensive exploratory analysis to ensure sufficient data quality. This may involve sourcing additional data to supplement your existing dataset.\n\n\n\nWe can use a similar approach to approximate the locations of fast food outlets in the Borough.\n\n\n\nR code\n\n# filter fast food poi data\npoi_fastfood &lt;- poi24 |&gt;\n    filter(str_detect(main_category, \"fast_food_restaurant\") | str_detect(alternate_category,\n        \"fast_food_restaurant\") | str_detect(alternate_category, \"chicken_restaurant\") |\n        str_detect(alternate_category, \"burger_restaurant\"))\n\n# inspect\npoi_fastfood\n\n\nSimple feature collection with 1444 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526666.3 ymin: 168272.9 xmax: 535546.9 ymax: 182554\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                id     primary_name          main_category\n1 08f194ada9716b86030eab41bbd4207e  \"Gorgeous Grub\"    \"burger_restaurant\"\n2 08f194ada9449a8a0345a466a0a6ece9        \"Lidl GB\"          \"supermarket\"\n3 08f194ada944daa80328c6604dab3503     \"Moss Bros.\" \"men's_clothing_store\"\n4 08f194ada932ad8603db11bbb7f953a7 \"Livi's Cuisine\"   \"african_restaurant\"\n                  alternate_category                          address  locality\n1 eat_and_drink|fast_food_restaurant          \"1 Prince Georges Road\"  \"London\"\n2        retail|fast_food_restaurant                  \"Colliers Wood\"  \"London\"\n3               fast_food_restaurant \"Unit 5, Tandem Shopping Centre\"  \"London\"\n4       caterer|fast_food_restaurant                   \"1 Locks Lane\" \"Mitcham\"\n    postcode region country source  source_record_id\n1   \"SW19 2\"  \"ENG\"    \"GB\" \"meta\" \"232538816864698\"\n2 \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\" \"111430837210163\"\n3 \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\" \"478090646011341\"\n4    \"CR4 2\"  \"ENG\"    \"GB\" \"meta\" \"231745500530140\"\n                            geom\n1 MULTIPOINT ((526913.4 16984...\n2 MULTIPOINT ((526922.2 16988...\n3 MULTIPOINT ((526945.5 16992...\n4 MULTIPOINT ((527970.3 16955...\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nLetâ€™s map both datasets to get an idea of how the data look like:\n\n\n\nR code\n\n# combine for mapping\npoi_schools &lt;- poi_schools |&gt;\n  mutate(type = \"School\")\npoi_fastfood &lt;- poi_fastfood |&gt;\n  mutate(type = \"Fast food\")\npoi_lambeth &lt;- rbind(poi_schools, poi_fastfood)\n\n# shape, polygon\ntm_shape(lambeth) +\n\n  # specify colours\n  tm_polygons(\n    col = \"#f0f0f0\",\n  ) +\n\n  # shape, points\n  tm_shape(poi_lambeth) +\n\n  # specify column, colours\n  tm_dots(\n    col = \"type\",\n    size = 0.05,\n    palette = c(\"#beaed4\", \"#fdc086\"),\n    title = \"\"\n  ) +\n\n  # set layout\n  tm_layout(\n    legend.outside = TRUE,\n    legend.position = c(\"right\", \"bottom\"),\n    legend.text.size = 1,\n    frame = FALSE\n  )\n\n\n\n\n\nFigureÂ 1: Extracted school and fast food locations for Lambeth.\n\n\n\n\n\n\n\nIn addition to the locations of interest, we need network data to assess the accessibility of schools in relation to fast food outlets. We will use OpenStreetMap to extract road segment data. Similar to the POI dataset, OSM uses key and value tags to categorise the features within its dataset.\n\n\n\n\n\n\nOpenStreetMap (OSM) is a free, editable map of the world, but its coverage is uneven globally. However, the accuracy and quality of the data can at times be questionable, with details such as road types and speed limits missing. The OpenStreetMap Wiki provides more details on the tagging system.\n\n\n\nTo download the Lambeth road network dataset, we first need to define our bounding box coordinates. We will then use these coordinates in our OSM query to extract specific types of road segments within the defined search area. Our focus will be on selecting all OSM features with the highway tag that are likely to be used by pedestrians (e.g.Â excluding motorways).\n\n\n\nR code\n\n# define our bbox coordinates, use WGS84\nbbox_lambeth &lt;- poi24 |&gt;\n    st_transform(4326) |&gt;\n    st_bbox()\n\n# osm query\nosm_network &lt;- opq(bbox = bbox_lambeth) |&gt;\n    add_osm_feature(key = \"highway\", value = c(\"primary\", \"secondary\", \"tertiary\",\n        \"residential\", \"path\", \"footway\", \"unclassified\", \"living_street\", \"pedestrian\")) |&gt;\n    osmdata_sf()\n\n\n\n\n\n\n\n\nIn some cases, the OSM query may return an error, particularly when multiple users from the same location are executing the exact same query. If so, you can download a prepared copy of the data here: [Download]. You can load this copy into R through load('data/spatial/London-OSM-Roads.RData')\n\n\n\nThe returned osm_network object contains a variety of elements with the specified tags. Our next step is to extract the spatial data from this object to create our road network dataset. Specifically, we will extract the edges of the network, which represent the lines of the roads, as well as the nodes, which represent the points where the roads start, end, or intersect.\n\n\n\nR code\n\n# extract the nodes, with their osm_id\nosm_network_nodes &lt;- osm_network$osm_points[, \"osm_id\"]\n\n# extract the edges, with their osm_id and relevant columns\nosm_network_edges &lt;- osm_network$osm_lines[, c(\"osm_id\", \"name\", \"highway\", \"maxspeed\",\n    \"oneway\")]\n\n# inspect\nhead(osm_network_nodes)\n\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -0.1541499 ymin: 51.52434 xmax: -0.1457924 ymax: 51.52698\nGeodetic CRS:  WGS 84\n      osm_id                    geometry\n78112  78112 POINT (-0.1457924 51.52698)\n99878  99878 POINT (-0.1529787 51.52434)\n99879  99879 POINT (-0.1532934 51.52482)\n99880  99880 POINT (-0.1535802 51.52508)\n99882  99882 POINT (-0.1541499 51.52567)\n99883  99883 POINT (-0.1541362 51.52598)\n\n# inspect\nhead(osm_network_edges)\n\nSimple feature collection with 6 features and 5 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -0.1398347 ymin: 51.50608 xmax: -0.0821093 ymax: 51.5246\nGeodetic CRS:  WGS 84\n         osm_id                 name     highway maxspeed oneway\n31030     31030          Grafton Way     primary   20 mph    yes\n31039     31039 Tottenham Court Road     primary   20 mph   &lt;NA&gt;\n31959     31959     Cleveland Street residential   20 mph    yes\n554369   554369  King William Street    tertiary   20 mph    yes\n554526   554526     Fenchurch Street    tertiary   20 mph   &lt;NA&gt;\n1530592 1530592  Borough High Street     primary   30 mph    yes\n                              geometry\n31030   LINESTRING (-0.1349153 51.5...\n31039   LINESTRING (-0.1303693 51.5...\n31959   LINESTRING (-0.139512 51.52...\n554369  LINESTRING (-0.08745 51.511...\n554526  LINESTRING (-0.085135 51.51...\n1530592 LINESTRING (-0.0882957 51.5...\n\n\nWe can quickly map the network edges to see how the road network looks like:\n\n\n\nR code\n\n# shape, polygon\ntm_shape(osm_network_edges) +\n\n  # specify column, classes\n  tm_lines(\n    col = \"#bdbdbd\",\n    lwd = 0.2,\n  ) +\n\n  # shape, polygon\n  tm_shape(lambeth) +\n\n  # specify column, classes\n  tm_borders(\n    col = \"#252525\",\n    lwd = 2\n  ) +\n\n  # set legend\n  tm_add_legend(\n    type = \"line\",\n    labels = \"Road segments\",\n    col = \"#bdbdbd\"\n  ) +\n\n  tm_add_legend(\n    type = \"line\",\n    labels = \"Outline Lambeth\",\n    col = \"#252525\"\n  ) +\n\n  # set layout\n  tm_layout(\n    frame = FALSE,\n    legend.outside = TRUE,\n    legend.position = c(\"right\", \"bottom\"),\n    legend.text.size = 1\n  )\n\n\n\n\n\nFigureÂ 2: Extracted OpenStreetMap road network data for Lambeth.\n\n\n\n\n\n\n\nSince our focus is on schoolchildren and walking distances, we will overwrite the oneway variable to assume that none of the road segments are restricted to one-way traffic. This adjustment will ensure our analysis is not skewed by such restrictions and will help maintain a more accurate representation of the general connectivity of the network.\n\n\n\nR code\n\n# overwrite one-way default\nosm_network_edges$oneway &lt;- \"no\"\n\n\nNow we have the network edges, we can turn this into a graph-representation that allows for the calculation of network-based accessibility statistics with our prepared point of interest data.\nIn any network analysis, the primary data structure is a graph composed of nodes and edges. The dodgr library utilises weighting profiles to assign weights based on road types, tailored to the mode of transport that each profile is designed to model. In this instance, we will use the foot weighting profile, as our focus is on modelling walking accessibility. To prevent errors related to the weighting profile, we will replace any NA values in the highway tag with the value unclassified.\n\n\n\nR code\n\n# replace missing highway tags with unclassified\nosm_network_edges &lt;- osm_network_edges |&gt;\n    mutate(highway = if_else(is.na(highway), \"unclassified\", highway))\n\n# create network graph\nosm_network_graph &lt;- weight_streetnet(osm_network_edges, wt_profile = \"foot\")\n\n\nOnce we have constructed our graph, we can use it to calculate network distances between our points of interest. One important consideration is that not all individual components in the extracted network may be connected. This can occur, for example, if the bounding box cuts off access to the road of a cul-de-sac. To ensure that our entire extracted network is connected, we will therefore extract the largest connected component of the graph.\n\n\n\n\n\n\nThe dodgr package documentation explains that components are numbered in order of decreasing size, with $component = 1 always representing the largest component. It is essential to inspect the resulting subgraph to ensure that its coverage is adequate for analysis.\n\n\n\n\n\n\nR code\n\n# extract the largest connected graph component\nnetx_connected &lt;- osm_network_graph[osm_network_graph$component == 1, ]\n\n# inspect number of remaining road segments\nnrow(netx_connected)\n\n\n[1] 436676\n\n\n\n\n\n\n\n\nOpenStreetMap is a dynamic dataset, meaning that changes are made on a continuous basis. As a result, it is quite possible that the number of remaining road segments, as shown above, may differ slightly when you run this analysis.\n\n\n\n\n\n\nNow that we have our connected subgraph, we can use the dodgr_distances() function to calculate the network distances between every possible origin (i.e.Â school) and destination (i.e.Â fast food outlet). For all combinations, the function will map the point of interest locations to the nearest point on the network and return the corresponding shortest-path distances.\n\n\n\n\n\n\nThe dodgr package requires data to be projected in WGS84, so we need to reproject our point of interest data accordingly.\n\n\n\n\n\n\nR code\n\n# reproject\npoi_schools &lt;- poi_schools |&gt;\n    st_transform(4326)\npoi_fastfood &lt;- poi_fastfood |&gt;\n    st_transform(4326)\n\n# distance matrix\ndistance_matrix &lt;- dodgr_distances(netx_connected, from = st_coordinates(poi_schools),\n    to = st_coordinates(poi_fastfood), shortest = FALSE, pairwise = FALSE, quiet = FALSE)\n\n\nThe result of this computation is a distance matrix that contains the network distances between all origins (i.e.Â schools) and all destinations (i.e.Â fast-food outlets):\n\n\n\nR code\n\n# inspect\ndistance_matrix[1:5, 1:5]\n\n\n            6807494201 7110321980 7110321980 11371586827 33148215\n8796433764    4660.831   4661.009   4661.009    3128.948 3087.031\n8820889464    3611.758   3753.383   3753.383    1957.011 1915.094\n11479633279   8497.581   8497.760   8497.760    6940.464 6898.547\n292521291     4917.554   4917.732   4917.732    4222.538 4287.953\n12331531180   6270.840   6271.018   6271.018    5575.824 5641.240\n\n\n\n\n\n\n\n\nThe above output displays the distance (in metres) between the first five schools and the first five fast-food outlets. The row and column IDs refer to the nearest nodes on the OSM network to which the schools and fast-food outlets were mapped.\n\n\n\nNow that we have the distance matrix, we can aggregate the data and perform accessibility analysis. For example, we can count the number of fast-food outlets within 500 or 1,000 metres walking distance from each school:\n\n\n\nR code\n\n# fast-food outlets within 500m\npoi_schools$fastfood_500m &lt;- rowSums(distance_matrix &lt;= 500)\n\n# fast-food outlets within 1000m\npoi_schools$fastfood_1000m &lt;- rowSums(distance_matrix &lt;= 1000)\n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\nIn the final step, we can investigate whether there is a relationship between the proximity of fast-food outlets and the relative levels of deprivation in the area. One approach is to calculate the average number of fast-food outlets within 1,000 metres of a school for each LSOA, and then compare these figures to their corresponding IMD deciles.\n\n\n\nR code\n\n# read imd dataset\nimd19 &lt;- read_csv(\"data/attributes/England-IMD-2019.csv\")\n\n\nRows: 32844 Columns: 3\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): lsoa11cd\ndbl (2): imd_rank, imd_dec\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# join imd\nlsoa11 &lt;- lsoa11 |&gt;\n  left_join(imd19, by = c(\"lsoa11cd\" = \"lsoa11cd\"))\n\n# join schools to their parent lsoa\npoi_schools &lt;- poi_schools |&gt;\n  st_transform(27700) |&gt;\n  st_join(lsoa11)\n\nWe can use this approach to derive the average number of fast-food by IMD decile:\n\n\n\nR code\n\n# average counts by imd decile\nfastfood_imd &lt;- poi_schools |&gt;\n    group_by(imd_dec) |&gt;\n    mutate(avg_cnt = mean(fastfood_1000m)) |&gt;\n    distinct(imd_dec, avg_cnt) |&gt;\n    arrange(imd_dec)\n\n# inspect\nfastfood_imd\n\n\n# A tibble: 7 Ã— 2\n# Groups:   imd_dec [7]\n  imd_dec avg_cnt\n    &lt;dbl&gt;   &lt;dbl&gt;\n1       2   20.1 \n2       3   14.3 \n3       4   17.5 \n4       5    9.83\n5       6    3   \n6       7    8.4 \n7       8   23.5 \n\n\nThere appears to be a weak relationship, with schools in more deprived areas having, on average, a higher number of fast-food outlets within a 1,000-metre walking distance. However, this trend is not consistent, as schools in the least deprived areas of Lambeth show the highest accessibility on average."
  },
  {
    "objectID": "08-network.html#assignment",
    "href": "08-network.html#assignment",
    "title": "1 Accessibility Analysis",
    "section": "",
    "text": "Accessibility analysis involves evaluating how easily people can reach essential services, destinations, or opportunities, such as schools, healthcare facilities, or workplaces, from a given location. The CDRC Access to Healthy Assets & Hazards (AHAH) dataset, for instance, uses accessibility analysis to quantify how easy it is to reach â€˜unhealthyâ€™ places, such as pubs and gambling outlets, for each neighbourhood in Great Britain.\nHaving run through all the steps during the tutorial, we can recreate this analysis ourselves. Using Lambeth as a case study, try to complete the following tasks:\n\nExtract all pubs from the Point of Interest dataset.\nFor each LSOA within Lambeth, calculate the average walking distance to the nearest pub.\nCreate a map of the results.\n\n\n\n\n\n\n\nUnlike before, LSOAs are now the unit of analysis. This means you will need to input the LSOA centroids into your distance matrix.\n\n\n\n\n\n\n\n\n\nIf you want to take a deep dive into accessibility analysis, there is a great resource that got published recently: Introduction to urban accessibility: a practical guide in R."
  },
  {
    "objectID": "08-network.html#before-you-leave",
    "href": "08-network.html#before-you-leave",
    "title": "1 Accessibility Analysis",
    "section": "",
    "text": "This brings us to the end of the tutorial. You should now have a basic understanding of the concepts behind accessibility analysis, how it can be executed in R, and some of the challenges you may encounter when conducting your own research. With this being said, you have now reached the end of this weekâ€™s content. Onwards and upwards!"
  },
  {
    "objectID": "09-maps.html",
    "href": "09-maps.html",
    "title": "1 Beyond the Choropleth",
    "section": "",
    "text": "So far, we have primarily created univariate choropleth maps to visualise data across defined spatial areas, such as LSOAs. This week, we will expand on this by exploring bivariate maps, which illustrate the relationship between two variables within a single visualisation. We will also introduce you to the ggplot2 library.\n\n\nYou can download the slides of this weekâ€™s lecture here: [Link].\n\n\n\n\n\n\nLongley, P. et al. 2015. Geographic Information Science & Systems, Chapter 11: Cartography and Map Production, pp.Â 1-32. [Link]\n\n\n\n\n\nCheshire, J. and Uberti, O. 2021. Atlas of the invisible: maps and graphics that will change how you see the world. London: Particular Books.\nWickham, H., Ã‡etinkaya-Rundel, M., and Grolemund, G. R for Data Science. 2nd edition. Chapter 1: Data visualization. [Link]\n\n\n\n\n\nThis week, we will look at the change in unemployment across London between 2011 and 2021. Specifically, we will try to reconcile 2011 Census data with 2021 Census data and present the results on a bivariate map. The data cover all usual residents, as recorded in the 2011 and 2021 Census for England and Wales, aggregated at the Lower Super Output Area (LSOA) level.\n\n\n\n\n\n\nAdministrative geographies, such as LSOAs, are periodically updated to reflect changes in population and other factors, resulting in occasional boundary adjustments. Consequently, it is essential to use the 2011 LSOA boundaries when mapping 2011 Census data and the 2021 LSOA boundaries for 2021 Census data. To facilitate mapping changes over time, we have access to a csv file containing a best-fit lookup table. This table provides a correspondence between 2011 LSOAs and their equivalent 2021 LSOAs, enabling consistent comparison across census periods.\n\n\n\nYou can download three files below and save them in your project folder under data/attributes. Along with these dataset, we also have access to a GeoPackage that contains the 2021 LSOA boundaries.\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon LSOA Census 2011 Unemployment\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Unemployment\ncsv\nDownload\n\n\nEngland and Wales LSOA 2011-2021 Lookup\ncsv\nDownload\n\n\nLondon LSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\nOpen a new script within your GEOG0030 project and save this as w09-unemployment-change.r.\nBegin by loading the necessary libraries:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(biscale)\nlibrary(cowplot)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nOnce downloaded, we can load all three files into memory:\n\n\n\nR code\n\n# read 2011 data\nlsoa11 &lt;- read_csv(\"data/attributes/London-LSOA-Unemployment-2011.csv\")\n\n\nRows: 4835 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (2): lsoa11cd, lsoa11nm\ndbl (2): eco_active_unemployed11, pop11\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# read 2021 data\nlsoa21 &lt;- read_csv(\"data/attributes/London-LSOA-Unemployment-2021.csv\")\n\nRows: 4994 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (2): lsoa21cd, lsoa21nm\ndbl (2): eco_active_unemployed21, pop21\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# read lookup data\nlookup &lt;- read_csv(\"data/attributes/England-Wales-LSOA-2011-2021.csv\")\n\nRows: 35796 Columns: 5\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (5): lsoa11cd, lsoa11nm, lsoa21cd, lsoa21nm, chgind\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# inspect\nhead(lsoa11)\n\n# A tibble: 6 Ã— 4\n  lsoa11cd  lsoa11nm                  eco_active_unemployed11 pop11\n  &lt;chr&gt;     &lt;chr&gt;                                       &lt;dbl&gt; &lt;dbl&gt;\n1 E01000001 City of London 001A                            34  1221\n2 E01000002 City of London 001B                            16  1196\n3 E01000003 City of London 001C                            39  1102\n4 E01000005 City of London 001E                            46   773\n5 E01000006 Barking and Dagenham 016A                      83  1251\n6 E01000007 Barking and Dagenham 015A                      87  1034\n\n# inspect\nhead(lsoa21)\n\n# A tibble: 6 Ã— 4\n  lsoa21cd  lsoa21nm                  eco_active_unemployed21 pop21\n  &lt;chr&gt;     &lt;chr&gt;                                       &lt;dbl&gt; &lt;dbl&gt;\n1 E01000001 City of London 001A                            32  1478\n2 E01000002 City of London 001B                            30  1383\n3 E01000003 City of London 001C                            68  1614\n4 E01000005 City of London 001E                            60  1099\n5 E01000006 Barking and Dagenham 016A                      57  1844\n6 E01000007 Barking and Dagenham 015A                     154  2908\n\n# inspect\nhead(lookup)\n\n# A tibble: 6 Ã— 5\n  lsoa11cd  lsoa11nm                  lsoa21cd  lsoa21nm                  chgind\n  &lt;chr&gt;     &lt;chr&gt;                     &lt;chr&gt;     &lt;chr&gt;                     &lt;chr&gt; \n1 E01000001 City of London 001A       E01000001 City of London 001A       U     \n2 E01000002 City of London 001B       E01000002 City of London 001B       U     \n3 E01000003 City of London 001C       E01000003 City of London 001C       U     \n4 E01000005 City of London 001E       E01000005 City of London 001E       U     \n5 E01000006 Barking and Dagenham 016A E01000006 Barking and Dagenham 016A U     \n6 E01000007 Barking and Dagenham 015A E01000007 Barking and Dagenham 015A U     \n\n\n\n\n\n\n\n\nYou can inspect both objects using the View() function.\n\n\n\n\n\nTo analyse changes in unemployment over time, we need to combine the 2011 and 2021 unemployment data. Previously, we have joined datasets using a unique identifier found in both, assuming the identifiers match exactly and represent the same geographies. However, when comparing the unique identifiers from (lsoa11cd and lsoa21cd) these datasets, we can see some clear differences:\n\n\n\nR code\n\n# inspect\nlength(unique(lsoa11$lsoa11cd))\n\n\n[1] 4835\n\n# inspect\nlength(unique(lsoa21$lsoa21cd))\n\n[1] 4994\n\n\nThe number of LSOAs increased between the 2011 and 2021 Census due to boundary changes. Specifically, some 2011 LSOAs have been split into multiple 2021 LSOAs, while others have been merged into a single 2021 LSOA polygon. The relationship between 2011 and 2021 LSOAs is captured in the chgind column of the lookup table, which flags the type of change for each case.\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nU\nUnchanged: The LSOA boundaries remain the same from 2011 to 2021, allowing direct comparisons between data for these years.\n\n\nS\nSplit: A 2011 LSOA has been divided into two or more 2021 LSOAs. Each split 2021 LSOA will have a corresponding record in the table, enabling comparisons by aggregating the 2021 LSOA data back to the 2011 boundary.\n\n\nM\nMerged: Two or more 2011 LSOAs have been combined into a single 2021 LSOA. Comparisons can be made by aggregating the 2011 LSOA data to match the new 2021 boundary.\n\n\nX\nIrregular/Fragmented: The relationship between 2011 and 2021 LSOAs is complex due to redesigns from local authority boundary changes or efforts to improve social homogeneity. These cases do not allow straightforward comparisons between 2011 and 2021 data.\n\n\n\nAlthough there are different approaches to handling this, today we will:\n\nDivide the total crimes for 2011 LSOAs that have been split equally across the corresponding 2021 LSOAs.\nCombine the total crimes for 2011 LSOAs that have been merged into a single 2021 LSOA.\n\n\n\n\n\n\n\nThe LSOA boundary changes in London between 2011 and 2021 did not result in any irregular or fragmented boundaries. Therefore, we only need to address the merged and split LSOAs.\n\n\n\nThis means we will apply weightings to the values based on their relationships. We can prepare these weightings as follows:\n\n\n\nR code\n\n# for unchanged LSOAs keep weighting the same\nlsoa_lookup_same &lt;- lookup |&gt;\n    filter(chgind == \"U\") |&gt;\n    group_by(lsoa11cd) |&gt;\n    mutate(n = n())\n\n# for merged LSOAs: keep weighting the same\nlsoa_lookup_merge &lt;- lookup |&gt;\n    filter(chgind == \"M\") |&gt;\n    group_by(lsoa11cd) |&gt;\n    mutate(n = n())\n\n# for split LSOAs: weigh proportionally to the number of 2021 LSOAs\nlsoa_lookup_split &lt;- lookup |&gt;\n    filter(chgind == \"S\") |&gt;\n    group_by(lsoa11cd) |&gt;\n    mutate(n = 1/n())\n\n# re-combine the lookup with updated weightings\nlsoa_lookup &lt;- rbind(lsoa_lookup_same, lsoa_lookup_merge, lsoa_lookup_split)\n\n# inspect\nlsoa_lookup\n\n\n# A tibble: 35,786 Ã— 6\n# Groups:   lsoa11cd [34,747]\n   lsoa11cd  lsoa11nm                  lsoa21cd  lsoa21nm           chgind     n\n   &lt;chr&gt;     &lt;chr&gt;                     &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;dbl&gt;\n 1 E01000001 City of London 001A       E01000001 City of London 00â€¦ U          1\n 2 E01000002 City of London 001B       E01000002 City of London 00â€¦ U          1\n 3 E01000003 City of London 001C       E01000003 City of London 00â€¦ U          1\n 4 E01000005 City of London 001E       E01000005 City of London 00â€¦ U          1\n 5 E01000006 Barking and Dagenham 016A E01000006 Barking and Dagenâ€¦ U          1\n 6 E01000007 Barking and Dagenham 015A E01000007 Barking and Dagenâ€¦ U          1\n 7 E01000008 Barking and Dagenham 015B E01000008 Barking and Dagenâ€¦ U          1\n 8 E01000009 Barking and Dagenham 016B E01000009 Barking and Dagenâ€¦ U          1\n 9 E01000011 Barking and Dagenham 016C E01000011 Barking and Dagenâ€¦ U          1\n10 E01000012 Barking and Dagenham 015D E01000012 Barking and Dagenâ€¦ U          1\n# â„¹ 35,776 more rows\n\n\n\n\n\n\n\n\nYou can inspect both objects using the View() function.\n\n\n\nWe can now join the lookup table on the 2011 LSOA data:\n\n\n\nR code\n\n# join to lsoa data\nlsoa11_21 &lt;- lsoa11 |&gt;\n  select(-lsoa11nm) |&gt;\n  left_join(lsoa_lookup, by = c(\"lsoa11cd\" = \"lsoa11cd\"))\n\n\nIf we now compare the number of records in our lsoa11_21 dataset with the original 2011 and 2021 LSOA datasets, we notice some differences:\n\n\n\nR code\n\n# lsoa 2011\nnrow(lsoa11)\n\n\n[1] 4835\n\n# lsoa 2021\nnrow(lsoa21)\n\n[1] 4994\n\n# lookup\nnrow(lsoa11_21)\n\n[1] 5016\n\n\nSomehow, the number of our LSOAs seem to have increased. However, this is not an actual increase in LSOAs; rather, the change in the number of LSOAs is due to our one-to-many relationships. A single 2011 LSOA can correspond to multiple 2021 LSOAs, which causes the data for that 2011 LSOA to be duplicated in the join operation. Fortunately, we anticipated this and have already created the necessary weightings. We can now apply these weightings to assign our 2011 population estimates to the 2021 LSOA boundaries as follows:\n\n\n\nR code\n\n# weigh data\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n    mutate(eco_active_unemployed11 = eco_active_unemployed11 * n) |&gt;\n    mutate(pop11 = pop11 * n)\n\n# assign 2011 to 2021\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n    group_by(lsoa21cd) |&gt;\n    mutate(eco_active_unemployed11_lsoa21 = sum(eco_active_unemployed11)) |&gt;\n    mutate(pop11_lsoa21 = sum(pop11)) |&gt;\n    distinct(lsoa21cd, eco_active_unemployed11_lsoa21, pop11_lsoa21)\n\n\nWe should now be left with all 2021 LSOAs, each containing the corresponding 2011 values, adjusted according to the merged and split LSOA relationships. We can quickly check this by comparing the original values with the re-assigned values:\n\n\n\nR code\n\n# inspect number\nnrow(lsoa21)\n\n\n[1] 4994\n\n# inspect number\nnrow(lsoa11_21)\n\n[1] 4994\n\n# inspect count original data\nsum(lsoa11$pop11)\n\n[1] 6117482\n\n# inspect count re-assigned data\nsum(lsoa11_21$pop11_lsoa21)\n\n[1] 6117482\n\n\nWe can now join the 2011 and 2021 population data together:\n\n\n\nR code\n\n# join 2011 data with 2021 data\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n  left_join(lsoa21, by = c(\"lsoa21cd\" = \"lsoa21cd\"))\n\n\n\n\n\nBivariate maps are visualisations that represent two different variables simultaneously on a single map, using combinations of colours, patterns, or symbols to convey relationships between them. They are commonly used to explore spatial correlations or patterns, such as comparing population density with income levels across a region. We will use a bivariate map to illustrate changes in unemployment between 2011 and 2021 in London.\nWe will start by calculating unemployment rates for both years and classifing them into categories using the biscale library:\n\n\n\nR code\n\n# unemployment rates\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n    mutate(unemp11 = eco_active_unemployed11_lsoa21/pop11_lsoa21) |&gt;\n    mutate(unemp21 = eco_active_unemployed21/pop21) |&gt;\n    select(-lsoa21nm)\n\n# add classes\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n    bi_class(x = unemp21, y = unemp11, style = \"quantile\", dim = 3)\n\n# inspect\nhead(lsoa11_21$bi_class)\n\n\n[1] \"1-1\" \"1-1\" \"3-1\" \"3-2\" \"2-3\" \"3-3\"\n\n\n\n\n\n\n\n\nThe dim argument is used to control the extent of the legend. For instance, dim = 2 will produce a two-by-two map where dim = 3 will produce a three-by-three map.\n\n\n\nInstead of using tmap to create our map, we will need to use the ggplot2 library. Like tmap, ggplot2 is based on the grammar of graphics, allowing you to build a graphic step by step by layering components such as data, aesthetics, and geometries. While we will explore ggplot2 in more detail next week, for now, we will use it to create a bivariate map by adding the necessary layers one at a time.\n\n\n\n\n\n\nBivariate maps are not supported in Version 3 of tmap. However, Version 4, which is currently under development, will include functionality for creating bivariate maps. This new version is expected to be released on CRAN soon\n\n\n\nOnce breaks are created, we can use bi_scale_fill() as part of our ggplot() call:\n\n\n\nR code\n\n# load spatial data\nlsoa21_sf &lt;- st_read(\"data/spatial/London-LSOA-2021.gpkg\")\n\n\nReading layer `London-LSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-LSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4994 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# join unemployment data\nlsoa21_sf &lt;- lsoa21_sf |&gt;\n  left_join(lsoa11_21, by = c(\"lsoa21cd\" = \"lsoa21cd\"))\n\n# bivariate map using ggplot\nggplot() +\n  geom_sf(data = lsoa21_sf, mapping = aes(fill = bi_class), color = NA, show.legend = FALSE) +\n  bi_scale_fill(pal = \"DkBlue2\", dim = 3) +\n  bi_theme()\n\n\n\n\nFigureÂ 1: Bivariate map change of unemployment rates in London 2011-2021.\n\n\n\n\nShades closer to grey indicate areas with relative low unemployment rates in both years, while shades closer to blue represent areas with high unemployment rates in both years. Mixed tones suggest areas where unemployment rates have changed between 2011 and 2021, with the specific colour intensity reflecting the degree and direction of this change.\nWe have set show.legend = FALSE to allow us to manually add our own bivariate legend. The palette and dimensions should align with those used in bi_class() for dimensions and bi_scale_fill() for both dimensions and palette to ensure consistency. We can create a legend and combine it with a map object as follows:\n\n\n\nR code\n\n# bivariate map object\nmap &lt;- ggplot() +\n  geom_sf(data = lsoa21_sf, mapping = aes(fill = bi_class), color = NA, show.legend = FALSE) +\n  bi_scale_fill(pal = \"DkBlue2\", dim = 3) +\n  bi_theme()\n\n# legend object\nlegend &lt;- bi_legend(\n  pal = \"DkBlue2\", dim = 3, xlab = \"Higher Unemployment 2021\",\n  ylab = \"Higher Unemployment 2011\", size = 6\n)\n\n# combine, draw\nggdraw() +\n  draw_plot(map, 0, 0, 1, 1) +\n  draw_plot(legend, 0, 0, .3, 0.3)\n\n\n\n\n\nFigureÂ 2: Bivariate map change of unemployment rates in London 2011-2021.\n\n\n\n\n\n\n\n\n\n\nThe values in the draw_plot() function specify the relative location and size of each map object on the canvas. Adjusting these values often requires some trial and error to achieve the desired positioning, as they control the x and y coordinates for placement and the width and height proportions of each object.\n\n\n\nWe have used LSOA data to create a bivariate map illustrating changes in unemployment rates. However, with nearly 5,000 LSOAs in London, this map can be challenging to interpret due to the high level of detail. Letâ€™s zoom in to Lambeth:\n\n\n\nR code\n\n# select lambeth\nlsoa21_lambeth &lt;- lsoa21_sf |&gt;\n  filter(str_detect(lsoa21nm, \"Lambeth\"))\n\n# add classes\nlsoa21_lambeth &lt;- lsoa21_lambeth |&gt;\n  bi_class(x = unemp21, y = unemp11, style = \"quantile\", dim = 3)\n\n# bivariate map object\nmap &lt;- ggplot() +\n  geom_sf(data = lsoa21_lambeth, mapping = aes(fill = bi_class), color = NA, show.legend = FALSE) +\n  bi_scale_fill(pal = \"DkBlue2\", dim = 3) +\n  bi_theme()\n\n# legend object\nlegend &lt;- bi_legend(\n  pal = \"DkBlue2\", dim = 3, xlab = \"Higher Unemployment 2021\",\n  ylab = \"Higher Unemployment 2011\", size = 6\n)\n\n# combine, draw\nggdraw() +\n  draw_plot(map, 0, 0, 1, 1) +\n  draw_plot(legend, 0.1, 0.1, 0.3, 0.3)\n\n\n\n\n\nFigureÂ 3: Bivariate map change of unemployment rates in Lambeth 2011-2021."
  },
  {
    "objectID": "09-maps.html#lecture-slides",
    "href": "09-maps.html#lecture-slides",
    "title": "1 Beyond the Choropleth",
    "section": "",
    "text": "You can download the slides of this weekâ€™s lecture here: [Link]."
  },
  {
    "objectID": "09-maps.html#reading-list",
    "href": "09-maps.html#reading-list",
    "title": "1 Beyond the Choropleth",
    "section": "",
    "text": "Longley, P. et al. 2015. Geographic Information Science & Systems, Chapter 11: Cartography and Map Production, pp.Â 1-32. [Link]\n\n\n\n\n\nCheshire, J. and Uberti, O. 2021. Atlas of the invisible: maps and graphics that will change how you see the world. London: Particular Books.\nWickham, H., Ã‡etinkaya-Rundel, M., and Grolemund, G. R for Data Science. 2nd edition. Chapter 1: Data visualization. [Link]"
  },
  {
    "objectID": "09-maps.html#unemployment-in-london",
    "href": "09-maps.html#unemployment-in-london",
    "title": "1 Beyond the Choropleth",
    "section": "",
    "text": "This week, we will look at the change in unemployment across London between 2011 and 2021. Specifically, we will try to reconcile 2011 Census data with 2021 Census data and present the results on a bivariate map. The data cover all usual residents, as recorded in the 2011 and 2021 Census for England and Wales, aggregated at the Lower Super Output Area (LSOA) level.\n\n\n\n\n\n\nAdministrative geographies, such as LSOAs, are periodically updated to reflect changes in population and other factors, resulting in occasional boundary adjustments. Consequently, it is essential to use the 2011 LSOA boundaries when mapping 2011 Census data and the 2021 LSOA boundaries for 2021 Census data. To facilitate mapping changes over time, we have access to a csv file containing a best-fit lookup table. This table provides a correspondence between 2011 LSOAs and their equivalent 2021 LSOAs, enabling consistent comparison across census periods.\n\n\n\nYou can download three files below and save them in your project folder under data/attributes. Along with these dataset, we also have access to a GeoPackage that contains the 2021 LSOA boundaries.\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon LSOA Census 2011 Unemployment\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Unemployment\ncsv\nDownload\n\n\nEngland and Wales LSOA 2011-2021 Lookup\ncsv\nDownload\n\n\nLondon LSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\nOpen a new script within your GEOG0030 project and save this as w09-unemployment-change.r.\nBegin by loading the necessary libraries:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(biscale)\nlibrary(cowplot)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nOnce downloaded, we can load all three files into memory:\n\n\n\nR code\n\n# read 2011 data\nlsoa11 &lt;- read_csv(\"data/attributes/London-LSOA-Unemployment-2011.csv\")\n\n\nRows: 4835 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (2): lsoa11cd, lsoa11nm\ndbl (2): eco_active_unemployed11, pop11\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# read 2021 data\nlsoa21 &lt;- read_csv(\"data/attributes/London-LSOA-Unemployment-2021.csv\")\n\nRows: 4994 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (2): lsoa21cd, lsoa21nm\ndbl (2): eco_active_unemployed21, pop21\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# read lookup data\nlookup &lt;- read_csv(\"data/attributes/England-Wales-LSOA-2011-2021.csv\")\n\nRows: 35796 Columns: 5\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (5): lsoa11cd, lsoa11nm, lsoa21cd, lsoa21nm, chgind\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# inspect\nhead(lsoa11)\n\n# A tibble: 6 Ã— 4\n  lsoa11cd  lsoa11nm                  eco_active_unemployed11 pop11\n  &lt;chr&gt;     &lt;chr&gt;                                       &lt;dbl&gt; &lt;dbl&gt;\n1 E01000001 City of London 001A                            34  1221\n2 E01000002 City of London 001B                            16  1196\n3 E01000003 City of London 001C                            39  1102\n4 E01000005 City of London 001E                            46   773\n5 E01000006 Barking and Dagenham 016A                      83  1251\n6 E01000007 Barking and Dagenham 015A                      87  1034\n\n# inspect\nhead(lsoa21)\n\n# A tibble: 6 Ã— 4\n  lsoa21cd  lsoa21nm                  eco_active_unemployed21 pop21\n  &lt;chr&gt;     &lt;chr&gt;                                       &lt;dbl&gt; &lt;dbl&gt;\n1 E01000001 City of London 001A                            32  1478\n2 E01000002 City of London 001B                            30  1383\n3 E01000003 City of London 001C                            68  1614\n4 E01000005 City of London 001E                            60  1099\n5 E01000006 Barking and Dagenham 016A                      57  1844\n6 E01000007 Barking and Dagenham 015A                     154  2908\n\n# inspect\nhead(lookup)\n\n# A tibble: 6 Ã— 5\n  lsoa11cd  lsoa11nm                  lsoa21cd  lsoa21nm                  chgind\n  &lt;chr&gt;     &lt;chr&gt;                     &lt;chr&gt;     &lt;chr&gt;                     &lt;chr&gt; \n1 E01000001 City of London 001A       E01000001 City of London 001A       U     \n2 E01000002 City of London 001B       E01000002 City of London 001B       U     \n3 E01000003 City of London 001C       E01000003 City of London 001C       U     \n4 E01000005 City of London 001E       E01000005 City of London 001E       U     \n5 E01000006 Barking and Dagenham 016A E01000006 Barking and Dagenham 016A U     \n6 E01000007 Barking and Dagenham 015A E01000007 Barking and Dagenham 015A U     \n\n\n\n\n\n\n\n\nYou can inspect both objects using the View() function.\n\n\n\n\n\nTo analyse changes in unemployment over time, we need to combine the 2011 and 2021 unemployment data. Previously, we have joined datasets using a unique identifier found in both, assuming the identifiers match exactly and represent the same geographies. However, when comparing the unique identifiers from (lsoa11cd and lsoa21cd) these datasets, we can see some clear differences:\n\n\n\nR code\n\n# inspect\nlength(unique(lsoa11$lsoa11cd))\n\n\n[1] 4835\n\n# inspect\nlength(unique(lsoa21$lsoa21cd))\n\n[1] 4994\n\n\nThe number of LSOAs increased between the 2011 and 2021 Census due to boundary changes. Specifically, some 2011 LSOAs have been split into multiple 2021 LSOAs, while others have been merged into a single 2021 LSOA polygon. The relationship between 2011 and 2021 LSOAs is captured in the chgind column of the lookup table, which flags the type of change for each case.\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nU\nUnchanged: The LSOA boundaries remain the same from 2011 to 2021, allowing direct comparisons between data for these years.\n\n\nS\nSplit: A 2011 LSOA has been divided into two or more 2021 LSOAs. Each split 2021 LSOA will have a corresponding record in the table, enabling comparisons by aggregating the 2021 LSOA data back to the 2011 boundary.\n\n\nM\nMerged: Two or more 2011 LSOAs have been combined into a single 2021 LSOA. Comparisons can be made by aggregating the 2011 LSOA data to match the new 2021 boundary.\n\n\nX\nIrregular/Fragmented: The relationship between 2011 and 2021 LSOAs is complex due to redesigns from local authority boundary changes or efforts to improve social homogeneity. These cases do not allow straightforward comparisons between 2011 and 2021 data.\n\n\n\nAlthough there are different approaches to handling this, today we will:\n\nDivide the total crimes for 2011 LSOAs that have been split equally across the corresponding 2021 LSOAs.\nCombine the total crimes for 2011 LSOAs that have been merged into a single 2021 LSOA.\n\n\n\n\n\n\n\nThe LSOA boundary changes in London between 2011 and 2021 did not result in any irregular or fragmented boundaries. Therefore, we only need to address the merged and split LSOAs.\n\n\n\nThis means we will apply weightings to the values based on their relationships. We can prepare these weightings as follows:\n\n\n\nR code\n\n# for unchanged LSOAs keep weighting the same\nlsoa_lookup_same &lt;- lookup |&gt;\n    filter(chgind == \"U\") |&gt;\n    group_by(lsoa11cd) |&gt;\n    mutate(n = n())\n\n# for merged LSOAs: keep weighting the same\nlsoa_lookup_merge &lt;- lookup |&gt;\n    filter(chgind == \"M\") |&gt;\n    group_by(lsoa11cd) |&gt;\n    mutate(n = n())\n\n# for split LSOAs: weigh proportionally to the number of 2021 LSOAs\nlsoa_lookup_split &lt;- lookup |&gt;\n    filter(chgind == \"S\") |&gt;\n    group_by(lsoa11cd) |&gt;\n    mutate(n = 1/n())\n\n# re-combine the lookup with updated weightings\nlsoa_lookup &lt;- rbind(lsoa_lookup_same, lsoa_lookup_merge, lsoa_lookup_split)\n\n# inspect\nlsoa_lookup\n\n\n# A tibble: 35,786 Ã— 6\n# Groups:   lsoa11cd [34,747]\n   lsoa11cd  lsoa11nm                  lsoa21cd  lsoa21nm           chgind     n\n   &lt;chr&gt;     &lt;chr&gt;                     &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;dbl&gt;\n 1 E01000001 City of London 001A       E01000001 City of London 00â€¦ U          1\n 2 E01000002 City of London 001B       E01000002 City of London 00â€¦ U          1\n 3 E01000003 City of London 001C       E01000003 City of London 00â€¦ U          1\n 4 E01000005 City of London 001E       E01000005 City of London 00â€¦ U          1\n 5 E01000006 Barking and Dagenham 016A E01000006 Barking and Dagenâ€¦ U          1\n 6 E01000007 Barking and Dagenham 015A E01000007 Barking and Dagenâ€¦ U          1\n 7 E01000008 Barking and Dagenham 015B E01000008 Barking and Dagenâ€¦ U          1\n 8 E01000009 Barking and Dagenham 016B E01000009 Barking and Dagenâ€¦ U          1\n 9 E01000011 Barking and Dagenham 016C E01000011 Barking and Dagenâ€¦ U          1\n10 E01000012 Barking and Dagenham 015D E01000012 Barking and Dagenâ€¦ U          1\n# â„¹ 35,776 more rows\n\n\n\n\n\n\n\n\nYou can inspect both objects using the View() function.\n\n\n\nWe can now join the lookup table on the 2011 LSOA data:\n\n\n\nR code\n\n# join to lsoa data\nlsoa11_21 &lt;- lsoa11 |&gt;\n  select(-lsoa11nm) |&gt;\n  left_join(lsoa_lookup, by = c(\"lsoa11cd\" = \"lsoa11cd\"))\n\n\nIf we now compare the number of records in our lsoa11_21 dataset with the original 2011 and 2021 LSOA datasets, we notice some differences:\n\n\n\nR code\n\n# lsoa 2011\nnrow(lsoa11)\n\n\n[1] 4835\n\n# lsoa 2021\nnrow(lsoa21)\n\n[1] 4994\n\n# lookup\nnrow(lsoa11_21)\n\n[1] 5016\n\n\nSomehow, the number of our LSOAs seem to have increased. However, this is not an actual increase in LSOAs; rather, the change in the number of LSOAs is due to our one-to-many relationships. A single 2011 LSOA can correspond to multiple 2021 LSOAs, which causes the data for that 2011 LSOA to be duplicated in the join operation. Fortunately, we anticipated this and have already created the necessary weightings. We can now apply these weightings to assign our 2011 population estimates to the 2021 LSOA boundaries as follows:\n\n\n\nR code\n\n# weigh data\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n    mutate(eco_active_unemployed11 = eco_active_unemployed11 * n) |&gt;\n    mutate(pop11 = pop11 * n)\n\n# assign 2011 to 2021\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n    group_by(lsoa21cd) |&gt;\n    mutate(eco_active_unemployed11_lsoa21 = sum(eco_active_unemployed11)) |&gt;\n    mutate(pop11_lsoa21 = sum(pop11)) |&gt;\n    distinct(lsoa21cd, eco_active_unemployed11_lsoa21, pop11_lsoa21)\n\n\nWe should now be left with all 2021 LSOAs, each containing the corresponding 2011 values, adjusted according to the merged and split LSOA relationships. We can quickly check this by comparing the original values with the re-assigned values:\n\n\n\nR code\n\n# inspect number\nnrow(lsoa21)\n\n\n[1] 4994\n\n# inspect number\nnrow(lsoa11_21)\n\n[1] 4994\n\n# inspect count original data\nsum(lsoa11$pop11)\n\n[1] 6117482\n\n# inspect count re-assigned data\nsum(lsoa11_21$pop11_lsoa21)\n\n[1] 6117482\n\n\nWe can now join the 2011 and 2021 population data together:\n\n\n\nR code\n\n# join 2011 data with 2021 data\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n  left_join(lsoa21, by = c(\"lsoa21cd\" = \"lsoa21cd\"))\n\n\n\n\n\nBivariate maps are visualisations that represent two different variables simultaneously on a single map, using combinations of colours, patterns, or symbols to convey relationships between them. They are commonly used to explore spatial correlations or patterns, such as comparing population density with income levels across a region. We will use a bivariate map to illustrate changes in unemployment between 2011 and 2021 in London.\nWe will start by calculating unemployment rates for both years and classifing them into categories using the biscale library:\n\n\n\nR code\n\n# unemployment rates\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n    mutate(unemp11 = eco_active_unemployed11_lsoa21/pop11_lsoa21) |&gt;\n    mutate(unemp21 = eco_active_unemployed21/pop21) |&gt;\n    select(-lsoa21nm)\n\n# add classes\nlsoa11_21 &lt;- lsoa11_21 |&gt;\n    bi_class(x = unemp21, y = unemp11, style = \"quantile\", dim = 3)\n\n# inspect\nhead(lsoa11_21$bi_class)\n\n\n[1] \"1-1\" \"1-1\" \"3-1\" \"3-2\" \"2-3\" \"3-3\"\n\n\n\n\n\n\n\n\nThe dim argument is used to control the extent of the legend. For instance, dim = 2 will produce a two-by-two map where dim = 3 will produce a three-by-three map.\n\n\n\nInstead of using tmap to create our map, we will need to use the ggplot2 library. Like tmap, ggplot2 is based on the grammar of graphics, allowing you to build a graphic step by step by layering components such as data, aesthetics, and geometries. While we will explore ggplot2 in more detail next week, for now, we will use it to create a bivariate map by adding the necessary layers one at a time.\n\n\n\n\n\n\nBivariate maps are not supported in Version 3 of tmap. However, Version 4, which is currently under development, will include functionality for creating bivariate maps. This new version is expected to be released on CRAN soon\n\n\n\nOnce breaks are created, we can use bi_scale_fill() as part of our ggplot() call:\n\n\n\nR code\n\n# load spatial data\nlsoa21_sf &lt;- st_read(\"data/spatial/London-LSOA-2021.gpkg\")\n\n\nReading layer `London-LSOA-2021' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0030/data/spatial/London-LSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4994 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# join unemployment data\nlsoa21_sf &lt;- lsoa21_sf |&gt;\n  left_join(lsoa11_21, by = c(\"lsoa21cd\" = \"lsoa21cd\"))\n\n# bivariate map using ggplot\nggplot() +\n  geom_sf(data = lsoa21_sf, mapping = aes(fill = bi_class), color = NA, show.legend = FALSE) +\n  bi_scale_fill(pal = \"DkBlue2\", dim = 3) +\n  bi_theme()\n\n\n\n\nFigureÂ 1: Bivariate map change of unemployment rates in London 2011-2021.\n\n\n\n\nShades closer to grey indicate areas with relative low unemployment rates in both years, while shades closer to blue represent areas with high unemployment rates in both years. Mixed tones suggest areas where unemployment rates have changed between 2011 and 2021, with the specific colour intensity reflecting the degree and direction of this change.\nWe have set show.legend = FALSE to allow us to manually add our own bivariate legend. The palette and dimensions should align with those used in bi_class() for dimensions and bi_scale_fill() for both dimensions and palette to ensure consistency. We can create a legend and combine it with a map object as follows:\n\n\n\nR code\n\n# bivariate map object\nmap &lt;- ggplot() +\n  geom_sf(data = lsoa21_sf, mapping = aes(fill = bi_class), color = NA, show.legend = FALSE) +\n  bi_scale_fill(pal = \"DkBlue2\", dim = 3) +\n  bi_theme()\n\n# legend object\nlegend &lt;- bi_legend(\n  pal = \"DkBlue2\", dim = 3, xlab = \"Higher Unemployment 2021\",\n  ylab = \"Higher Unemployment 2011\", size = 6\n)\n\n# combine, draw\nggdraw() +\n  draw_plot(map, 0, 0, 1, 1) +\n  draw_plot(legend, 0, 0, .3, 0.3)\n\n\n\n\n\nFigureÂ 2: Bivariate map change of unemployment rates in London 2011-2021.\n\n\n\n\n\n\n\n\n\n\nThe values in the draw_plot() function specify the relative location and size of each map object on the canvas. Adjusting these values often requires some trial and error to achieve the desired positioning, as they control the x and y coordinates for placement and the width and height proportions of each object.\n\n\n\nWe have used LSOA data to create a bivariate map illustrating changes in unemployment rates. However, with nearly 5,000 LSOAs in London, this map can be challenging to interpret due to the high level of detail. Letâ€™s zoom in to Lambeth:\n\n\n\nR code\n\n# select lambeth\nlsoa21_lambeth &lt;- lsoa21_sf |&gt;\n  filter(str_detect(lsoa21nm, \"Lambeth\"))\n\n# add classes\nlsoa21_lambeth &lt;- lsoa21_lambeth |&gt;\n  bi_class(x = unemp21, y = unemp11, style = \"quantile\", dim = 3)\n\n# bivariate map object\nmap &lt;- ggplot() +\n  geom_sf(data = lsoa21_lambeth, mapping = aes(fill = bi_class), color = NA, show.legend = FALSE) +\n  bi_scale_fill(pal = \"DkBlue2\", dim = 3) +\n  bi_theme()\n\n# legend object\nlegend &lt;- bi_legend(\n  pal = \"DkBlue2\", dim = 3, xlab = \"Higher Unemployment 2021\",\n  ylab = \"Higher Unemployment 2011\", size = 6\n)\n\n# combine, draw\nggdraw() +\n  draw_plot(map, 0, 0, 1, 1) +\n  draw_plot(legend, 0.1, 0.1, 0.3, 0.3)\n\n\n\n\n\nFigureÂ 3: Bivariate map change of unemployment rates in Lambeth 2011-2021."
  }
]